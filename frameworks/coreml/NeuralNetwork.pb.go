// Code generated by protoc-gen-gogo.
// source: NeuralNetwork.proto
// DO NOT EDIT!

package CoreML

import proto "github.com/gogo/protobuf/proto"
import fmt "fmt"
import math "math"

import io "io"

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// Ignoring public import of StringToInt64Map from DataStructures.proto

// Ignoring public import of Int64ToStringMap from DataStructures.proto

// Ignoring public import of StringToDoubleMap from DataStructures.proto

// Ignoring public import of Int64ToDoubleMap from DataStructures.proto

// Ignoring public import of StringVector from DataStructures.proto

// Ignoring public import of Int64Vector from DataStructures.proto

// Ignoring public import of DoubleVector from DataStructures.proto

type SamePadding_SamePaddingMode int32

const (
	SamePadding_BOTTOM_RIGHT_HEAVY SamePadding_SamePaddingMode = 0
	SamePadding_TOP_LEFT_HEAVY     SamePadding_SamePaddingMode = 1
)

var SamePadding_SamePaddingMode_name = map[int32]string{
	0: "BOTTOM_RIGHT_HEAVY",
	1: "TOP_LEFT_HEAVY",
}
var SamePadding_SamePaddingMode_value = map[string]int32{
	"BOTTOM_RIGHT_HEAVY": 0,
	"TOP_LEFT_HEAVY":     1,
}

func (x SamePadding_SamePaddingMode) String() string {
	return proto.EnumName(SamePadding_SamePaddingMode_name, int32(x))
}
func (SamePadding_SamePaddingMode) EnumDescriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{21, 0}
}

type PoolingLayerParams_PoolingType int32

const (
	PoolingLayerParams_MAX     PoolingLayerParams_PoolingType = 0
	PoolingLayerParams_AVERAGE PoolingLayerParams_PoolingType = 1
	PoolingLayerParams_L2      PoolingLayerParams_PoolingType = 2
)

var PoolingLayerParams_PoolingType_name = map[int32]string{
	0: "MAX",
	1: "AVERAGE",
	2: "L2",
}
var PoolingLayerParams_PoolingType_value = map[string]int32{
	"MAX":     0,
	"AVERAGE": 1,
	"L2":      2,
}

func (x PoolingLayerParams_PoolingType) String() string {
	return proto.EnumName(PoolingLayerParams_PoolingType_name, int32(x))
}
func (PoolingLayerParams_PoolingType) EnumDescriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{27, 0}
}

// *
// A unary operator.
//
// The following functions are supported:
//
// ``SQRT``
//     .. math:: f(x) = \sqrt{x}
//
// ``RSQRT``
//     .. math:: f(x) = \dfrac{1}{\sqrt{x + \epsilon}}
//
// ``INVERSE``
//     .. math:: f(x) = \dfrac{1}{x + \epsilon}
//
// ``POWER``
//     .. math:: f(x) = x^\alpha
//
// ``EXP``
//     .. math:: f(x) = e^x
//
// ``LOG``
//     .. math:: f(x) = \log x
//
// ``ABS``
//     .. math:: f(x) = |x|
//
// ``THRESHOLD``
//     .. math:: f(x) = \text{max}(\alpha, x)
type UnaryFunctionLayerParams_Operation int32

const (
	UnaryFunctionLayerParams_SQRT      UnaryFunctionLayerParams_Operation = 0
	UnaryFunctionLayerParams_RSQRT     UnaryFunctionLayerParams_Operation = 1
	UnaryFunctionLayerParams_INVERSE   UnaryFunctionLayerParams_Operation = 2
	UnaryFunctionLayerParams_POWER     UnaryFunctionLayerParams_Operation = 3
	UnaryFunctionLayerParams_EXP       UnaryFunctionLayerParams_Operation = 4
	UnaryFunctionLayerParams_LOG       UnaryFunctionLayerParams_Operation = 5
	UnaryFunctionLayerParams_ABS       UnaryFunctionLayerParams_Operation = 6
	UnaryFunctionLayerParams_THRESHOLD UnaryFunctionLayerParams_Operation = 7
)

var UnaryFunctionLayerParams_Operation_name = map[int32]string{
	0: "SQRT",
	1: "RSQRT",
	2: "INVERSE",
	3: "POWER",
	4: "EXP",
	5: "LOG",
	6: "ABS",
	7: "THRESHOLD",
}
var UnaryFunctionLayerParams_Operation_value = map[string]int32{
	"SQRT":      0,
	"RSQRT":     1,
	"INVERSE":   2,
	"POWER":     3,
	"EXP":       4,
	"LOG":       5,
	"ABS":       6,
	"THRESHOLD": 7,
}

func (x UnaryFunctionLayerParams_Operation) String() string {
	return proto.EnumName(UnaryFunctionLayerParams_Operation_name, int32(x))
}
func (UnaryFunctionLayerParams_Operation) EnumDescriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{35, 0}
}

type FlattenLayerParams_FlattenOrder int32

const (
	FlattenLayerParams_CHANNEL_FIRST FlattenLayerParams_FlattenOrder = 0
	FlattenLayerParams_CHANNEL_LAST  FlattenLayerParams_FlattenOrder = 1
)

var FlattenLayerParams_FlattenOrder_name = map[int32]string{
	0: "CHANNEL_FIRST",
	1: "CHANNEL_LAST",
}
var FlattenLayerParams_FlattenOrder_value = map[string]int32{
	"CHANNEL_FIRST": 0,
	"CHANNEL_LAST":  1,
}

func (x FlattenLayerParams_FlattenOrder) String() string {
	return proto.EnumName(FlattenLayerParams_FlattenOrder_name, int32(x))
}
func (FlattenLayerParams_FlattenOrder) EnumDescriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{41, 0}
}

type ReshapeLayerParams_ReshapeOrder int32

const (
	ReshapeLayerParams_CHANNEL_FIRST ReshapeLayerParams_ReshapeOrder = 0
	ReshapeLayerParams_CHANNEL_LAST  ReshapeLayerParams_ReshapeOrder = 1
)

var ReshapeLayerParams_ReshapeOrder_name = map[int32]string{
	0: "CHANNEL_FIRST",
	1: "CHANNEL_LAST",
}
var ReshapeLayerParams_ReshapeOrder_value = map[string]int32{
	"CHANNEL_FIRST": 0,
	"CHANNEL_LAST":  1,
}

func (x ReshapeLayerParams_ReshapeOrder) String() string {
	return proto.EnumName(ReshapeLayerParams_ReshapeOrder_name, int32(x))
}
func (ReshapeLayerParams_ReshapeOrder) EnumDescriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{42, 0}
}

//
// The following reduction operations are supported
// and are applied on flattened input array:
//
// ``SUM``
//     Sum of all elements
//
//     .. math:: \sum{x_i}
//
// ``AVG``
//     Sum of all elements divided by the number of elements
//
//     .. math:: \dfrac{\sum^n{x_i}}{n}
//
// ``PROD``
//     Product of all elements
//
//     .. math:: \prod{x_i}
//
// ``LOGSUM``
//     Sum of the natural logarithm of all elements
//
//     .. math:: \sum{\ln{(x_i + \epsilon)}}
//
// ``SUMSQUARE``
//     Sum of squares of all elements
//
//     .. math:: \sum{x^2}
//
// ``L1``
//     L1 normalization of all elements
//
//     .. math:: ||x||_1 = \sum{|x_i|}
//
// ``L2``
//     L2 normalization of all elements
//
//     .. math:: ||x||_2 = \sqrt{\sum{x_i^2}}
//
type ReduceLayerParams_ReduceOperation int32

const (
	ReduceLayerParams_SUM       ReduceLayerParams_ReduceOperation = 0
	ReduceLayerParams_AVG       ReduceLayerParams_ReduceOperation = 1
	ReduceLayerParams_PROD      ReduceLayerParams_ReduceOperation = 2
	ReduceLayerParams_LOGSUM    ReduceLayerParams_ReduceOperation = 3
	ReduceLayerParams_SUMSQUARE ReduceLayerParams_ReduceOperation = 4
	ReduceLayerParams_L1        ReduceLayerParams_ReduceOperation = 5
	ReduceLayerParams_L2        ReduceLayerParams_ReduceOperation = 6
)

var ReduceLayerParams_ReduceOperation_name = map[int32]string{
	0: "SUM",
	1: "AVG",
	2: "PROD",
	3: "LOGSUM",
	4: "SUMSQUARE",
	5: "L1",
	6: "L2",
}
var ReduceLayerParams_ReduceOperation_value = map[string]int32{
	"SUM":       0,
	"AVG":       1,
	"PROD":      2,
	"LOGSUM":    3,
	"SUMSQUARE": 4,
	"L1":        5,
	"L2":        6,
}

func (x ReduceLayerParams_ReduceOperation) String() string {
	return proto.EnumName(ReduceLayerParams_ReduceOperation_name, int32(x))
}
func (ReduceLayerParams_ReduceOperation) EnumDescriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{44, 0}
}

// *
// A neural network is defined through a collection of layers
// and represents a directed acyclic graph (DAG).
// Each layer has a name, a layer type,
// a list of input names, a list of output names,
// and a collection of parameters specific to the layer type.
//
// The graph structure and connectivity of the neural network
// is inferred from the input and output names.
// A neural network starts with the layer
// whose input name is equal to the value specified in
// ``Model.description.input.name``,
// and ends with the layer
// whose output name is equal to the value specified in
// ``Model.description.output.name``.
// Layers must have unique input and output names,
// and a layer may not have input or output names that
// refer to layers that are not yet defined.
//
// CoreML supports sequential data that can be 1- or 3-dimensional.
// 3-dimensional data typically represents an image feature map,
// whose shape is denoted by ``[C, H, W]``,
// which corresponds to the channel, height, and width, respectively.
// 1-dimensional data is a set of features
// whose shape is denoted by ``[C]``,
// and is equivalent to 3-dimensional data
// with the shape ``[C, 1, 1]``.
//
// For the purposes of this specification,
// batch dimension is ignored.
// Thus, a sequence of 3-dimensional data
// is to be understood as a 4-dimensional array,
// whose shape is denoted by ``[Seq_length, C, H, W]``,
// and a sequence of 1-dimensional data
// is to be understood as a 2-dimensional array,
// whose shape is denoted by ``[Seq_length, C]``,
// which is equivalent to a 4-dimensional array
// with the shape ``[Seq_length, C, 1, 1]``. This axes order is important to
// remember while setting parameters for layers such as "reshape" and "permute".
//
//
// At runtime, all data blobs are internally represented
// as 5-dimensional blobs
// with the shape ``[Seq_length, Batch, C, H, W]``.
//
// A layer may process input data differently if operating over a sequence;
// details of this behavior is documented in the layer's message.
// Otherwise, sequential data is processed like a batch ---
// that is, the sequence of inputs are processed independently and in parallel.
//
// The network input shape specified by ``Model.description.input.type``
// must be compatible with the expected input shape
// of the network input layer, i.e. the last dimension is the fastest moving
// one.
//
// All data blobs, as well as weight parameters,
// are stored using row-major ordering, i.e. the last dimension is the fastest
// moving one.
type NeuralNetwork struct {
	Layers        []*NeuralNetworkLayer         `protobuf:"bytes,1,rep,name=layers" json:"layers,omitempty"`
	Preprocessing []*NeuralNetworkPreprocessing `protobuf:"bytes,2,rep,name=preprocessing" json:"preprocessing,omitempty"`
}

func (m *NeuralNetwork) Reset()                    { *m = NeuralNetwork{} }
func (m *NeuralNetwork) String() string            { return proto.CompactTextString(m) }
func (*NeuralNetwork) ProtoMessage()               {}
func (*NeuralNetwork) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{0} }

func (m *NeuralNetwork) GetLayers() []*NeuralNetworkLayer {
	if m != nil {
		return m.Layers
	}
	return nil
}

func (m *NeuralNetwork) GetPreprocessing() []*NeuralNetworkPreprocessing {
	if m != nil {
		return m.Preprocessing
	}
	return nil
}

// *
// A neural network preprocessor that
// performs a scalar multiplication of an image
// followed by addition of scalar biases to the channels.
//
// Input: X
//    An image in BGR or RGB format with shape ``[3, H, W]``
//    or in grayscale format with shape ``[1, H, W]``.
// Output: Y
//    An image with format and shape corresponding to the input.
//
// If the input image is in BGR format:
// ::
//     Y[0, :, :] = channelScale * X[0, :, :] + blueBias
//     Y[1, :, :] = channelScale * X[1, :, :] + greenBias
//     Y[2, :, :] = channelScale * X[2, :, :] + redBias
//
// If the input image is in RGB format:
// ::
//     Y[0, :, :] = channelScale * X[0, :, :] + redBias
//     Y[1, :, :] = channelScale * X[1, :, :] + greenBias
//     Y[2, :, :] = channelScale * X[2, :, :] + blueBias
//
// If the input image is in grayscale format:
// ::
//     Y[0, :, :] = channelScale * X[0, :, :] + grayBias
type NeuralNetworkImageScaler struct {
	ChannelScale float32 `protobuf:"fixed32,10,opt,name=channelScale,proto3" json:"channelScale,omitempty"`
	BlueBias     float32 `protobuf:"fixed32,20,opt,name=blueBias,proto3" json:"blueBias,omitempty"`
	GreenBias    float32 `protobuf:"fixed32,21,opt,name=greenBias,proto3" json:"greenBias,omitempty"`
	RedBias      float32 `protobuf:"fixed32,22,opt,name=redBias,proto3" json:"redBias,omitempty"`
	GrayBias     float32 `protobuf:"fixed32,30,opt,name=grayBias,proto3" json:"grayBias,omitempty"`
}

func (m *NeuralNetworkImageScaler) Reset()         { *m = NeuralNetworkImageScaler{} }
func (m *NeuralNetworkImageScaler) String() string { return proto.CompactTextString(m) }
func (*NeuralNetworkImageScaler) ProtoMessage()    {}
func (*NeuralNetworkImageScaler) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{1}
}

func (m *NeuralNetworkImageScaler) GetChannelScale() float32 {
	if m != nil {
		return m.ChannelScale
	}
	return 0
}

func (m *NeuralNetworkImageScaler) GetBlueBias() float32 {
	if m != nil {
		return m.BlueBias
	}
	return 0
}

func (m *NeuralNetworkImageScaler) GetGreenBias() float32 {
	if m != nil {
		return m.GreenBias
	}
	return 0
}

func (m *NeuralNetworkImageScaler) GetRedBias() float32 {
	if m != nil {
		return m.RedBias
	}
	return 0
}

func (m *NeuralNetworkImageScaler) GetGrayBias() float32 {
	if m != nil {
		return m.GrayBias
	}
	return 0
}

// *
// A neural network preprocessor that
// subtracts the provided mean image from the input image.
// The mean image is subtracted from the input named
// ``NeuralNetworkPreprocessing.featureName``.
type NeuralNetworkMeanImage struct {
	// *
	// Mean image stored as a flattened array of floats,
	// representing shape [Channel,Height,Width].
	MeanImage []float32 `protobuf:"fixed32,1,rep,packed,name=meanImage" json:"meanImage,omitempty"`
}

func (m *NeuralNetworkMeanImage) Reset()         { *m = NeuralNetworkMeanImage{} }
func (m *NeuralNetworkMeanImage) String() string { return proto.CompactTextString(m) }
func (*NeuralNetworkMeanImage) ProtoMessage()    {}
func (*NeuralNetworkMeanImage) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{2}
}

func (m *NeuralNetworkMeanImage) GetMeanImage() []float32 {
	if m != nil {
		return m.MeanImage
	}
	return nil
}

// / Preprocessing parameters for image inputs.
type NeuralNetworkPreprocessing struct {
	FeatureName string `protobuf:"bytes,1,opt,name=featureName,proto3" json:"featureName,omitempty"`
	// Types that are valid to be assigned to Preprocessor:
	//	*NeuralNetworkPreprocessing_Scaler
	//	*NeuralNetworkPreprocessing_MeanImage
	Preprocessor isNeuralNetworkPreprocessing_Preprocessor `protobuf_oneof:"preprocessor"`
}

func (m *NeuralNetworkPreprocessing) Reset()         { *m = NeuralNetworkPreprocessing{} }
func (m *NeuralNetworkPreprocessing) String() string { return proto.CompactTextString(m) }
func (*NeuralNetworkPreprocessing) ProtoMessage()    {}
func (*NeuralNetworkPreprocessing) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{3}
}

type isNeuralNetworkPreprocessing_Preprocessor interface {
	isNeuralNetworkPreprocessing_Preprocessor()
	MarshalTo([]byte) (int, error)
	Size() int
}

type NeuralNetworkPreprocessing_Scaler struct {
	Scaler *NeuralNetworkImageScaler `protobuf:"bytes,10,opt,name=scaler,oneof"`
}
type NeuralNetworkPreprocessing_MeanImage struct {
	MeanImage *NeuralNetworkMeanImage `protobuf:"bytes,11,opt,name=meanImage,oneof"`
}

func (*NeuralNetworkPreprocessing_Scaler) isNeuralNetworkPreprocessing_Preprocessor()    {}
func (*NeuralNetworkPreprocessing_MeanImage) isNeuralNetworkPreprocessing_Preprocessor() {}

func (m *NeuralNetworkPreprocessing) GetPreprocessor() isNeuralNetworkPreprocessing_Preprocessor {
	if m != nil {
		return m.Preprocessor
	}
	return nil
}

func (m *NeuralNetworkPreprocessing) GetFeatureName() string {
	if m != nil {
		return m.FeatureName
	}
	return ""
}

func (m *NeuralNetworkPreprocessing) GetScaler() *NeuralNetworkImageScaler {
	if x, ok := m.GetPreprocessor().(*NeuralNetworkPreprocessing_Scaler); ok {
		return x.Scaler
	}
	return nil
}

func (m *NeuralNetworkPreprocessing) GetMeanImage() *NeuralNetworkMeanImage {
	if x, ok := m.GetPreprocessor().(*NeuralNetworkPreprocessing_MeanImage); ok {
		return x.MeanImage
	}
	return nil
}

// XXX_OneofFuncs is for the internal use of the proto package.
func (*NeuralNetworkPreprocessing) XXX_OneofFuncs() (func(msg proto.Message, b *proto.Buffer) error, func(msg proto.Message, tag, wire int, b *proto.Buffer) (bool, error), func(msg proto.Message) (n int), []interface{}) {
	return _NeuralNetworkPreprocessing_OneofMarshaler, _NeuralNetworkPreprocessing_OneofUnmarshaler, _NeuralNetworkPreprocessing_OneofSizer, []interface{}{
		(*NeuralNetworkPreprocessing_Scaler)(nil),
		(*NeuralNetworkPreprocessing_MeanImage)(nil),
	}
}

func _NeuralNetworkPreprocessing_OneofMarshaler(msg proto.Message, b *proto.Buffer) error {
	m := msg.(*NeuralNetworkPreprocessing)
	// preprocessor
	switch x := m.Preprocessor.(type) {
	case *NeuralNetworkPreprocessing_Scaler:
		_ = b.EncodeVarint(10<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Scaler); err != nil {
			return err
		}
	case *NeuralNetworkPreprocessing_MeanImage:
		_ = b.EncodeVarint(11<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.MeanImage); err != nil {
			return err
		}
	case nil:
	default:
		return fmt.Errorf("NeuralNetworkPreprocessing.Preprocessor has unexpected type %T", x)
	}
	return nil
}

func _NeuralNetworkPreprocessing_OneofUnmarshaler(msg proto.Message, tag, wire int, b *proto.Buffer) (bool, error) {
	m := msg.(*NeuralNetworkPreprocessing)
	switch tag {
	case 10: // preprocessor.scaler
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(NeuralNetworkImageScaler)
		err := b.DecodeMessage(msg)
		m.Preprocessor = &NeuralNetworkPreprocessing_Scaler{msg}
		return true, err
	case 11: // preprocessor.meanImage
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(NeuralNetworkMeanImage)
		err := b.DecodeMessage(msg)
		m.Preprocessor = &NeuralNetworkPreprocessing_MeanImage{msg}
		return true, err
	default:
		return false, nil
	}
}

func _NeuralNetworkPreprocessing_OneofSizer(msg proto.Message) (n int) {
	m := msg.(*NeuralNetworkPreprocessing)
	// preprocessor
	switch x := m.Preprocessor.(type) {
	case *NeuralNetworkPreprocessing_Scaler:
		s := proto.Size(x.Scaler)
		n += proto.SizeVarint(10<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkPreprocessing_MeanImage:
		s := proto.Size(x.MeanImage)
		n += proto.SizeVarint(11<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case nil:
	default:
		panic(fmt.Sprintf("proto: unexpected type %T in oneof", x))
	}
	return n
}

// *
// A rectified linear unit (ReLU) activation function.
//
// This function has the following formula:
//
// .. math::
//     f(x) = \text{max}(0, x)
type ActivationReLU struct {
}

func (m *ActivationReLU) Reset()                    { *m = ActivationReLU{} }
func (m *ActivationReLU) String() string            { return proto.CompactTextString(m) }
func (*ActivationReLU) ProtoMessage()               {}
func (*ActivationReLU) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{4} }

// *
// A leaky rectified linear unit (ReLU) activation function.
//
// This function has the following formula:
//
// .. math::
//     f(x) = \begin{cases}
//             x      & \text{if } x \geq 0 \\
//             \alpha x & \text{if } x < 0
//            \end{cases}
type ActivationLeakyReLU struct {
	Alpha float32 `protobuf:"fixed32,1,opt,name=alpha,proto3" json:"alpha,omitempty"`
}

func (m *ActivationLeakyReLU) Reset()                    { *m = ActivationLeakyReLU{} }
func (m *ActivationLeakyReLU) String() string            { return proto.CompactTextString(m) }
func (*ActivationLeakyReLU) ProtoMessage()               {}
func (*ActivationLeakyReLU) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{5} }

func (m *ActivationLeakyReLU) GetAlpha() float32 {
	if m != nil {
		return m.Alpha
	}
	return 0
}

// *
// A hyperbolic tangent activation function.
//
// This function has the following formula:
//
// .. math::
//     f(x) = \dfrac{1 - e^{-2x}}{1 + e^{-2x}}
type ActivationTanh struct {
}

func (m *ActivationTanh) Reset()                    { *m = ActivationTanh{} }
func (m *ActivationTanh) String() string            { return proto.CompactTextString(m) }
func (*ActivationTanh) ProtoMessage()               {}
func (*ActivationTanh) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{6} }

// *
// A scaled hyperbolic tangent activation function.
//
// This function has the following formula:
//
// .. math::
//     f(x) = \alpha \tanh(\beta x)
type ActivationScaledTanh struct {
	Alpha float32 `protobuf:"fixed32,1,opt,name=alpha,proto3" json:"alpha,omitempty"`
	Beta  float32 `protobuf:"fixed32,2,opt,name=beta,proto3" json:"beta,omitempty"`
}

func (m *ActivationScaledTanh) Reset()         { *m = ActivationScaledTanh{} }
func (m *ActivationScaledTanh) String() string { return proto.CompactTextString(m) }
func (*ActivationScaledTanh) ProtoMessage()    {}
func (*ActivationScaledTanh) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{7}
}

func (m *ActivationScaledTanh) GetAlpha() float32 {
	if m != nil {
		return m.Alpha
	}
	return 0
}

func (m *ActivationScaledTanh) GetBeta() float32 {
	if m != nil {
		return m.Beta
	}
	return 0
}

// *
// A sigmoid activation function.
//
// This function has the following formula:
//
// .. math::
//     f(x) = \dfrac{1}{1 + e^{-x}}
type ActivationSigmoid struct {
}

func (m *ActivationSigmoid) Reset()                    { *m = ActivationSigmoid{} }
func (m *ActivationSigmoid) String() string            { return proto.CompactTextString(m) }
func (*ActivationSigmoid) ProtoMessage()               {}
func (*ActivationSigmoid) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{8} }

// *
// A linear activation function.
//
// This function has the following formula:
//
// .. math::
//     f(x) = \alpha x + \beta
type ActivationLinear struct {
	Alpha float32 `protobuf:"fixed32,1,opt,name=alpha,proto3" json:"alpha,omitempty"`
	Beta  float32 `protobuf:"fixed32,2,opt,name=beta,proto3" json:"beta,omitempty"`
}

func (m *ActivationLinear) Reset()                    { *m = ActivationLinear{} }
func (m *ActivationLinear) String() string            { return proto.CompactTextString(m) }
func (*ActivationLinear) ProtoMessage()               {}
func (*ActivationLinear) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{9} }

func (m *ActivationLinear) GetAlpha() float32 {
	if m != nil {
		return m.Alpha
	}
	return 0
}

func (m *ActivationLinear) GetBeta() float32 {
	if m != nil {
		return m.Beta
	}
	return 0
}

// *
// A hard sigmoid activation function.
//
// This function has the following formula:
//
// .. math::
//     f(x) = \text{min}(\text{max}(\alpha x + \beta, 0), 1)
type ActivationSigmoidHard struct {
	Alpha float32 `protobuf:"fixed32,1,opt,name=alpha,proto3" json:"alpha,omitempty"`
	Beta  float32 `protobuf:"fixed32,2,opt,name=beta,proto3" json:"beta,omitempty"`
}

func (m *ActivationSigmoidHard) Reset()         { *m = ActivationSigmoidHard{} }
func (m *ActivationSigmoidHard) String() string { return proto.CompactTextString(m) }
func (*ActivationSigmoidHard) ProtoMessage()    {}
func (*ActivationSigmoidHard) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{10}
}

func (m *ActivationSigmoidHard) GetAlpha() float32 {
	if m != nil {
		return m.Alpha
	}
	return 0
}

func (m *ActivationSigmoidHard) GetBeta() float32 {
	if m != nil {
		return m.Beta
	}
	return 0
}

// *
// A parameterized rectified linear unit (PReLU) activation function,
// which takes ``[C]`` or ``[C,H,W]`` as an input and
// applies different parameters in each channel dimension
// (shared across the ``H`` and ``W`` components).
//
// This function has the following formula:
//
// .. math::
//    f(x_i) = \begin{cases}
//                 x_i          & \text{if } x_i \geq 0 \\
//                 \alpha_i x_i & \text{if } x_i < 0
//             \end{cases} \;,\;i=1,...,C
type ActivationPReLU struct {
	// parameter of length C or 1.
	// If length is 1, same value is used for all channels
	Alpha *WeightParams `protobuf:"bytes,1,opt,name=alpha" json:"alpha,omitempty"`
}

func (m *ActivationPReLU) Reset()                    { *m = ActivationPReLU{} }
func (m *ActivationPReLU) String() string            { return proto.CompactTextString(m) }
func (*ActivationPReLU) ProtoMessage()               {}
func (*ActivationPReLU) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{11} }

func (m *ActivationPReLU) GetAlpha() *WeightParams {
	if m != nil {
		return m.Alpha
	}
	return nil
}

// *
// An exponential linear unit (ELU) activation function.
//
// This function has the following formula:
//
// .. math::
//     f(x) = \begin{cases}
//             x              & \text{if } x \geq 0 \\
//             \alpha (e^x - 1) & \text{if } x < 0
//            \end{cases}
type ActivationELU struct {
	Alpha float32 `protobuf:"fixed32,1,opt,name=alpha,proto3" json:"alpha,omitempty"`
}

func (m *ActivationELU) Reset()                    { *m = ActivationELU{} }
func (m *ActivationELU) String() string            { return proto.CompactTextString(m) }
func (*ActivationELU) ProtoMessage()               {}
func (*ActivationELU) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{12} }

func (m *ActivationELU) GetAlpha() float32 {
	if m != nil {
		return m.Alpha
	}
	return 0
}

// *
// A thresholded rectified linear unit (ReLU) activation function.
//
// This function has the following formula:
//
// .. math::
//     f(x) = \begin{cases}
//             x & \text{if } x \geq \alpha \\
//             0 & \text{if } x < \alpha
//            \end{cases}
type ActivationThresholdedReLU struct {
	Alpha float32 `protobuf:"fixed32,1,opt,name=alpha,proto3" json:"alpha,omitempty"`
}

func (m *ActivationThresholdedReLU) Reset()         { *m = ActivationThresholdedReLU{} }
func (m *ActivationThresholdedReLU) String() string { return proto.CompactTextString(m) }
func (*ActivationThresholdedReLU) ProtoMessage()    {}
func (*ActivationThresholdedReLU) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{13}
}

func (m *ActivationThresholdedReLU) GetAlpha() float32 {
	if m != nil {
		return m.Alpha
	}
	return 0
}

// *
// A softsign activation function.
//
// This function has the following formula:
//
// .. math::
//     f(x) = \dfrac{x}{1 + |x|}
type ActivationSoftsign struct {
}

func (m *ActivationSoftsign) Reset()                    { *m = ActivationSoftsign{} }
func (m *ActivationSoftsign) String() string            { return proto.CompactTextString(m) }
func (*ActivationSoftsign) ProtoMessage()               {}
func (*ActivationSoftsign) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{14} }

// *
// A softplus activation function.
//
// This function has the following formula:
//
// .. math::
//     f(x) = \text{log}(1 + e^x)
type ActivationSoftplus struct {
}

func (m *ActivationSoftplus) Reset()                    { *m = ActivationSoftplus{} }
func (m *ActivationSoftplus) String() string            { return proto.CompactTextString(m) }
func (*ActivationSoftplus) ProtoMessage()               {}
func (*ActivationSoftplus) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{15} }

// *
// A parametric softplus activation function,
// which takes ``[C]`` or ``[C,H,W]`` as an input and
// applies different parameters in each channel dimension
// (shared across the ``H`` and ``W`` components).
//
// This function has the following formula:
//
// .. math::
//     f(x_i) = \alpha_i \text{log}(1 + e^{\beta_i x_i}) \;,\;i=1,...,C
type ActivationParametricSoftplus struct {
	// If length is 1, same value is used for all channels
	Alpha *WeightParams `protobuf:"bytes,1,opt,name=alpha" json:"alpha,omitempty"`
	Beta  *WeightParams `protobuf:"bytes,2,opt,name=beta" json:"beta,omitempty"`
}

func (m *ActivationParametricSoftplus) Reset()         { *m = ActivationParametricSoftplus{} }
func (m *ActivationParametricSoftplus) String() string { return proto.CompactTextString(m) }
func (*ActivationParametricSoftplus) ProtoMessage()    {}
func (*ActivationParametricSoftplus) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{16}
}

func (m *ActivationParametricSoftplus) GetAlpha() *WeightParams {
	if m != nil {
		return m.Alpha
	}
	return nil
}

func (m *ActivationParametricSoftplus) GetBeta() *WeightParams {
	if m != nil {
		return m.Beta
	}
	return nil
}

type ActivationParams struct {
	// Types that are valid to be assigned to NonlinearityType:
	//	*ActivationParams_Linear
	//	*ActivationParams_ReLU
	//	*ActivationParams_LeakyReLU
	//	*ActivationParams_ThresholdedReLU
	//	*ActivationParams_PReLU
	//	*ActivationParams_Tanh
	//	*ActivationParams_ScaledTanh
	//	*ActivationParams_Sigmoid
	//	*ActivationParams_SigmoidHard
	//	*ActivationParams_ELU
	//	*ActivationParams_Softsign
	//	*ActivationParams_Softplus
	//	*ActivationParams_ParametricSoftplus
	NonlinearityType isActivationParams_NonlinearityType `protobuf_oneof:"NonlinearityType"`
}

func (m *ActivationParams) Reset()                    { *m = ActivationParams{} }
func (m *ActivationParams) String() string            { return proto.CompactTextString(m) }
func (*ActivationParams) ProtoMessage()               {}
func (*ActivationParams) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{17} }

type isActivationParams_NonlinearityType interface {
	isActivationParams_NonlinearityType()
	MarshalTo([]byte) (int, error)
	Size() int
}

type ActivationParams_Linear struct {
	Linear *ActivationLinear `protobuf:"bytes,5,opt,name=linear,oneof"`
}
type ActivationParams_ReLU struct {
	ReLU *ActivationReLU `protobuf:"bytes,10,opt,name=ReLU,oneof"`
}
type ActivationParams_LeakyReLU struct {
	LeakyReLU *ActivationLeakyReLU `protobuf:"bytes,15,opt,name=leakyReLU,oneof"`
}
type ActivationParams_ThresholdedReLU struct {
	ThresholdedReLU *ActivationThresholdedReLU `protobuf:"bytes,20,opt,name=thresholdedReLU,oneof"`
}
type ActivationParams_PReLU struct {
	PReLU *ActivationPReLU `protobuf:"bytes,25,opt,name=PReLU,oneof"`
}
type ActivationParams_Tanh struct {
	Tanh *ActivationTanh `protobuf:"bytes,30,opt,name=tanh,oneof"`
}
type ActivationParams_ScaledTanh struct {
	ScaledTanh *ActivationScaledTanh `protobuf:"bytes,31,opt,name=scaledTanh,oneof"`
}
type ActivationParams_Sigmoid struct {
	Sigmoid *ActivationSigmoid `protobuf:"bytes,40,opt,name=sigmoid,oneof"`
}
type ActivationParams_SigmoidHard struct {
	SigmoidHard *ActivationSigmoidHard `protobuf:"bytes,41,opt,name=sigmoidHard,oneof"`
}
type ActivationParams_ELU struct {
	ELU *ActivationELU `protobuf:"bytes,50,opt,name=ELU,oneof"`
}
type ActivationParams_Softsign struct {
	Softsign *ActivationSoftsign `protobuf:"bytes,60,opt,name=softsign,oneof"`
}
type ActivationParams_Softplus struct {
	Softplus *ActivationSoftplus `protobuf:"bytes,70,opt,name=softplus,oneof"`
}
type ActivationParams_ParametricSoftplus struct {
	ParametricSoftplus *ActivationParametricSoftplus `protobuf:"bytes,71,opt,name=parametricSoftplus,oneof"`
}

func (*ActivationParams_Linear) isActivationParams_NonlinearityType()             {}
func (*ActivationParams_ReLU) isActivationParams_NonlinearityType()               {}
func (*ActivationParams_LeakyReLU) isActivationParams_NonlinearityType()          {}
func (*ActivationParams_ThresholdedReLU) isActivationParams_NonlinearityType()    {}
func (*ActivationParams_PReLU) isActivationParams_NonlinearityType()              {}
func (*ActivationParams_Tanh) isActivationParams_NonlinearityType()               {}
func (*ActivationParams_ScaledTanh) isActivationParams_NonlinearityType()         {}
func (*ActivationParams_Sigmoid) isActivationParams_NonlinearityType()            {}
func (*ActivationParams_SigmoidHard) isActivationParams_NonlinearityType()        {}
func (*ActivationParams_ELU) isActivationParams_NonlinearityType()                {}
func (*ActivationParams_Softsign) isActivationParams_NonlinearityType()           {}
func (*ActivationParams_Softplus) isActivationParams_NonlinearityType()           {}
func (*ActivationParams_ParametricSoftplus) isActivationParams_NonlinearityType() {}

func (m *ActivationParams) GetNonlinearityType() isActivationParams_NonlinearityType {
	if m != nil {
		return m.NonlinearityType
	}
	return nil
}

func (m *ActivationParams) GetLinear() *ActivationLinear {
	if x, ok := m.GetNonlinearityType().(*ActivationParams_Linear); ok {
		return x.Linear
	}
	return nil
}

func (m *ActivationParams) GetReLU() *ActivationReLU {
	if x, ok := m.GetNonlinearityType().(*ActivationParams_ReLU); ok {
		return x.ReLU
	}
	return nil
}

func (m *ActivationParams) GetLeakyReLU() *ActivationLeakyReLU {
	if x, ok := m.GetNonlinearityType().(*ActivationParams_LeakyReLU); ok {
		return x.LeakyReLU
	}
	return nil
}

func (m *ActivationParams) GetThresholdedReLU() *ActivationThresholdedReLU {
	if x, ok := m.GetNonlinearityType().(*ActivationParams_ThresholdedReLU); ok {
		return x.ThresholdedReLU
	}
	return nil
}

func (m *ActivationParams) GetPReLU() *ActivationPReLU {
	if x, ok := m.GetNonlinearityType().(*ActivationParams_PReLU); ok {
		return x.PReLU
	}
	return nil
}

func (m *ActivationParams) GetTanh() *ActivationTanh {
	if x, ok := m.GetNonlinearityType().(*ActivationParams_Tanh); ok {
		return x.Tanh
	}
	return nil
}

func (m *ActivationParams) GetScaledTanh() *ActivationScaledTanh {
	if x, ok := m.GetNonlinearityType().(*ActivationParams_ScaledTanh); ok {
		return x.ScaledTanh
	}
	return nil
}

func (m *ActivationParams) GetSigmoid() *ActivationSigmoid {
	if x, ok := m.GetNonlinearityType().(*ActivationParams_Sigmoid); ok {
		return x.Sigmoid
	}
	return nil
}

func (m *ActivationParams) GetSigmoidHard() *ActivationSigmoidHard {
	if x, ok := m.GetNonlinearityType().(*ActivationParams_SigmoidHard); ok {
		return x.SigmoidHard
	}
	return nil
}

func (m *ActivationParams) GetELU() *ActivationELU {
	if x, ok := m.GetNonlinearityType().(*ActivationParams_ELU); ok {
		return x.ELU
	}
	return nil
}

func (m *ActivationParams) GetSoftsign() *ActivationSoftsign {
	if x, ok := m.GetNonlinearityType().(*ActivationParams_Softsign); ok {
		return x.Softsign
	}
	return nil
}

func (m *ActivationParams) GetSoftplus() *ActivationSoftplus {
	if x, ok := m.GetNonlinearityType().(*ActivationParams_Softplus); ok {
		return x.Softplus
	}
	return nil
}

func (m *ActivationParams) GetParametricSoftplus() *ActivationParametricSoftplus {
	if x, ok := m.GetNonlinearityType().(*ActivationParams_ParametricSoftplus); ok {
		return x.ParametricSoftplus
	}
	return nil
}

// XXX_OneofFuncs is for the internal use of the proto package.
func (*ActivationParams) XXX_OneofFuncs() (func(msg proto.Message, b *proto.Buffer) error, func(msg proto.Message, tag, wire int, b *proto.Buffer) (bool, error), func(msg proto.Message) (n int), []interface{}) {
	return _ActivationParams_OneofMarshaler, _ActivationParams_OneofUnmarshaler, _ActivationParams_OneofSizer, []interface{}{
		(*ActivationParams_Linear)(nil),
		(*ActivationParams_ReLU)(nil),
		(*ActivationParams_LeakyReLU)(nil),
		(*ActivationParams_ThresholdedReLU)(nil),
		(*ActivationParams_PReLU)(nil),
		(*ActivationParams_Tanh)(nil),
		(*ActivationParams_ScaledTanh)(nil),
		(*ActivationParams_Sigmoid)(nil),
		(*ActivationParams_SigmoidHard)(nil),
		(*ActivationParams_ELU)(nil),
		(*ActivationParams_Softsign)(nil),
		(*ActivationParams_Softplus)(nil),
		(*ActivationParams_ParametricSoftplus)(nil),
	}
}

func _ActivationParams_OneofMarshaler(msg proto.Message, b *proto.Buffer) error {
	m := msg.(*ActivationParams)
	// NonlinearityType
	switch x := m.NonlinearityType.(type) {
	case *ActivationParams_Linear:
		_ = b.EncodeVarint(5<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Linear); err != nil {
			return err
		}
	case *ActivationParams_ReLU:
		_ = b.EncodeVarint(10<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.ReLU); err != nil {
			return err
		}
	case *ActivationParams_LeakyReLU:
		_ = b.EncodeVarint(15<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.LeakyReLU); err != nil {
			return err
		}
	case *ActivationParams_ThresholdedReLU:
		_ = b.EncodeVarint(20<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.ThresholdedReLU); err != nil {
			return err
		}
	case *ActivationParams_PReLU:
		_ = b.EncodeVarint(25<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.PReLU); err != nil {
			return err
		}
	case *ActivationParams_Tanh:
		_ = b.EncodeVarint(30<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Tanh); err != nil {
			return err
		}
	case *ActivationParams_ScaledTanh:
		_ = b.EncodeVarint(31<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.ScaledTanh); err != nil {
			return err
		}
	case *ActivationParams_Sigmoid:
		_ = b.EncodeVarint(40<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Sigmoid); err != nil {
			return err
		}
	case *ActivationParams_SigmoidHard:
		_ = b.EncodeVarint(41<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.SigmoidHard); err != nil {
			return err
		}
	case *ActivationParams_ELU:
		_ = b.EncodeVarint(50<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.ELU); err != nil {
			return err
		}
	case *ActivationParams_Softsign:
		_ = b.EncodeVarint(60<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Softsign); err != nil {
			return err
		}
	case *ActivationParams_Softplus:
		_ = b.EncodeVarint(70<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Softplus); err != nil {
			return err
		}
	case *ActivationParams_ParametricSoftplus:
		_ = b.EncodeVarint(71<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.ParametricSoftplus); err != nil {
			return err
		}
	case nil:
	default:
		return fmt.Errorf("ActivationParams.NonlinearityType has unexpected type %T", x)
	}
	return nil
}

func _ActivationParams_OneofUnmarshaler(msg proto.Message, tag, wire int, b *proto.Buffer) (bool, error) {
	m := msg.(*ActivationParams)
	switch tag {
	case 5: // NonlinearityType.linear
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(ActivationLinear)
		err := b.DecodeMessage(msg)
		m.NonlinearityType = &ActivationParams_Linear{msg}
		return true, err
	case 10: // NonlinearityType.ReLU
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(ActivationReLU)
		err := b.DecodeMessage(msg)
		m.NonlinearityType = &ActivationParams_ReLU{msg}
		return true, err
	case 15: // NonlinearityType.leakyReLU
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(ActivationLeakyReLU)
		err := b.DecodeMessage(msg)
		m.NonlinearityType = &ActivationParams_LeakyReLU{msg}
		return true, err
	case 20: // NonlinearityType.thresholdedReLU
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(ActivationThresholdedReLU)
		err := b.DecodeMessage(msg)
		m.NonlinearityType = &ActivationParams_ThresholdedReLU{msg}
		return true, err
	case 25: // NonlinearityType.PReLU
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(ActivationPReLU)
		err := b.DecodeMessage(msg)
		m.NonlinearityType = &ActivationParams_PReLU{msg}
		return true, err
	case 30: // NonlinearityType.tanh
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(ActivationTanh)
		err := b.DecodeMessage(msg)
		m.NonlinearityType = &ActivationParams_Tanh{msg}
		return true, err
	case 31: // NonlinearityType.scaledTanh
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(ActivationScaledTanh)
		err := b.DecodeMessage(msg)
		m.NonlinearityType = &ActivationParams_ScaledTanh{msg}
		return true, err
	case 40: // NonlinearityType.sigmoid
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(ActivationSigmoid)
		err := b.DecodeMessage(msg)
		m.NonlinearityType = &ActivationParams_Sigmoid{msg}
		return true, err
	case 41: // NonlinearityType.sigmoidHard
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(ActivationSigmoidHard)
		err := b.DecodeMessage(msg)
		m.NonlinearityType = &ActivationParams_SigmoidHard{msg}
		return true, err
	case 50: // NonlinearityType.ELU
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(ActivationELU)
		err := b.DecodeMessage(msg)
		m.NonlinearityType = &ActivationParams_ELU{msg}
		return true, err
	case 60: // NonlinearityType.softsign
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(ActivationSoftsign)
		err := b.DecodeMessage(msg)
		m.NonlinearityType = &ActivationParams_Softsign{msg}
		return true, err
	case 70: // NonlinearityType.softplus
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(ActivationSoftplus)
		err := b.DecodeMessage(msg)
		m.NonlinearityType = &ActivationParams_Softplus{msg}
		return true, err
	case 71: // NonlinearityType.parametricSoftplus
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(ActivationParametricSoftplus)
		err := b.DecodeMessage(msg)
		m.NonlinearityType = &ActivationParams_ParametricSoftplus{msg}
		return true, err
	default:
		return false, nil
	}
}

func _ActivationParams_OneofSizer(msg proto.Message) (n int) {
	m := msg.(*ActivationParams)
	// NonlinearityType
	switch x := m.NonlinearityType.(type) {
	case *ActivationParams_Linear:
		s := proto.Size(x.Linear)
		n += proto.SizeVarint(5<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *ActivationParams_ReLU:
		s := proto.Size(x.ReLU)
		n += proto.SizeVarint(10<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *ActivationParams_LeakyReLU:
		s := proto.Size(x.LeakyReLU)
		n += proto.SizeVarint(15<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *ActivationParams_ThresholdedReLU:
		s := proto.Size(x.ThresholdedReLU)
		n += proto.SizeVarint(20<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *ActivationParams_PReLU:
		s := proto.Size(x.PReLU)
		n += proto.SizeVarint(25<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *ActivationParams_Tanh:
		s := proto.Size(x.Tanh)
		n += proto.SizeVarint(30<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *ActivationParams_ScaledTanh:
		s := proto.Size(x.ScaledTanh)
		n += proto.SizeVarint(31<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *ActivationParams_Sigmoid:
		s := proto.Size(x.Sigmoid)
		n += proto.SizeVarint(40<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *ActivationParams_SigmoidHard:
		s := proto.Size(x.SigmoidHard)
		n += proto.SizeVarint(41<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *ActivationParams_ELU:
		s := proto.Size(x.ELU)
		n += proto.SizeVarint(50<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *ActivationParams_Softsign:
		s := proto.Size(x.Softsign)
		n += proto.SizeVarint(60<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *ActivationParams_Softplus:
		s := proto.Size(x.Softplus)
		n += proto.SizeVarint(70<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *ActivationParams_ParametricSoftplus:
		s := proto.Size(x.ParametricSoftplus)
		n += proto.SizeVarint(71<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case nil:
	default:
		panic(fmt.Sprintf("proto: unexpected type %T in oneof", x))
	}
	return n
}

// *
// A single neural network layer.
type NeuralNetworkLayer struct {
	Name   string   `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	Input  []string `protobuf:"bytes,2,rep,name=input" json:"input,omitempty"`
	Output []string `protobuf:"bytes,3,rep,name=output" json:"output,omitempty"`
	// Types that are valid to be assigned to Layer:
	//	*NeuralNetworkLayer_Convolution
	//	*NeuralNetworkLayer_Pooling
	//	*NeuralNetworkLayer_Activation
	//	*NeuralNetworkLayer_InnerProduct
	//	*NeuralNetworkLayer_Embedding
	//	*NeuralNetworkLayer_Batchnorm
	//	*NeuralNetworkLayer_Mvn
	//	*NeuralNetworkLayer_L2Normalize
	//	*NeuralNetworkLayer_Softmax
	//	*NeuralNetworkLayer_Lrn
	//	*NeuralNetworkLayer_Crop
	//	*NeuralNetworkLayer_Padding
	//	*NeuralNetworkLayer_Upsample
	//	*NeuralNetworkLayer_Unary
	//	*NeuralNetworkLayer_Add
	//	*NeuralNetworkLayer_Multiply
	//	*NeuralNetworkLayer_Average
	//	*NeuralNetworkLayer_Scale
	//	*NeuralNetworkLayer_Bias
	//	*NeuralNetworkLayer_Max
	//	*NeuralNetworkLayer_Min
	//	*NeuralNetworkLayer_Dot
	//	*NeuralNetworkLayer_Reduce
	//	*NeuralNetworkLayer_LoadConstant
	//	*NeuralNetworkLayer_Reshape
	//	*NeuralNetworkLayer_Flatten
	//	*NeuralNetworkLayer_Permute
	//	*NeuralNetworkLayer_Concat
	//	*NeuralNetworkLayer_Split
	//	*NeuralNetworkLayer_SequenceRepeat
	//	*NeuralNetworkLayer_SimpleRecurrent
	//	*NeuralNetworkLayer_Gru
	//	*NeuralNetworkLayer_UniDirectionalLSTM
	//	*NeuralNetworkLayer_BiDirectionalLSTM
	Layer isNeuralNetworkLayer_Layer `protobuf_oneof:"layer"`
}

func (m *NeuralNetworkLayer) Reset()                    { *m = NeuralNetworkLayer{} }
func (m *NeuralNetworkLayer) String() string            { return proto.CompactTextString(m) }
func (*NeuralNetworkLayer) ProtoMessage()               {}
func (*NeuralNetworkLayer) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{18} }

type isNeuralNetworkLayer_Layer interface {
	isNeuralNetworkLayer_Layer()
	MarshalTo([]byte) (int, error)
	Size() int
}

type NeuralNetworkLayer_Convolution struct {
	Convolution *ConvolutionLayerParams `protobuf:"bytes,100,opt,name=convolution,oneof"`
}
type NeuralNetworkLayer_Pooling struct {
	Pooling *PoolingLayerParams `protobuf:"bytes,120,opt,name=pooling,oneof"`
}
type NeuralNetworkLayer_Activation struct {
	Activation *ActivationParams `protobuf:"bytes,130,opt,name=activation,oneof"`
}
type NeuralNetworkLayer_InnerProduct struct {
	InnerProduct *InnerProductLayerParams `protobuf:"bytes,140,opt,name=innerProduct,oneof"`
}
type NeuralNetworkLayer_Embedding struct {
	Embedding *EmbeddingLayerParams `protobuf:"bytes,150,opt,name=embedding,oneof"`
}
type NeuralNetworkLayer_Batchnorm struct {
	Batchnorm *BatchnormLayerParams `protobuf:"bytes,160,opt,name=batchnorm,oneof"`
}
type NeuralNetworkLayer_Mvn struct {
	Mvn *MeanVarianceNormalizeLayerParams `protobuf:"bytes,165,opt,name=mvn,oneof"`
}
type NeuralNetworkLayer_L2Normalize struct {
	L2Normalize *L2NormalizeLayerParams `protobuf:"bytes,170,opt,name=l2normalize,oneof"`
}
type NeuralNetworkLayer_Softmax struct {
	Softmax *SoftmaxLayerParams `protobuf:"bytes,175,opt,name=softmax,oneof"`
}
type NeuralNetworkLayer_Lrn struct {
	Lrn *LRNLayerParams `protobuf:"bytes,180,opt,name=lrn,oneof"`
}
type NeuralNetworkLayer_Crop struct {
	Crop *CropLayerParams `protobuf:"bytes,190,opt,name=crop,oneof"`
}
type NeuralNetworkLayer_Padding struct {
	Padding *PaddingLayerParams `protobuf:"bytes,200,opt,name=padding,oneof"`
}
type NeuralNetworkLayer_Upsample struct {
	Upsample *UpsampleLayerParams `protobuf:"bytes,210,opt,name=upsample,oneof"`
}
type NeuralNetworkLayer_Unary struct {
	Unary *UnaryFunctionLayerParams `protobuf:"bytes,220,opt,name=unary,oneof"`
}
type NeuralNetworkLayer_Add struct {
	Add *AddLayerParams `protobuf:"bytes,230,opt,name=add,oneof"`
}
type NeuralNetworkLayer_Multiply struct {
	Multiply *MultiplyLayerParams `protobuf:"bytes,231,opt,name=multiply,oneof"`
}
type NeuralNetworkLayer_Average struct {
	Average *AverageLayerParams `protobuf:"bytes,240,opt,name=average,oneof"`
}
type NeuralNetworkLayer_Scale struct {
	Scale *ScaleLayerParams `protobuf:"bytes,245,opt,name=scale,oneof"`
}
type NeuralNetworkLayer_Bias struct {
	Bias *BiasLayerParams `protobuf:"bytes,250,opt,name=bias,oneof"`
}
type NeuralNetworkLayer_Max struct {
	Max *MaxLayerParams `protobuf:"bytes,260,opt,name=max,oneof"`
}
type NeuralNetworkLayer_Min struct {
	Min *MinLayerParams `protobuf:"bytes,261,opt,name=min,oneof"`
}
type NeuralNetworkLayer_Dot struct {
	Dot *DotProductLayerParams `protobuf:"bytes,270,opt,name=dot,oneof"`
}
type NeuralNetworkLayer_Reduce struct {
	Reduce *ReduceLayerParams `protobuf:"bytes,280,opt,name=reduce,oneof"`
}
type NeuralNetworkLayer_LoadConstant struct {
	LoadConstant *LoadConstantLayerParams `protobuf:"bytes,290,opt,name=loadConstant,oneof"`
}
type NeuralNetworkLayer_Reshape struct {
	Reshape *ReshapeLayerParams `protobuf:"bytes,300,opt,name=reshape,oneof"`
}
type NeuralNetworkLayer_Flatten struct {
	Flatten *FlattenLayerParams `protobuf:"bytes,301,opt,name=flatten,oneof"`
}
type NeuralNetworkLayer_Permute struct {
	Permute *PermuteLayerParams `protobuf:"bytes,310,opt,name=permute,oneof"`
}
type NeuralNetworkLayer_Concat struct {
	Concat *ConcatLayerParams `protobuf:"bytes,320,opt,name=concat,oneof"`
}
type NeuralNetworkLayer_Split struct {
	Split *SplitLayerParams `protobuf:"bytes,330,opt,name=split,oneof"`
}
type NeuralNetworkLayer_SequenceRepeat struct {
	SequenceRepeat *SequenceRepeatLayerParams `protobuf:"bytes,340,opt,name=sequenceRepeat,oneof"`
}
type NeuralNetworkLayer_SimpleRecurrent struct {
	SimpleRecurrent *SimpleRecurrentLayerParams `protobuf:"bytes,400,opt,name=simpleRecurrent,oneof"`
}
type NeuralNetworkLayer_Gru struct {
	Gru *GRULayerParams `protobuf:"bytes,410,opt,name=gru,oneof"`
}
type NeuralNetworkLayer_UniDirectionalLSTM struct {
	UniDirectionalLSTM *UniDirectionalLSTMLayerParams `protobuf:"bytes,420,opt,name=uniDirectionalLSTM,oneof"`
}
type NeuralNetworkLayer_BiDirectionalLSTM struct {
	BiDirectionalLSTM *BiDirectionalLSTMLayerParams `protobuf:"bytes,430,opt,name=biDirectionalLSTM,oneof"`
}

func (*NeuralNetworkLayer_Convolution) isNeuralNetworkLayer_Layer()        {}
func (*NeuralNetworkLayer_Pooling) isNeuralNetworkLayer_Layer()            {}
func (*NeuralNetworkLayer_Activation) isNeuralNetworkLayer_Layer()         {}
func (*NeuralNetworkLayer_InnerProduct) isNeuralNetworkLayer_Layer()       {}
func (*NeuralNetworkLayer_Embedding) isNeuralNetworkLayer_Layer()          {}
func (*NeuralNetworkLayer_Batchnorm) isNeuralNetworkLayer_Layer()          {}
func (*NeuralNetworkLayer_Mvn) isNeuralNetworkLayer_Layer()                {}
func (*NeuralNetworkLayer_L2Normalize) isNeuralNetworkLayer_Layer()        {}
func (*NeuralNetworkLayer_Softmax) isNeuralNetworkLayer_Layer()            {}
func (*NeuralNetworkLayer_Lrn) isNeuralNetworkLayer_Layer()                {}
func (*NeuralNetworkLayer_Crop) isNeuralNetworkLayer_Layer()               {}
func (*NeuralNetworkLayer_Padding) isNeuralNetworkLayer_Layer()            {}
func (*NeuralNetworkLayer_Upsample) isNeuralNetworkLayer_Layer()           {}
func (*NeuralNetworkLayer_Unary) isNeuralNetworkLayer_Layer()              {}
func (*NeuralNetworkLayer_Add) isNeuralNetworkLayer_Layer()                {}
func (*NeuralNetworkLayer_Multiply) isNeuralNetworkLayer_Layer()           {}
func (*NeuralNetworkLayer_Average) isNeuralNetworkLayer_Layer()            {}
func (*NeuralNetworkLayer_Scale) isNeuralNetworkLayer_Layer()              {}
func (*NeuralNetworkLayer_Bias) isNeuralNetworkLayer_Layer()               {}
func (*NeuralNetworkLayer_Max) isNeuralNetworkLayer_Layer()                {}
func (*NeuralNetworkLayer_Min) isNeuralNetworkLayer_Layer()                {}
func (*NeuralNetworkLayer_Dot) isNeuralNetworkLayer_Layer()                {}
func (*NeuralNetworkLayer_Reduce) isNeuralNetworkLayer_Layer()             {}
func (*NeuralNetworkLayer_LoadConstant) isNeuralNetworkLayer_Layer()       {}
func (*NeuralNetworkLayer_Reshape) isNeuralNetworkLayer_Layer()            {}
func (*NeuralNetworkLayer_Flatten) isNeuralNetworkLayer_Layer()            {}
func (*NeuralNetworkLayer_Permute) isNeuralNetworkLayer_Layer()            {}
func (*NeuralNetworkLayer_Concat) isNeuralNetworkLayer_Layer()             {}
func (*NeuralNetworkLayer_Split) isNeuralNetworkLayer_Layer()              {}
func (*NeuralNetworkLayer_SequenceRepeat) isNeuralNetworkLayer_Layer()     {}
func (*NeuralNetworkLayer_SimpleRecurrent) isNeuralNetworkLayer_Layer()    {}
func (*NeuralNetworkLayer_Gru) isNeuralNetworkLayer_Layer()                {}
func (*NeuralNetworkLayer_UniDirectionalLSTM) isNeuralNetworkLayer_Layer() {}
func (*NeuralNetworkLayer_BiDirectionalLSTM) isNeuralNetworkLayer_Layer()  {}

func (m *NeuralNetworkLayer) GetLayer() isNeuralNetworkLayer_Layer {
	if m != nil {
		return m.Layer
	}
	return nil
}

func (m *NeuralNetworkLayer) GetName() string {
	if m != nil {
		return m.Name
	}
	return ""
}

func (m *NeuralNetworkLayer) GetInput() []string {
	if m != nil {
		return m.Input
	}
	return nil
}

func (m *NeuralNetworkLayer) GetOutput() []string {
	if m != nil {
		return m.Output
	}
	return nil
}

func (m *NeuralNetworkLayer) GetConvolution() *ConvolutionLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Convolution); ok {
		return x.Convolution
	}
	return nil
}

func (m *NeuralNetworkLayer) GetPooling() *PoolingLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Pooling); ok {
		return x.Pooling
	}
	return nil
}

func (m *NeuralNetworkLayer) GetActivation() *ActivationParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Activation); ok {
		return x.Activation
	}
	return nil
}

func (m *NeuralNetworkLayer) GetInnerProduct() *InnerProductLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_InnerProduct); ok {
		return x.InnerProduct
	}
	return nil
}

func (m *NeuralNetworkLayer) GetEmbedding() *EmbeddingLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Embedding); ok {
		return x.Embedding
	}
	return nil
}

func (m *NeuralNetworkLayer) GetBatchnorm() *BatchnormLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Batchnorm); ok {
		return x.Batchnorm
	}
	return nil
}

func (m *NeuralNetworkLayer) GetMvn() *MeanVarianceNormalizeLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Mvn); ok {
		return x.Mvn
	}
	return nil
}

func (m *NeuralNetworkLayer) GetL2Normalize() *L2NormalizeLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_L2Normalize); ok {
		return x.L2Normalize
	}
	return nil
}

func (m *NeuralNetworkLayer) GetSoftmax() *SoftmaxLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Softmax); ok {
		return x.Softmax
	}
	return nil
}

func (m *NeuralNetworkLayer) GetLrn() *LRNLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Lrn); ok {
		return x.Lrn
	}
	return nil
}

func (m *NeuralNetworkLayer) GetCrop() *CropLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Crop); ok {
		return x.Crop
	}
	return nil
}

func (m *NeuralNetworkLayer) GetPadding() *PaddingLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Padding); ok {
		return x.Padding
	}
	return nil
}

func (m *NeuralNetworkLayer) GetUpsample() *UpsampleLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Upsample); ok {
		return x.Upsample
	}
	return nil
}

func (m *NeuralNetworkLayer) GetUnary() *UnaryFunctionLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Unary); ok {
		return x.Unary
	}
	return nil
}

func (m *NeuralNetworkLayer) GetAdd() *AddLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Add); ok {
		return x.Add
	}
	return nil
}

func (m *NeuralNetworkLayer) GetMultiply() *MultiplyLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Multiply); ok {
		return x.Multiply
	}
	return nil
}

func (m *NeuralNetworkLayer) GetAverage() *AverageLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Average); ok {
		return x.Average
	}
	return nil
}

func (m *NeuralNetworkLayer) GetScale() *ScaleLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Scale); ok {
		return x.Scale
	}
	return nil
}

func (m *NeuralNetworkLayer) GetBias() *BiasLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Bias); ok {
		return x.Bias
	}
	return nil
}

func (m *NeuralNetworkLayer) GetMax() *MaxLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Max); ok {
		return x.Max
	}
	return nil
}

func (m *NeuralNetworkLayer) GetMin() *MinLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Min); ok {
		return x.Min
	}
	return nil
}

func (m *NeuralNetworkLayer) GetDot() *DotProductLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Dot); ok {
		return x.Dot
	}
	return nil
}

func (m *NeuralNetworkLayer) GetReduce() *ReduceLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Reduce); ok {
		return x.Reduce
	}
	return nil
}

func (m *NeuralNetworkLayer) GetLoadConstant() *LoadConstantLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_LoadConstant); ok {
		return x.LoadConstant
	}
	return nil
}

func (m *NeuralNetworkLayer) GetReshape() *ReshapeLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Reshape); ok {
		return x.Reshape
	}
	return nil
}

func (m *NeuralNetworkLayer) GetFlatten() *FlattenLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Flatten); ok {
		return x.Flatten
	}
	return nil
}

func (m *NeuralNetworkLayer) GetPermute() *PermuteLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Permute); ok {
		return x.Permute
	}
	return nil
}

func (m *NeuralNetworkLayer) GetConcat() *ConcatLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Concat); ok {
		return x.Concat
	}
	return nil
}

func (m *NeuralNetworkLayer) GetSplit() *SplitLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Split); ok {
		return x.Split
	}
	return nil
}

func (m *NeuralNetworkLayer) GetSequenceRepeat() *SequenceRepeatLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_SequenceRepeat); ok {
		return x.SequenceRepeat
	}
	return nil
}

func (m *NeuralNetworkLayer) GetSimpleRecurrent() *SimpleRecurrentLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_SimpleRecurrent); ok {
		return x.SimpleRecurrent
	}
	return nil
}

func (m *NeuralNetworkLayer) GetGru() *GRULayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_Gru); ok {
		return x.Gru
	}
	return nil
}

func (m *NeuralNetworkLayer) GetUniDirectionalLSTM() *UniDirectionalLSTMLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_UniDirectionalLSTM); ok {
		return x.UniDirectionalLSTM
	}
	return nil
}

func (m *NeuralNetworkLayer) GetBiDirectionalLSTM() *BiDirectionalLSTMLayerParams {
	if x, ok := m.GetLayer().(*NeuralNetworkLayer_BiDirectionalLSTM); ok {
		return x.BiDirectionalLSTM
	}
	return nil
}

// XXX_OneofFuncs is for the internal use of the proto package.
func (*NeuralNetworkLayer) XXX_OneofFuncs() (func(msg proto.Message, b *proto.Buffer) error, func(msg proto.Message, tag, wire int, b *proto.Buffer) (bool, error), func(msg proto.Message) (n int), []interface{}) {
	return _NeuralNetworkLayer_OneofMarshaler, _NeuralNetworkLayer_OneofUnmarshaler, _NeuralNetworkLayer_OneofSizer, []interface{}{
		(*NeuralNetworkLayer_Convolution)(nil),
		(*NeuralNetworkLayer_Pooling)(nil),
		(*NeuralNetworkLayer_Activation)(nil),
		(*NeuralNetworkLayer_InnerProduct)(nil),
		(*NeuralNetworkLayer_Embedding)(nil),
		(*NeuralNetworkLayer_Batchnorm)(nil),
		(*NeuralNetworkLayer_Mvn)(nil),
		(*NeuralNetworkLayer_L2Normalize)(nil),
		(*NeuralNetworkLayer_Softmax)(nil),
		(*NeuralNetworkLayer_Lrn)(nil),
		(*NeuralNetworkLayer_Crop)(nil),
		(*NeuralNetworkLayer_Padding)(nil),
		(*NeuralNetworkLayer_Upsample)(nil),
		(*NeuralNetworkLayer_Unary)(nil),
		(*NeuralNetworkLayer_Add)(nil),
		(*NeuralNetworkLayer_Multiply)(nil),
		(*NeuralNetworkLayer_Average)(nil),
		(*NeuralNetworkLayer_Scale)(nil),
		(*NeuralNetworkLayer_Bias)(nil),
		(*NeuralNetworkLayer_Max)(nil),
		(*NeuralNetworkLayer_Min)(nil),
		(*NeuralNetworkLayer_Dot)(nil),
		(*NeuralNetworkLayer_Reduce)(nil),
		(*NeuralNetworkLayer_LoadConstant)(nil),
		(*NeuralNetworkLayer_Reshape)(nil),
		(*NeuralNetworkLayer_Flatten)(nil),
		(*NeuralNetworkLayer_Permute)(nil),
		(*NeuralNetworkLayer_Concat)(nil),
		(*NeuralNetworkLayer_Split)(nil),
		(*NeuralNetworkLayer_SequenceRepeat)(nil),
		(*NeuralNetworkLayer_SimpleRecurrent)(nil),
		(*NeuralNetworkLayer_Gru)(nil),
		(*NeuralNetworkLayer_UniDirectionalLSTM)(nil),
		(*NeuralNetworkLayer_BiDirectionalLSTM)(nil),
	}
}

func _NeuralNetworkLayer_OneofMarshaler(msg proto.Message, b *proto.Buffer) error {
	m := msg.(*NeuralNetworkLayer)
	// layer
	switch x := m.Layer.(type) {
	case *NeuralNetworkLayer_Convolution:
		_ = b.EncodeVarint(100<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Convolution); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Pooling:
		_ = b.EncodeVarint(120<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Pooling); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Activation:
		_ = b.EncodeVarint(130<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Activation); err != nil {
			return err
		}
	case *NeuralNetworkLayer_InnerProduct:
		_ = b.EncodeVarint(140<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.InnerProduct); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Embedding:
		_ = b.EncodeVarint(150<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Embedding); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Batchnorm:
		_ = b.EncodeVarint(160<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Batchnorm); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Mvn:
		_ = b.EncodeVarint(165<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Mvn); err != nil {
			return err
		}
	case *NeuralNetworkLayer_L2Normalize:
		_ = b.EncodeVarint(170<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.L2Normalize); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Softmax:
		_ = b.EncodeVarint(175<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Softmax); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Lrn:
		_ = b.EncodeVarint(180<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Lrn); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Crop:
		_ = b.EncodeVarint(190<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Crop); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Padding:
		_ = b.EncodeVarint(200<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Padding); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Upsample:
		_ = b.EncodeVarint(210<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Upsample); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Unary:
		_ = b.EncodeVarint(220<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Unary); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Add:
		_ = b.EncodeVarint(230<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Add); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Multiply:
		_ = b.EncodeVarint(231<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Multiply); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Average:
		_ = b.EncodeVarint(240<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Average); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Scale:
		_ = b.EncodeVarint(245<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Scale); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Bias:
		_ = b.EncodeVarint(250<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Bias); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Max:
		_ = b.EncodeVarint(260<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Max); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Min:
		_ = b.EncodeVarint(261<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Min); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Dot:
		_ = b.EncodeVarint(270<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Dot); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Reduce:
		_ = b.EncodeVarint(280<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Reduce); err != nil {
			return err
		}
	case *NeuralNetworkLayer_LoadConstant:
		_ = b.EncodeVarint(290<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.LoadConstant); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Reshape:
		_ = b.EncodeVarint(300<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Reshape); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Flatten:
		_ = b.EncodeVarint(301<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Flatten); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Permute:
		_ = b.EncodeVarint(310<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Permute); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Concat:
		_ = b.EncodeVarint(320<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Concat); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Split:
		_ = b.EncodeVarint(330<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Split); err != nil {
			return err
		}
	case *NeuralNetworkLayer_SequenceRepeat:
		_ = b.EncodeVarint(340<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.SequenceRepeat); err != nil {
			return err
		}
	case *NeuralNetworkLayer_SimpleRecurrent:
		_ = b.EncodeVarint(400<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.SimpleRecurrent); err != nil {
			return err
		}
	case *NeuralNetworkLayer_Gru:
		_ = b.EncodeVarint(410<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Gru); err != nil {
			return err
		}
	case *NeuralNetworkLayer_UniDirectionalLSTM:
		_ = b.EncodeVarint(420<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.UniDirectionalLSTM); err != nil {
			return err
		}
	case *NeuralNetworkLayer_BiDirectionalLSTM:
		_ = b.EncodeVarint(430<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.BiDirectionalLSTM); err != nil {
			return err
		}
	case nil:
	default:
		return fmt.Errorf("NeuralNetworkLayer.Layer has unexpected type %T", x)
	}
	return nil
}

func _NeuralNetworkLayer_OneofUnmarshaler(msg proto.Message, tag, wire int, b *proto.Buffer) (bool, error) {
	m := msg.(*NeuralNetworkLayer)
	switch tag {
	case 100: // layer.convolution
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(ConvolutionLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Convolution{msg}
		return true, err
	case 120: // layer.pooling
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(PoolingLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Pooling{msg}
		return true, err
	case 130: // layer.activation
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(ActivationParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Activation{msg}
		return true, err
	case 140: // layer.innerProduct
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(InnerProductLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_InnerProduct{msg}
		return true, err
	case 150: // layer.embedding
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(EmbeddingLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Embedding{msg}
		return true, err
	case 160: // layer.batchnorm
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(BatchnormLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Batchnorm{msg}
		return true, err
	case 165: // layer.mvn
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(MeanVarianceNormalizeLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Mvn{msg}
		return true, err
	case 170: // layer.l2normalize
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(L2NormalizeLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_L2Normalize{msg}
		return true, err
	case 175: // layer.softmax
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(SoftmaxLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Softmax{msg}
		return true, err
	case 180: // layer.lrn
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(LRNLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Lrn{msg}
		return true, err
	case 190: // layer.crop
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(CropLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Crop{msg}
		return true, err
	case 200: // layer.padding
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(PaddingLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Padding{msg}
		return true, err
	case 210: // layer.upsample
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(UpsampleLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Upsample{msg}
		return true, err
	case 220: // layer.unary
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(UnaryFunctionLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Unary{msg}
		return true, err
	case 230: // layer.add
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(AddLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Add{msg}
		return true, err
	case 231: // layer.multiply
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(MultiplyLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Multiply{msg}
		return true, err
	case 240: // layer.average
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(AverageLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Average{msg}
		return true, err
	case 245: // layer.scale
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(ScaleLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Scale{msg}
		return true, err
	case 250: // layer.bias
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(BiasLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Bias{msg}
		return true, err
	case 260: // layer.max
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(MaxLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Max{msg}
		return true, err
	case 261: // layer.min
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(MinLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Min{msg}
		return true, err
	case 270: // layer.dot
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(DotProductLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Dot{msg}
		return true, err
	case 280: // layer.reduce
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(ReduceLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Reduce{msg}
		return true, err
	case 290: // layer.loadConstant
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(LoadConstantLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_LoadConstant{msg}
		return true, err
	case 300: // layer.reshape
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(ReshapeLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Reshape{msg}
		return true, err
	case 301: // layer.flatten
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(FlattenLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Flatten{msg}
		return true, err
	case 310: // layer.permute
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(PermuteLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Permute{msg}
		return true, err
	case 320: // layer.concat
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(ConcatLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Concat{msg}
		return true, err
	case 330: // layer.split
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(SplitLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Split{msg}
		return true, err
	case 340: // layer.sequenceRepeat
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(SequenceRepeatLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_SequenceRepeat{msg}
		return true, err
	case 400: // layer.simpleRecurrent
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(SimpleRecurrentLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_SimpleRecurrent{msg}
		return true, err
	case 410: // layer.gru
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(GRULayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_Gru{msg}
		return true, err
	case 420: // layer.uniDirectionalLSTM
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(UniDirectionalLSTMLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_UniDirectionalLSTM{msg}
		return true, err
	case 430: // layer.biDirectionalLSTM
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(BiDirectionalLSTMLayerParams)
		err := b.DecodeMessage(msg)
		m.Layer = &NeuralNetworkLayer_BiDirectionalLSTM{msg}
		return true, err
	default:
		return false, nil
	}
}

func _NeuralNetworkLayer_OneofSizer(msg proto.Message) (n int) {
	m := msg.(*NeuralNetworkLayer)
	// layer
	switch x := m.Layer.(type) {
	case *NeuralNetworkLayer_Convolution:
		s := proto.Size(x.Convolution)
		n += proto.SizeVarint(100<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Pooling:
		s := proto.Size(x.Pooling)
		n += proto.SizeVarint(120<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Activation:
		s := proto.Size(x.Activation)
		n += proto.SizeVarint(130<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_InnerProduct:
		s := proto.Size(x.InnerProduct)
		n += proto.SizeVarint(140<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Embedding:
		s := proto.Size(x.Embedding)
		n += proto.SizeVarint(150<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Batchnorm:
		s := proto.Size(x.Batchnorm)
		n += proto.SizeVarint(160<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Mvn:
		s := proto.Size(x.Mvn)
		n += proto.SizeVarint(165<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_L2Normalize:
		s := proto.Size(x.L2Normalize)
		n += proto.SizeVarint(170<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Softmax:
		s := proto.Size(x.Softmax)
		n += proto.SizeVarint(175<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Lrn:
		s := proto.Size(x.Lrn)
		n += proto.SizeVarint(180<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Crop:
		s := proto.Size(x.Crop)
		n += proto.SizeVarint(190<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Padding:
		s := proto.Size(x.Padding)
		n += proto.SizeVarint(200<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Upsample:
		s := proto.Size(x.Upsample)
		n += proto.SizeVarint(210<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Unary:
		s := proto.Size(x.Unary)
		n += proto.SizeVarint(220<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Add:
		s := proto.Size(x.Add)
		n += proto.SizeVarint(230<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Multiply:
		s := proto.Size(x.Multiply)
		n += proto.SizeVarint(231<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Average:
		s := proto.Size(x.Average)
		n += proto.SizeVarint(240<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Scale:
		s := proto.Size(x.Scale)
		n += proto.SizeVarint(245<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Bias:
		s := proto.Size(x.Bias)
		n += proto.SizeVarint(250<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Max:
		s := proto.Size(x.Max)
		n += proto.SizeVarint(260<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Min:
		s := proto.Size(x.Min)
		n += proto.SizeVarint(261<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Dot:
		s := proto.Size(x.Dot)
		n += proto.SizeVarint(270<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Reduce:
		s := proto.Size(x.Reduce)
		n += proto.SizeVarint(280<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_LoadConstant:
		s := proto.Size(x.LoadConstant)
		n += proto.SizeVarint(290<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Reshape:
		s := proto.Size(x.Reshape)
		n += proto.SizeVarint(300<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Flatten:
		s := proto.Size(x.Flatten)
		n += proto.SizeVarint(301<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Permute:
		s := proto.Size(x.Permute)
		n += proto.SizeVarint(310<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Concat:
		s := proto.Size(x.Concat)
		n += proto.SizeVarint(320<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Split:
		s := proto.Size(x.Split)
		n += proto.SizeVarint(330<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_SequenceRepeat:
		s := proto.Size(x.SequenceRepeat)
		n += proto.SizeVarint(340<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_SimpleRecurrent:
		s := proto.Size(x.SimpleRecurrent)
		n += proto.SizeVarint(400<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_Gru:
		s := proto.Size(x.Gru)
		n += proto.SizeVarint(410<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_UniDirectionalLSTM:
		s := proto.Size(x.UniDirectionalLSTM)
		n += proto.SizeVarint(420<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkLayer_BiDirectionalLSTM:
		s := proto.Size(x.BiDirectionalLSTM)
		n += proto.SizeVarint(430<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case nil:
	default:
		panic(fmt.Sprintf("proto: unexpected type %T in oneof", x))
	}
	return n
}

// *
// Specifies the amount of spatial border to be either padded or cropped.
//
// For padding:
// ::
//     H_out = borderAmounts[0].startEdgeSize + H_in +
// borderAmounts[0].endEdgeSize W_out = borderAmounts[1].startEdgeSize + W_in +
// borderAmounts[1].endEdgeSize
//
//     topPaddingAmount == Height startEdgeSize
//     bottomPaddingAmount == Height endEdgeSize
//     leftPaddingAmount == Width startEdgeSize
//     rightPaddingAmount == Width endEdgeSize
//
// For cropping:
// ::
//     H_out = (-borderAmounts[0].startEdgeSize) + H_in +
// (-borderAmounts[0].endEdgeSize) W_out = (-borderAmounts[1].startEdgeSize) +
// W_in + (-borderAmounts[1].endEdgeSize)
//
//     topCropAmount == Height startEdgeSize
//     bottomCropAmount == Height endEdgeSize
//     leftCropAmount == Width startEdgeSize
//     rightCropAmount == Width endEdgeSize
type BorderAmounts struct {
	// *
	// The border amounts.
	// This must be length 2 in the order ``[H, W]``.
	BorderAmounts []*BorderAmounts_EdgeSizes `protobuf:"bytes,10,rep,name=borderAmounts" json:"borderAmounts,omitempty"`
}

func (m *BorderAmounts) Reset()                    { *m = BorderAmounts{} }
func (m *BorderAmounts) String() string            { return proto.CompactTextString(m) }
func (*BorderAmounts) ProtoMessage()               {}
func (*BorderAmounts) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{19} }

func (m *BorderAmounts) GetBorderAmounts() []*BorderAmounts_EdgeSizes {
	if m != nil {
		return m.BorderAmounts
	}
	return nil
}

type BorderAmounts_EdgeSizes struct {
	// *
	// The amount to be padded or cropped from the beginning.
	StartEdgeSize uint64 `protobuf:"varint,1,opt,name=startEdgeSize,proto3" json:"startEdgeSize,omitempty"`
	// *
	// The amount to be padded or cropped from the end.
	EndEdgeSize uint64 `protobuf:"varint,2,opt,name=endEdgeSize,proto3" json:"endEdgeSize,omitempty"`
}

func (m *BorderAmounts_EdgeSizes) Reset()         { *m = BorderAmounts_EdgeSizes{} }
func (m *BorderAmounts_EdgeSizes) String() string { return proto.CompactTextString(m) }
func (*BorderAmounts_EdgeSizes) ProtoMessage()    {}
func (*BorderAmounts_EdgeSizes) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{19, 0}
}

func (m *BorderAmounts_EdgeSizes) GetStartEdgeSize() uint64 {
	if m != nil {
		return m.StartEdgeSize
	}
	return 0
}

func (m *BorderAmounts_EdgeSizes) GetEndEdgeSize() uint64 {
	if m != nil {
		return m.EndEdgeSize
	}
	return 0
}

// *
// Specifies the type of padding to be used with Convolution/Deconvolution and
// Pooling layers. After padding, input spatial shape: ``[H_in, W_in]``, gets
// modified to the output spatial shape ``[H_out, W_out]``.
// ::
// 		topPaddingAmount == Height startEdgeSize ==
// borderAmounts[0].startEdgeSize bottomPaddingAmount == Height endEdgeSize ==
// borderAmounts[0].endEdgeSize leftPaddingAmount == Width startEdgeSize ==
// borderAmounts[1].startEdgeSize rightPaddingAmount == Width endEdgeSize ==
// borderAmounts[1].endEdgeSize
//
// With Convolution or Pooling:
// ::
//    H_out = int_division_round_down((H_in + topPaddingAmount +
// bottomPaddingAmount - KernelSize[0]),stride[0]) + 1
//
// which is same as:
// ::
//    H_out = int_division_round_up((H_in + topPaddingAmount +
// bottomPaddingAmount - KernelSize[0] + 1),stride[0])
//
// With Deconvolution:
// ::
//    H_out = (H_in-1) * stride[0] + kernelSize[0] - (topPaddingAmount +
// bottomPaddingAmount)
//
//
// The equivalent expressions hold true for ``W_out`` as well.
//
//
// By default, the values of ``paddingAmounts`` are set to ``0``,
// which results in a "true" valid padding.
// If non-zero values are provided for ``paddingAmounts``,
// "valid" convolution/pooling is performed within the spatially expanded input.
//
type ValidPadding struct {
	PaddingAmounts *BorderAmounts `protobuf:"bytes,1,opt,name=paddingAmounts" json:"paddingAmounts,omitempty"`
}

func (m *ValidPadding) Reset()                    { *m = ValidPadding{} }
func (m *ValidPadding) String() string            { return proto.CompactTextString(m) }
func (*ValidPadding) ProtoMessage()               {}
func (*ValidPadding) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{20} }

func (m *ValidPadding) GetPaddingAmounts() *BorderAmounts {
	if m != nil {
		return m.PaddingAmounts
	}
	return nil
}

// *
// Specifies the type of padding to be used with Convolution/Deconvolution and
// pooling layers. After padding, input spatial shape: ``[H_in, W_in]``, gets
// modified to the output spatial shape ``[H_out, W_out]``. With Convolution or
// pooling:
// ::
// 		H_out = int_division_round_up(H_in,stride[0])
// 		W_out = int_division_round_up(W_in,stride[1])
//
// This is achieved by using the following padding amounts:
// ::
//     totalPaddingHeight = max(0,(H_out-1) * stride[0] + KernelSize[0] - Hin)
//     totalPaddingWidth = max(0,(W_out-1) * stride[1] + KernelSize[1] - Win)
//
// There are two modes of asymmetry:
// ``BOTTOM_RIGHT_HEAVY``, and ``TOP_LEFT_HEAVY``.
//
// If the mode is ``BOTTOM_RIGHT_HEAVY``:
// ::
//     topPaddingAmount = floor(totalPaddingHeight / 2)
//     bottomPaddingAmount = totalPaddingHeight - topPaddingAmount
//     leftPaddingAmount = floor(totalPaddingWidth / 2)
//     rightPaddingAmount = totalPaddingWidth - leftPaddingAmount
//
// If the mode is ``TOP_LEFT_HEAVY``:
// ::
//     bottomPaddingAmount = floor(totalPaddingHeight / 2)
//     topPaddingAmount = totalPaddingHeight - bottomPaddingAmount
//     rightPaddingAmount = floor(totalPaddingWidth / 2)
//     leftPaddingAmount = totalPaddingWidth - rightPaddingAmount
//
//
// With Deconvolution:
// ::
//    H_out = H_in * stride[0]
//    W_out = W_in * stride[1]
type SamePadding struct {
	AsymmetryMode SamePadding_SamePaddingMode `protobuf:"varint,1,opt,name=asymmetryMode,proto3,enum=CoreML.SamePadding_SamePaddingMode" json:"asymmetryMode,omitempty"`
}

func (m *SamePadding) Reset()                    { *m = SamePadding{} }
func (m *SamePadding) String() string            { return proto.CompactTextString(m) }
func (*SamePadding) ProtoMessage()               {}
func (*SamePadding) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{21} }

func (m *SamePadding) GetAsymmetryMode() SamePadding_SamePaddingMode {
	if m != nil {
		return m.AsymmetryMode
	}
	return SamePadding_BOTTOM_RIGHT_HEAVY
}

// *
// Weights for layer parameters.
// Weights are stored as repeated floating point numbers
// using row-major ordering
// and can represent 1-, 2-, 3-, or 4-dimensional data.
type WeightParams struct {
	// *
	// Values specified in single / float / FP32 precision.
	FloatValue []float32 `protobuf:"fixed32,1,rep,packed,name=floatValue" json:"floatValue,omitempty"`
}

func (m *WeightParams) Reset()                    { *m = WeightParams{} }
func (m *WeightParams) String() string            { return proto.CompactTextString(m) }
func (*WeightParams) ProtoMessage()               {}
func (*WeightParams) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{22} }

func (m *WeightParams) GetFloatValue() []float32 {
	if m != nil {
		return m.FloatValue
	}
	return nil
}

// *
// A layer that performs spatial convolution or deconvolution.
// ::
// 		y = ConvolutionLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
//  A blob with shape ``[inputChannels,inputHeight,inputWidth]`` or ``[C_in,
// H_in, W_in]``.
//
// Output
//  A blob with shape ``[outputChannels,outputHeight,outputWidth]`` or
// ``[C_out, H_out, W_out]``.
//
//
// If ``dilationFactor`` is not 1 and ``isDeconvolution`` is not True, effective
// kernel size is modified as follows:
// ::
// 		KernelSize[0] <-- (kernelSize[0]-1) * dilationFactor[0] + 1
// 		KernelSize[1] <-- (kernelSize[1]-1) * dilationFactor[1] + 1
//
// Type of padding can be ``valid`` or ``same``. Output spatial dimensions
// depend on the the type of padding. For details, refer to the descriptions of
// the messages "ValidPadding" and "SamePadding". Padded values are all zeros.
//
// For Deconvolution, ``ConvolutionPaddingType`` (``valid`` or ``same``) is
// ignored when ``outputShape`` is set.
//
//
type ConvolutionLayerParams struct {
	// *
	// The number of kernels.
	// Same as ``C_out`` used in the layer description.
	OutputChannels uint64 `protobuf:"varint,1,opt,name=outputChannels,proto3" json:"outputChannels,omitempty"`
	// *
	// Channel dimension of the kernels.
	// Must be equal to ``inputChannels / nGroups``.
	KernelChannels uint64 `protobuf:"varint,2,opt,name=kernelChannels,proto3" json:"kernelChannels,omitempty"`
	// *
	// Group convolution as used in AlexNet,
	// i.e. weight reuse along channel axis.
	// Kernel channels * nGroups = inputChannels.
	// If not set or 0, it is set to the default value 1.
	NGroups uint64 `protobuf:"varint,10,opt,name=nGroups,proto3" json:"nGroups,omitempty"`
	// *
	// Must be length 2 in the order ``[H, W]``.
	// If not set, default value ``[3, 3]`` is used.
	KernelSize []uint64 `protobuf:"varint,20,rep,packed,name=kernelSize" json:"kernelSize,omitempty"`
	// *
	// Must be length 2 in the order ``[H, W]``.
	// If not set, default value ``[1, 1]`` is used.
	Stride []uint64 `protobuf:"varint,30,rep,packed,name=stride" json:"stride,omitempty"`
	// *
	// Must be length 2 in order ``[H, W]``.
	// If not set, default value ``[1, 1]`` is used.
	// It is ignored if ``isDeconvolution == true``.
	DilationFactor []uint64 `protobuf:"varint,40,rep,packed,name=dilationFactor" json:"dilationFactor,omitempty"`
	// *
	// The type of padding.
	//
	// Types that are valid to be assigned to ConvolutionPaddingType:
	//	*ConvolutionLayerParams_Valid
	//	*ConvolutionLayerParams_Same
	ConvolutionPaddingType isConvolutionLayerParams_ConvolutionPaddingType `protobuf_oneof:"ConvolutionPaddingType"`
	// *
	// Flag to specify whether it is a deconvolution layer.
	IsDeconvolution bool `protobuf:"varint,60,opt,name=isDeconvolution,proto3" json:"isDeconvolution,omitempty"`
	// *
	// Flag to specify whether a bias is to be added or not.
	HasBias bool `protobuf:"varint,70,opt,name=hasBias,proto3" json:"hasBias,omitempty"`
	// *
	// Weights associated with this layer.
	// If convolution (``isDeconvolution == false``), weights have the shape
	// ``[outputChannels, kernelChannels, kernelHeight, kernelWidth]``.
	// If deconvolution (``isDeconvolution == true``) weights have the shape
	// ``[kernelChannels, outputChannels, kernelHeight, kernelWidth]``.
	Weights *WeightParams `protobuf:"bytes,90,opt,name=weights" json:"weights,omitempty"`
	Bias    *WeightParams `protobuf:"bytes,91,opt,name=bias" json:"bias,omitempty"`
	// *
	// The output shape, which has length 2 ``[H_out, W_out]``.
	// This is used only for deconvolution (``isDeconvolution == true``).
	// If not set, the deconvolution output shape is calculated
	// based on ``ConvolutionPaddingType``.
	OutputShape []uint64 `protobuf:"varint,100,rep,packed,name=outputShape" json:"outputShape,omitempty"`
}

func (m *ConvolutionLayerParams) Reset()         { *m = ConvolutionLayerParams{} }
func (m *ConvolutionLayerParams) String() string { return proto.CompactTextString(m) }
func (*ConvolutionLayerParams) ProtoMessage()    {}
func (*ConvolutionLayerParams) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{23}
}

type isConvolutionLayerParams_ConvolutionPaddingType interface {
	isConvolutionLayerParams_ConvolutionPaddingType()
	MarshalTo([]byte) (int, error)
	Size() int
}

type ConvolutionLayerParams_Valid struct {
	Valid *ValidPadding `protobuf:"bytes,50,opt,name=valid,oneof"`
}
type ConvolutionLayerParams_Same struct {
	Same *SamePadding `protobuf:"bytes,51,opt,name=same,oneof"`
}

func (*ConvolutionLayerParams_Valid) isConvolutionLayerParams_ConvolutionPaddingType() {}
func (*ConvolutionLayerParams_Same) isConvolutionLayerParams_ConvolutionPaddingType()  {}

func (m *ConvolutionLayerParams) GetConvolutionPaddingType() isConvolutionLayerParams_ConvolutionPaddingType {
	if m != nil {
		return m.ConvolutionPaddingType
	}
	return nil
}

func (m *ConvolutionLayerParams) GetOutputChannels() uint64 {
	if m != nil {
		return m.OutputChannels
	}
	return 0
}

func (m *ConvolutionLayerParams) GetKernelChannels() uint64 {
	if m != nil {
		return m.KernelChannels
	}
	return 0
}

func (m *ConvolutionLayerParams) GetNGroups() uint64 {
	if m != nil {
		return m.NGroups
	}
	return 0
}

func (m *ConvolutionLayerParams) GetKernelSize() []uint64 {
	if m != nil {
		return m.KernelSize
	}
	return nil
}

func (m *ConvolutionLayerParams) GetStride() []uint64 {
	if m != nil {
		return m.Stride
	}
	return nil
}

func (m *ConvolutionLayerParams) GetDilationFactor() []uint64 {
	if m != nil {
		return m.DilationFactor
	}
	return nil
}

func (m *ConvolutionLayerParams) GetValid() *ValidPadding {
	if x, ok := m.GetConvolutionPaddingType().(*ConvolutionLayerParams_Valid); ok {
		return x.Valid
	}
	return nil
}

func (m *ConvolutionLayerParams) GetSame() *SamePadding {
	if x, ok := m.GetConvolutionPaddingType().(*ConvolutionLayerParams_Same); ok {
		return x.Same
	}
	return nil
}

func (m *ConvolutionLayerParams) GetIsDeconvolution() bool {
	if m != nil {
		return m.IsDeconvolution
	}
	return false
}

func (m *ConvolutionLayerParams) GetHasBias() bool {
	if m != nil {
		return m.HasBias
	}
	return false
}

func (m *ConvolutionLayerParams) GetWeights() *WeightParams {
	if m != nil {
		return m.Weights
	}
	return nil
}

func (m *ConvolutionLayerParams) GetBias() *WeightParams {
	if m != nil {
		return m.Bias
	}
	return nil
}

func (m *ConvolutionLayerParams) GetOutputShape() []uint64 {
	if m != nil {
		return m.OutputShape
	}
	return nil
}

// XXX_OneofFuncs is for the internal use of the proto package.
func (*ConvolutionLayerParams) XXX_OneofFuncs() (func(msg proto.Message, b *proto.Buffer) error, func(msg proto.Message, tag, wire int, b *proto.Buffer) (bool, error), func(msg proto.Message) (n int), []interface{}) {
	return _ConvolutionLayerParams_OneofMarshaler, _ConvolutionLayerParams_OneofUnmarshaler, _ConvolutionLayerParams_OneofSizer, []interface{}{
		(*ConvolutionLayerParams_Valid)(nil),
		(*ConvolutionLayerParams_Same)(nil),
	}
}

func _ConvolutionLayerParams_OneofMarshaler(msg proto.Message, b *proto.Buffer) error {
	m := msg.(*ConvolutionLayerParams)
	// ConvolutionPaddingType
	switch x := m.ConvolutionPaddingType.(type) {
	case *ConvolutionLayerParams_Valid:
		_ = b.EncodeVarint(50<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Valid); err != nil {
			return err
		}
	case *ConvolutionLayerParams_Same:
		_ = b.EncodeVarint(51<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Same); err != nil {
			return err
		}
	case nil:
	default:
		return fmt.Errorf("ConvolutionLayerParams.ConvolutionPaddingType has unexpected type %T", x)
	}
	return nil
}

func _ConvolutionLayerParams_OneofUnmarshaler(msg proto.Message, tag, wire int, b *proto.Buffer) (bool, error) {
	m := msg.(*ConvolutionLayerParams)
	switch tag {
	case 50: // ConvolutionPaddingType.valid
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(ValidPadding)
		err := b.DecodeMessage(msg)
		m.ConvolutionPaddingType = &ConvolutionLayerParams_Valid{msg}
		return true, err
	case 51: // ConvolutionPaddingType.same
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(SamePadding)
		err := b.DecodeMessage(msg)
		m.ConvolutionPaddingType = &ConvolutionLayerParams_Same{msg}
		return true, err
	default:
		return false, nil
	}
}

func _ConvolutionLayerParams_OneofSizer(msg proto.Message) (n int) {
	m := msg.(*ConvolutionLayerParams)
	// ConvolutionPaddingType
	switch x := m.ConvolutionPaddingType.(type) {
	case *ConvolutionLayerParams_Valid:
		s := proto.Size(x.Valid)
		n += proto.SizeVarint(50<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *ConvolutionLayerParams_Same:
		s := proto.Size(x.Same)
		n += proto.SizeVarint(51<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case nil:
	default:
		panic(fmt.Sprintf("proto: unexpected type %T in oneof", x))
	}
	return n
}

// *
// A layer that performs a matrix vector product.
// This is equivalent to a fully-connected, or dense layer.
// ::
// 		y = InnerProductLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
// 	A blob with shape ``[C_in]`` or ``[C_in, 1, 1]``, where ``C_in`` is
// equal to ``inputChannels``.
//
// Output
//  A blob with shape ``[C_out]``, where ``C_out`` is equal to
// ``outputChannels``.
type InnerProductLayerParams struct {
	InputChannels  uint64        `protobuf:"varint,1,opt,name=inputChannels,proto3" json:"inputChannels,omitempty"`
	OutputChannels uint64        `protobuf:"varint,2,opt,name=outputChannels,proto3" json:"outputChannels,omitempty"`
	HasBias        bool          `protobuf:"varint,10,opt,name=hasBias,proto3" json:"hasBias,omitempty"`
	Weights        *WeightParams `protobuf:"bytes,20,opt,name=weights" json:"weights,omitempty"`
	Bias           *WeightParams `protobuf:"bytes,21,opt,name=bias" json:"bias,omitempty"`
}

func (m *InnerProductLayerParams) Reset()         { *m = InnerProductLayerParams{} }
func (m *InnerProductLayerParams) String() string { return proto.CompactTextString(m) }
func (*InnerProductLayerParams) ProtoMessage()    {}
func (*InnerProductLayerParams) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{24}
}

func (m *InnerProductLayerParams) GetInputChannels() uint64 {
	if m != nil {
		return m.InputChannels
	}
	return 0
}

func (m *InnerProductLayerParams) GetOutputChannels() uint64 {
	if m != nil {
		return m.OutputChannels
	}
	return 0
}

func (m *InnerProductLayerParams) GetHasBias() bool {
	if m != nil {
		return m.HasBias
	}
	return false
}

func (m *InnerProductLayerParams) GetWeights() *WeightParams {
	if m != nil {
		return m.Weights
	}
	return nil
}

func (m *InnerProductLayerParams) GetBias() *WeightParams {
	if m != nil {
		return m.Bias
	}
	return nil
}

// *
// A layer that performs a matrix lookup and optionally adds a bias.
// ::
// 		y = EmbeddingLayer(x)
//
// Requires 1 input and produces 1 output.
//
// Input
// 	   A sequence of integers with shape ``[1]`` or ``[1, 1, 1]``,
// (equivalent to ``[Seq_length, 1, 1, 1]``). Input values must be in the range
// ``[0, inputDim - 1]``.
//
// Output
//     A sequence of 1-dimensional features of size ``outputChannels``
//     (equivalent to ``[Seq_length, outputChannels, 1, 1]``).
type EmbeddingLayerParams struct {
	InputDim       uint64        `protobuf:"varint,1,opt,name=inputDim,proto3" json:"inputDim,omitempty"`
	OutputChannels uint64        `protobuf:"varint,2,opt,name=outputChannels,proto3" json:"outputChannels,omitempty"`
	HasBias        bool          `protobuf:"varint,10,opt,name=hasBias,proto3" json:"hasBias,omitempty"`
	Weights        *WeightParams `protobuf:"bytes,20,opt,name=weights" json:"weights,omitempty"`
	Bias           *WeightParams `protobuf:"bytes,21,opt,name=bias" json:"bias,omitempty"`
}

func (m *EmbeddingLayerParams) Reset()         { *m = EmbeddingLayerParams{} }
func (m *EmbeddingLayerParams) String() string { return proto.CompactTextString(m) }
func (*EmbeddingLayerParams) ProtoMessage()    {}
func (*EmbeddingLayerParams) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{25}
}

func (m *EmbeddingLayerParams) GetInputDim() uint64 {
	if m != nil {
		return m.InputDim
	}
	return 0
}

func (m *EmbeddingLayerParams) GetOutputChannels() uint64 {
	if m != nil {
		return m.OutputChannels
	}
	return 0
}

func (m *EmbeddingLayerParams) GetHasBias() bool {
	if m != nil {
		return m.HasBias
	}
	return false
}

func (m *EmbeddingLayerParams) GetWeights() *WeightParams {
	if m != nil {
		return m.Weights
	}
	return nil
}

func (m *EmbeddingLayerParams) GetBias() *WeightParams {
	if m != nil {
		return m.Bias
	}
	return nil
}

// *
// A layer that performs batch normalization,
// which is performed along the channel axis,
// and repeated along the other axes, if present.
// ::
// 		y = BatchnormLayer(x)
// Requires 1 input and produces 1 output.
//
// This operation is described by the following formula:
//
// .. math::
//     y_i = \gamma_i \dfrac{ (x_i - \mu_i)}{\sqrt{\sigma_i^2 + \epsilon}} +
// \beta_i \;,\;i=1,....,C
//
// Input
//     A blob with shape ``[C]`` or ``[C, H, W]``.
//
// Output
//     A blob with the same shape as the input.
type BatchnormLayerParams struct {
	Channels uint64 `protobuf:"varint,1,opt,name=channels,proto3" json:"channels,omitempty"`
	// *
	// If ``computeMeanVar == true``,
	// the mean and variance are calculated from either
	// the single input instance, if ``instanceNormalization == true``,
	// or the whole batch, if ``instanceNormalization = false``.
	// and the values provided in parameters "mean" and "variance" are ignored.
	ComputeMeanVar        bool `protobuf:"varint,5,opt,name=computeMeanVar,proto3" json:"computeMeanVar,omitempty"`
	InstanceNormalization bool `protobuf:"varint,6,opt,name=instanceNormalization,proto3" json:"instanceNormalization,omitempty"`
	// *
	// A small constant to avoid division by 0 while normalizing by variance.
	// Defaults to ``1e-5`` if not set or set to ``0``.
	Epsilon  float32       `protobuf:"fixed32,10,opt,name=epsilon,proto3" json:"epsilon,omitempty"`
	Gamma    *WeightParams `protobuf:"bytes,15,opt,name=gamma" json:"gamma,omitempty"`
	Beta     *WeightParams `protobuf:"bytes,16,opt,name=beta" json:"beta,omitempty"`
	Mean     *WeightParams `protobuf:"bytes,17,opt,name=mean" json:"mean,omitempty"`
	Variance *WeightParams `protobuf:"bytes,18,opt,name=variance" json:"variance,omitempty"`
}

func (m *BatchnormLayerParams) Reset()         { *m = BatchnormLayerParams{} }
func (m *BatchnormLayerParams) String() string { return proto.CompactTextString(m) }
func (*BatchnormLayerParams) ProtoMessage()    {}
func (*BatchnormLayerParams) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{26}
}

func (m *BatchnormLayerParams) GetChannels() uint64 {
	if m != nil {
		return m.Channels
	}
	return 0
}

func (m *BatchnormLayerParams) GetComputeMeanVar() bool {
	if m != nil {
		return m.ComputeMeanVar
	}
	return false
}

func (m *BatchnormLayerParams) GetInstanceNormalization() bool {
	if m != nil {
		return m.InstanceNormalization
	}
	return false
}

func (m *BatchnormLayerParams) GetEpsilon() float32 {
	if m != nil {
		return m.Epsilon
	}
	return 0
}

func (m *BatchnormLayerParams) GetGamma() *WeightParams {
	if m != nil {
		return m.Gamma
	}
	return nil
}

func (m *BatchnormLayerParams) GetBeta() *WeightParams {
	if m != nil {
		return m.Beta
	}
	return nil
}

func (m *BatchnormLayerParams) GetMean() *WeightParams {
	if m != nil {
		return m.Mean
	}
	return nil
}

func (m *BatchnormLayerParams) GetVariance() *WeightParams {
	if m != nil {
		return m.Variance
	}
	return nil
}

// *
// A spatial pooling layer.
// ::
// 		y = PoolingLayer(x)
// Requires 1 input and produces 1 output.
//
// Input
//     A blob with shape ``[C, H_in, W_in]``.
// Output
//     A blob with shape ``[C, H_out, W_out]``.
//
// Padding options are similar to ``ConvolutionLayerParams``
// with the additional option of ``ValidCompletePadding``
// (``includeLastPixel``), which ensures that the last application of the kernel
// always includes the last pixel of the input image.
// ::
//     H_out = int_division_round_up((H_in + 2 * paddingAmounts[0] -
// kernelSize[0]),Stride[0]) + 1) if ((H_out - 1) * Stride >= H_in +
// paddingAmounts[0]) { H_out = H_out - 1
//     }
//
// The equivalent expressions hold true for ``W_out`` as well.
// Only symmetric padding is supported with this option.
type PoolingLayerParams struct {
	Type PoolingLayerParams_PoolingType `protobuf:"varint,1,opt,name=type,proto3,enum=CoreML.PoolingLayerParams_PoolingType" json:"type,omitempty"`
	// *
	// Must be length 2 in the order ``[H, W]``.
	// If not set, default value ``[3, 3]`` is used.
	KernelSize []uint64 `protobuf:"varint,10,rep,packed,name=kernelSize" json:"kernelSize,omitempty"`
	// *
	// Must be length 2 in the order ``[H, W]``.
	// If not set, default value ``[1, 1]`` is used.
	Stride []uint64 `protobuf:"varint,20,rep,packed,name=stride" json:"stride,omitempty"`
	// Types that are valid to be assigned to PoolingPaddingType:
	//	*PoolingLayerParams_Valid
	//	*PoolingLayerParams_Same
	//	*PoolingLayerParams_IncludeLastPixel
	PoolingPaddingType isPoolingLayerParams_PoolingPaddingType `protobuf_oneof:"PoolingPaddingType"`
	// *
	// If true, padded values are excluded from the count (denominator)
	// when computing average pooling.
	AvgPoolExcludePadding bool `protobuf:"varint,50,opt,name=avgPoolExcludePadding,proto3" json:"avgPoolExcludePadding,omitempty"`
	// *
	// If true, global pooling is performed.
	// Kernel size is inferred from the input data spatial dimensions.
	GlobalPooling bool `protobuf:"varint,60,opt,name=globalPooling,proto3" json:"globalPooling,omitempty"`
}

func (m *PoolingLayerParams) Reset()                    { *m = PoolingLayerParams{} }
func (m *PoolingLayerParams) String() string            { return proto.CompactTextString(m) }
func (*PoolingLayerParams) ProtoMessage()               {}
func (*PoolingLayerParams) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{27} }

type isPoolingLayerParams_PoolingPaddingType interface {
	isPoolingLayerParams_PoolingPaddingType()
	MarshalTo([]byte) (int, error)
	Size() int
}

type PoolingLayerParams_Valid struct {
	Valid *ValidPadding `protobuf:"bytes,30,opt,name=valid,oneof"`
}
type PoolingLayerParams_Same struct {
	Same *SamePadding `protobuf:"bytes,31,opt,name=same,oneof"`
}
type PoolingLayerParams_IncludeLastPixel struct {
	IncludeLastPixel *PoolingLayerParams_ValidCompletePadding `protobuf:"bytes,32,opt,name=includeLastPixel,oneof"`
}

func (*PoolingLayerParams_Valid) isPoolingLayerParams_PoolingPaddingType()            {}
func (*PoolingLayerParams_Same) isPoolingLayerParams_PoolingPaddingType()             {}
func (*PoolingLayerParams_IncludeLastPixel) isPoolingLayerParams_PoolingPaddingType() {}

func (m *PoolingLayerParams) GetPoolingPaddingType() isPoolingLayerParams_PoolingPaddingType {
	if m != nil {
		return m.PoolingPaddingType
	}
	return nil
}

func (m *PoolingLayerParams) GetType() PoolingLayerParams_PoolingType {
	if m != nil {
		return m.Type
	}
	return PoolingLayerParams_MAX
}

func (m *PoolingLayerParams) GetKernelSize() []uint64 {
	if m != nil {
		return m.KernelSize
	}
	return nil
}

func (m *PoolingLayerParams) GetStride() []uint64 {
	if m != nil {
		return m.Stride
	}
	return nil
}

func (m *PoolingLayerParams) GetValid() *ValidPadding {
	if x, ok := m.GetPoolingPaddingType().(*PoolingLayerParams_Valid); ok {
		return x.Valid
	}
	return nil
}

func (m *PoolingLayerParams) GetSame() *SamePadding {
	if x, ok := m.GetPoolingPaddingType().(*PoolingLayerParams_Same); ok {
		return x.Same
	}
	return nil
}

func (m *PoolingLayerParams) GetIncludeLastPixel() *PoolingLayerParams_ValidCompletePadding {
	if x, ok := m.GetPoolingPaddingType().(*PoolingLayerParams_IncludeLastPixel); ok {
		return x.IncludeLastPixel
	}
	return nil
}

func (m *PoolingLayerParams) GetAvgPoolExcludePadding() bool {
	if m != nil {
		return m.AvgPoolExcludePadding
	}
	return false
}

func (m *PoolingLayerParams) GetGlobalPooling() bool {
	if m != nil {
		return m.GlobalPooling
	}
	return false
}

// XXX_OneofFuncs is for the internal use of the proto package.
func (*PoolingLayerParams) XXX_OneofFuncs() (func(msg proto.Message, b *proto.Buffer) error, func(msg proto.Message, tag, wire int, b *proto.Buffer) (bool, error), func(msg proto.Message) (n int), []interface{}) {
	return _PoolingLayerParams_OneofMarshaler, _PoolingLayerParams_OneofUnmarshaler, _PoolingLayerParams_OneofSizer, []interface{}{
		(*PoolingLayerParams_Valid)(nil),
		(*PoolingLayerParams_Same)(nil),
		(*PoolingLayerParams_IncludeLastPixel)(nil),
	}
}

func _PoolingLayerParams_OneofMarshaler(msg proto.Message, b *proto.Buffer) error {
	m := msg.(*PoolingLayerParams)
	// PoolingPaddingType
	switch x := m.PoolingPaddingType.(type) {
	case *PoolingLayerParams_Valid:
		_ = b.EncodeVarint(30<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Valid); err != nil {
			return err
		}
	case *PoolingLayerParams_Same:
		_ = b.EncodeVarint(31<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Same); err != nil {
			return err
		}
	case *PoolingLayerParams_IncludeLastPixel:
		_ = b.EncodeVarint(32<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.IncludeLastPixel); err != nil {
			return err
		}
	case nil:
	default:
		return fmt.Errorf("PoolingLayerParams.PoolingPaddingType has unexpected type %T", x)
	}
	return nil
}

func _PoolingLayerParams_OneofUnmarshaler(msg proto.Message, tag, wire int, b *proto.Buffer) (bool, error) {
	m := msg.(*PoolingLayerParams)
	switch tag {
	case 30: // PoolingPaddingType.valid
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(ValidPadding)
		err := b.DecodeMessage(msg)
		m.PoolingPaddingType = &PoolingLayerParams_Valid{msg}
		return true, err
	case 31: // PoolingPaddingType.same
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(SamePadding)
		err := b.DecodeMessage(msg)
		m.PoolingPaddingType = &PoolingLayerParams_Same{msg}
		return true, err
	case 32: // PoolingPaddingType.includeLastPixel
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(PoolingLayerParams_ValidCompletePadding)
		err := b.DecodeMessage(msg)
		m.PoolingPaddingType = &PoolingLayerParams_IncludeLastPixel{msg}
		return true, err
	default:
		return false, nil
	}
}

func _PoolingLayerParams_OneofSizer(msg proto.Message) (n int) {
	m := msg.(*PoolingLayerParams)
	// PoolingPaddingType
	switch x := m.PoolingPaddingType.(type) {
	case *PoolingLayerParams_Valid:
		s := proto.Size(x.Valid)
		n += proto.SizeVarint(30<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *PoolingLayerParams_Same:
		s := proto.Size(x.Same)
		n += proto.SizeVarint(31<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *PoolingLayerParams_IncludeLastPixel:
		s := proto.Size(x.IncludeLastPixel)
		n += proto.SizeVarint(32<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case nil:
	default:
		panic(fmt.Sprintf("proto: unexpected type %T in oneof", x))
	}
	return n
}

type PoolingLayerParams_ValidCompletePadding struct {
	// *
	// Must be length 2 in order ``[H, W]``.
	// If not set, value ``[0, 0]`` is used.
	PaddingAmounts []uint64 `protobuf:"varint,10,rep,packed,name=paddingAmounts" json:"paddingAmounts,omitempty"`
}

func (m *PoolingLayerParams_ValidCompletePadding) Reset() {
	*m = PoolingLayerParams_ValidCompletePadding{}
}
func (m *PoolingLayerParams_ValidCompletePadding) String() string { return proto.CompactTextString(m) }
func (*PoolingLayerParams_ValidCompletePadding) ProtoMessage()    {}
func (*PoolingLayerParams_ValidCompletePadding) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{27, 0}
}

func (m *PoolingLayerParams_ValidCompletePadding) GetPaddingAmounts() []uint64 {
	if m != nil {
		return m.PaddingAmounts
	}
	return nil
}

// *
// A layer that performs padding along spatial dimensions.
// ::
// 		y = PaddingLayer(x)
// Requires 1 input and produces 1 output.
//
// Input
//     A blob with shape ``[C, H_in, W_in]``.
//
// Output
//     A blob with shape ``[C, H_out, W_out]``.
// Output dimensions are calculated as follows:
// ::
//     H_out = H_in + topPaddingAmount + bottomPaddingAmount
//     W_out = W_in + leftPaddingAmount + rightPaddingAmount
//
//     topPaddingAmount == Height startEdgeSize ==
// borderAmounts[0].startEdgeSize bottomPaddingAmount == Height endEdgeSize ==
// borderAmounts[0].endEdgeSize leftPaddingAmount == Width startEdgeSize ==
// borderAmounts[1].startEdgeSize rightPaddingAmount == Width endEdgeSize ==
// borderAmounts[1].endEdgeSize
//
// There are three types of padding:
//
// - ``PaddingConstant``, which fills a constant value at the border.
// - ``PaddingReflection``, which reflects the values at the border.
// - ``PaddingReplication``, which replicates the values at the border.
//
// Given the following input:
// ::
//     [1, 3, 4]  :  1   2   3   4
//                   5   6   7   8
//                   9   10  11  12
//
// Here is the output of applying the padding
// ``(top=2, left=2, bottom=0, right=0)``
// with each of the supported types:
//
// - ``PaddingConstant`` (``value = 0``):
//   ::
//       [1, 5, 6]  :  0   0   0  0   0   0
//                     0   0   0  0   0   0
//                     0   0   1  2   3   4
//                     0   0   5  6   7   8
//                     0   0   9  10  11  12
//
// - ``PaddingReflection``:
//   ::
//       [1, 5, 6]  :  11  10  9  10  11  12
//                     7   6   5  6   7   8
//                     3   2   1  2   3   4
//                     7   6   5  6   7   8
//                     11  10  9  10  11  12
//
// - ``PaddingReplication``:
//   ::
//       [1, 5, 6]  :  1   1   1  2   3   4
//                     1   1   1  2   3   4
//                     1   1   1  2   3   4
//                     5   5   5  6   7   8
//                     9   9   9  10  11  12
type PaddingLayerParams struct {
	// Types that are valid to be assigned to PaddingType:
	//	*PaddingLayerParams_Constant
	//	*PaddingLayerParams_Reflection
	//	*PaddingLayerParams_Replication
	PaddingType    isPaddingLayerParams_PaddingType `protobuf_oneof:"PaddingType"`
	PaddingAmounts *BorderAmounts                   `protobuf:"bytes,10,opt,name=paddingAmounts" json:"paddingAmounts,omitempty"`
}

func (m *PaddingLayerParams) Reset()                    { *m = PaddingLayerParams{} }
func (m *PaddingLayerParams) String() string            { return proto.CompactTextString(m) }
func (*PaddingLayerParams) ProtoMessage()               {}
func (*PaddingLayerParams) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{28} }

type isPaddingLayerParams_PaddingType interface {
	isPaddingLayerParams_PaddingType()
	MarshalTo([]byte) (int, error)
	Size() int
}

type PaddingLayerParams_Constant struct {
	Constant *PaddingLayerParams_PaddingConstant `protobuf:"bytes,1,opt,name=constant,oneof"`
}
type PaddingLayerParams_Reflection struct {
	Reflection *PaddingLayerParams_PaddingReflection `protobuf:"bytes,2,opt,name=reflection,oneof"`
}
type PaddingLayerParams_Replication struct {
	Replication *PaddingLayerParams_PaddingReplication `protobuf:"bytes,3,opt,name=replication,oneof"`
}

func (*PaddingLayerParams_Constant) isPaddingLayerParams_PaddingType()    {}
func (*PaddingLayerParams_Reflection) isPaddingLayerParams_PaddingType()  {}
func (*PaddingLayerParams_Replication) isPaddingLayerParams_PaddingType() {}

func (m *PaddingLayerParams) GetPaddingType() isPaddingLayerParams_PaddingType {
	if m != nil {
		return m.PaddingType
	}
	return nil
}

func (m *PaddingLayerParams) GetConstant() *PaddingLayerParams_PaddingConstant {
	if x, ok := m.GetPaddingType().(*PaddingLayerParams_Constant); ok {
		return x.Constant
	}
	return nil
}

func (m *PaddingLayerParams) GetReflection() *PaddingLayerParams_PaddingReflection {
	if x, ok := m.GetPaddingType().(*PaddingLayerParams_Reflection); ok {
		return x.Reflection
	}
	return nil
}

func (m *PaddingLayerParams) GetReplication() *PaddingLayerParams_PaddingReplication {
	if x, ok := m.GetPaddingType().(*PaddingLayerParams_Replication); ok {
		return x.Replication
	}
	return nil
}

func (m *PaddingLayerParams) GetPaddingAmounts() *BorderAmounts {
	if m != nil {
		return m.PaddingAmounts
	}
	return nil
}

// XXX_OneofFuncs is for the internal use of the proto package.
func (*PaddingLayerParams) XXX_OneofFuncs() (func(msg proto.Message, b *proto.Buffer) error, func(msg proto.Message, tag, wire int, b *proto.Buffer) (bool, error), func(msg proto.Message) (n int), []interface{}) {
	return _PaddingLayerParams_OneofMarshaler, _PaddingLayerParams_OneofUnmarshaler, _PaddingLayerParams_OneofSizer, []interface{}{
		(*PaddingLayerParams_Constant)(nil),
		(*PaddingLayerParams_Reflection)(nil),
		(*PaddingLayerParams_Replication)(nil),
	}
}

func _PaddingLayerParams_OneofMarshaler(msg proto.Message, b *proto.Buffer) error {
	m := msg.(*PaddingLayerParams)
	// PaddingType
	switch x := m.PaddingType.(type) {
	case *PaddingLayerParams_Constant:
		_ = b.EncodeVarint(1<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Constant); err != nil {
			return err
		}
	case *PaddingLayerParams_Reflection:
		_ = b.EncodeVarint(2<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Reflection); err != nil {
			return err
		}
	case *PaddingLayerParams_Replication:
		_ = b.EncodeVarint(3<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Replication); err != nil {
			return err
		}
	case nil:
	default:
		return fmt.Errorf("PaddingLayerParams.PaddingType has unexpected type %T", x)
	}
	return nil
}

func _PaddingLayerParams_OneofUnmarshaler(msg proto.Message, tag, wire int, b *proto.Buffer) (bool, error) {
	m := msg.(*PaddingLayerParams)
	switch tag {
	case 1: // PaddingType.constant
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(PaddingLayerParams_PaddingConstant)
		err := b.DecodeMessage(msg)
		m.PaddingType = &PaddingLayerParams_Constant{msg}
		return true, err
	case 2: // PaddingType.reflection
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(PaddingLayerParams_PaddingReflection)
		err := b.DecodeMessage(msg)
		m.PaddingType = &PaddingLayerParams_Reflection{msg}
		return true, err
	case 3: // PaddingType.replication
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(PaddingLayerParams_PaddingReplication)
		err := b.DecodeMessage(msg)
		m.PaddingType = &PaddingLayerParams_Replication{msg}
		return true, err
	default:
		return false, nil
	}
}

func _PaddingLayerParams_OneofSizer(msg proto.Message) (n int) {
	m := msg.(*PaddingLayerParams)
	// PaddingType
	switch x := m.PaddingType.(type) {
	case *PaddingLayerParams_Constant:
		s := proto.Size(x.Constant)
		n += proto.SizeVarint(1<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *PaddingLayerParams_Reflection:
		s := proto.Size(x.Reflection)
		n += proto.SizeVarint(2<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *PaddingLayerParams_Replication:
		s := proto.Size(x.Replication)
		n += proto.SizeVarint(3<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case nil:
	default:
		panic(fmt.Sprintf("proto: unexpected type %T in oneof", x))
	}
	return n
}

// *
// Fill a constant value in the padded region.
type PaddingLayerParams_PaddingConstant struct {
	Value float32 `protobuf:"fixed32,1,opt,name=value,proto3" json:"value,omitempty"`
}

func (m *PaddingLayerParams_PaddingConstant) Reset()         { *m = PaddingLayerParams_PaddingConstant{} }
func (m *PaddingLayerParams_PaddingConstant) String() string { return proto.CompactTextString(m) }
func (*PaddingLayerParams_PaddingConstant) ProtoMessage()    {}
func (*PaddingLayerParams_PaddingConstant) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{28, 0}
}

func (m *PaddingLayerParams_PaddingConstant) GetValue() float32 {
	if m != nil {
		return m.Value
	}
	return 0
}

// *
// Reflect the values at the border for padding.
type PaddingLayerParams_PaddingReflection struct {
}

func (m *PaddingLayerParams_PaddingReflection) Reset()         { *m = PaddingLayerParams_PaddingReflection{} }
func (m *PaddingLayerParams_PaddingReflection) String() string { return proto.CompactTextString(m) }
func (*PaddingLayerParams_PaddingReflection) ProtoMessage()    {}
func (*PaddingLayerParams_PaddingReflection) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{28, 1}
}

// *
// Replicate the values at the border for padding.
type PaddingLayerParams_PaddingReplication struct {
}

func (m *PaddingLayerParams_PaddingReplication) Reset()         { *m = PaddingLayerParams_PaddingReplication{} }
func (m *PaddingLayerParams_PaddingReplication) String() string { return proto.CompactTextString(m) }
func (*PaddingLayerParams_PaddingReplication) ProtoMessage()    {}
func (*PaddingLayerParams_PaddingReplication) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{28, 2}
}

// *
// A layer that concatenates along the channel axis (default) or sequence axis.
// ::
// 		y = ConcatLayer(x1,x2,....)
// Requires more than 1 input and produces 1 output.
//
// The input and output formats are dependent on ``sequenceConcat``.
//
// If ``sequenceConcat == true``:
//
// Input
//     Sequences of length ``Seq_i`` of blobs with shape ``[C, H, W]``.
// Output
//     A Sequence of length ``summation(Seq_i)`` of blobs with shape ``[C, H,
// W]``.
//
// If ``sequenceConcat == false``:
//
// Input
//     A blob with shape ``[C_i, H, W]``, where ``i = 1, 2, ...``.
// Output
//     A blob with shape ``[summation(C_i), H, W]``.
type ConcatLayerParams struct {
	// *
	// If true, concatenate along the sequence axis instead of the channel axis.
	SequenceConcat bool `protobuf:"varint,100,opt,name=sequenceConcat,proto3" json:"sequenceConcat,omitempty"`
}

func (m *ConcatLayerParams) Reset()                    { *m = ConcatLayerParams{} }
func (m *ConcatLayerParams) String() string            { return proto.CompactTextString(m) }
func (*ConcatLayerParams) ProtoMessage()               {}
func (*ConcatLayerParams) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{29} }

func (m *ConcatLayerParams) GetSequenceConcat() bool {
	if m != nil {
		return m.SequenceConcat
	}
	return false
}

// *
// A layer that performs local response normalization (LRN).
// ::
//  	y = LRNLayer(x)
// Requires 1 input and produces 1 output.
//
// Input
//     A blob with shape ``[C, H, W]``
// Output
//     A blob with the same shape as the input.
//
// This layer is described by the following formula:
//
// .. math::
//     x_i \leftarrow  \dfrac{x_i}{\left ( k + \dfrac{\alpha}{C} \sum_j x_j^2
// \right )^\beta}
//
// where the summation is done over a ``(localSize, 1, 1)`` neighborhood ---
// that is, over a window "across" channels in 1x1 spatial neighborhoods.
type LRNLayerParams struct {
	Alpha     float32 `protobuf:"fixed32,1,opt,name=alpha,proto3" json:"alpha,omitempty"`
	Beta      float32 `protobuf:"fixed32,2,opt,name=beta,proto3" json:"beta,omitempty"`
	LocalSize uint64  `protobuf:"varint,3,opt,name=localSize,proto3" json:"localSize,omitempty"`
	K         float32 `protobuf:"fixed32,4,opt,name=k,proto3" json:"k,omitempty"`
}

func (m *LRNLayerParams) Reset()                    { *m = LRNLayerParams{} }
func (m *LRNLayerParams) String() string            { return proto.CompactTextString(m) }
func (*LRNLayerParams) ProtoMessage()               {}
func (*LRNLayerParams) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{30} }

func (m *LRNLayerParams) GetAlpha() float32 {
	if m != nil {
		return m.Alpha
	}
	return 0
}

func (m *LRNLayerParams) GetBeta() float32 {
	if m != nil {
		return m.Beta
	}
	return 0
}

func (m *LRNLayerParams) GetLocalSize() uint64 {
	if m != nil {
		return m.LocalSize
	}
	return 0
}

func (m *LRNLayerParams) GetK() float32 {
	if m != nil {
		return m.K
	}
	return 0
}

// *
// Softmax Normalization Layer
//
// A layer that performs softmax normalization.
// Normalization is done along the channel axis.
// ::
//  	y = SoftmaxLayer(x)
// Requires 1 input and produces 1 output.
//
// Input
//     A blob with shape ``[C]`` or ``[C, H, W]``.
// Output
//     A blob with the same shape as the input.
//
// This layer is described by the following formula:
//
// .. math::
//     x_i \leftarrow \dfrac{e^{x_i}}{\sum_i{e^{x_i}}}
type SoftmaxLayerParams struct {
}

func (m *SoftmaxLayerParams) Reset()                    { *m = SoftmaxLayerParams{} }
func (m *SoftmaxLayerParams) String() string            { return proto.CompactTextString(m) }
func (*SoftmaxLayerParams) ProtoMessage()               {}
func (*SoftmaxLayerParams) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{31} }

// *
// A layer that uniformly splits across the channel dimension
// to produce a specified number of outputs.
// ::
//  	(y1,y2,...yN) = SplitLayer(x), where N = nOutputs
// Requires 1 input and produces multiple outputs.
//
// Input
//     A blob with shape ``[C]`` or ``[C, H, W]``
// Output
//     ``nOutputs`` blobs with shapes
//     ``[C/nOutputs]`` or ``[C/nOutputs, H, W]``
type SplitLayerParams struct {
	NOutputs uint64 `protobuf:"varint,1,opt,name=nOutputs,proto3" json:"nOutputs,omitempty"`
}

func (m *SplitLayerParams) Reset()                    { *m = SplitLayerParams{} }
func (m *SplitLayerParams) String() string            { return proto.CompactTextString(m) }
func (*SplitLayerParams) ProtoMessage()               {}
func (*SplitLayerParams) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{32} }

func (m *SplitLayerParams) GetNOutputs() uint64 {
	if m != nil {
		return m.NOutputs
	}
	return 0
}

// *
// A layer that performs elementwise addition.
// ::
//  	y = AddLayer(x1,x2,...)
// Requires 1 or more than 1 input and produces 1 output.
//
// Input
//     One or more blobs with shape ``[C, H, W]``.
// Output
//     A blob with shape equal to the input blob.
//
// If only one input is provided, scalar addition is performed:
//
// .. math::
//     y = x + \alpha
//
// If multiple inputs are provided,
// each input is broadcasted to the shape of the first input and added.
// The shapes of inputs after the first must be one of the following:
// ``[1]``, ``[C]``, ``[1, H, W]``, or ``[C, H, W]``.
type AddLayerParams struct {
	// *
	// Scalar to be added to the input.
	// Only used if there is a single input.
	Alpha float32 `protobuf:"fixed32,1,opt,name=alpha,proto3" json:"alpha,omitempty"`
}

func (m *AddLayerParams) Reset()                    { *m = AddLayerParams{} }
func (m *AddLayerParams) String() string            { return proto.CompactTextString(m) }
func (*AddLayerParams) ProtoMessage()               {}
func (*AddLayerParams) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{33} }

func (m *AddLayerParams) GetAlpha() float32 {
	if m != nil {
		return m.Alpha
	}
	return 0
}

// *
// A layer that performs elementwise multiplication.
// ::
//  	y = MultiplyLayer(x1,x2,...)
// Requires 1 or more than 1 input and produces 1 output.
//
// Input
//     One or more blobs with shape ``[C, H, W]``.
// Output
//     A blob with shape equal to the first input blob.
//
// If only one input is provided, scalar multiplication is performed:
//
// .. math::
//     y = \alpha x
//
// If multiple inputs are provided,
// each input is broadcasted to the shape of the first input and multiplied.
// The shapes of inputs after the first must be one of the following:
// ``[1]``, ``[C]``, ``[1, H, W]``, or ``[C, H, W]``.
type MultiplyLayerParams struct {
	// *
	// Scalar to be multiplied with the input.
	// Only used if there is a single input.
	Alpha float32 `protobuf:"fixed32,1,opt,name=alpha,proto3" json:"alpha,omitempty"`
}

func (m *MultiplyLayerParams) Reset()         { *m = MultiplyLayerParams{} }
func (m *MultiplyLayerParams) String() string { return proto.CompactTextString(m) }
func (*MultiplyLayerParams) ProtoMessage()    {}
func (*MultiplyLayerParams) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{34}
}

func (m *MultiplyLayerParams) GetAlpha() float32 {
	if m != nil {
		return m.Alpha
	}
	return 0
}

// *
// A layer that applies a unary function.
// ::
//  	y = UnaryFunctionLayer(x)
// Requires 1 input and produces 1 output.
//
// Input
//     A blob with shape ``[C]`` or ``[C, H, W]``.
// Output
//     A blob with the same shape as the input.
//
// The input is first modified by shifting and scaling:
//
// .. math::
//     x \leftarrow \text{scale} \cdot x + \text{shift}
type UnaryFunctionLayerParams struct {
	Type UnaryFunctionLayerParams_Operation `protobuf:"varint,1,opt,name=type,proto3,enum=CoreML.UnaryFunctionLayerParams_Operation" json:"type,omitempty"`
	// *
	// A constant used in ``POWER`` and ``THRESHOLD`` functions.
	Alpha float32 `protobuf:"fixed32,2,opt,name=alpha,proto3" json:"alpha,omitempty"`
	// *
	// A small constant to avoid division by 0 while normalizing variance.
	// Defaults to ``1e-6`` if not set or set to ``0``.
	Epsilon float32 `protobuf:"fixed32,3,opt,name=epsilon,proto3" json:"epsilon,omitempty"`
	// *
	// Input is shifted by this amount
	// before the unary function is applied.
	// Defaults to ``0.0`` if not set.
	Shift float32 `protobuf:"fixed32,4,opt,name=shift,proto3" json:"shift,omitempty"`
	// *
	// Input is scaled by this amount
	// before the unary function is applied.
	// Defaults to ``1.0`` if not set or set to ``0``.
	Scale float32 `protobuf:"fixed32,5,opt,name=scale,proto3" json:"scale,omitempty"`
}

func (m *UnaryFunctionLayerParams) Reset()         { *m = UnaryFunctionLayerParams{} }
func (m *UnaryFunctionLayerParams) String() string { return proto.CompactTextString(m) }
func (*UnaryFunctionLayerParams) ProtoMessage()    {}
func (*UnaryFunctionLayerParams) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{35}
}

func (m *UnaryFunctionLayerParams) GetType() UnaryFunctionLayerParams_Operation {
	if m != nil {
		return m.Type
	}
	return UnaryFunctionLayerParams_SQRT
}

func (m *UnaryFunctionLayerParams) GetAlpha() float32 {
	if m != nil {
		return m.Alpha
	}
	return 0
}

func (m *UnaryFunctionLayerParams) GetEpsilon() float32 {
	if m != nil {
		return m.Epsilon
	}
	return 0
}

func (m *UnaryFunctionLayerParams) GetShift() float32 {
	if m != nil {
		return m.Shift
	}
	return 0
}

func (m *UnaryFunctionLayerParams) GetScale() float32 {
	if m != nil {
		return m.Scale
	}
	return 0
}

// *
// A layer that scales up spatial dimensions
// using nearest neighbor interpolation.
// ::
//  	y = UpsampleLayer(x)
// Requires 1 input and produces 1 output.
//
// Input
//     A blob with shape ``[C, H, W]``.
// Output
//     A blob with shape ``[C, scalingFactor[0] * H, scalingFactor[1] * W]``
type UpsampleLayerParams struct {
	// *
	// Scaling Factor.
	// Must be length 2 in order ``[H, W]``.
	// If not set, default value ``[1, 1]`` is used.
	ScalingFactor []uint64 `protobuf:"varint,1,rep,packed,name=scalingFactor" json:"scalingFactor,omitempty"`
}

func (m *UpsampleLayerParams) Reset()         { *m = UpsampleLayerParams{} }
func (m *UpsampleLayerParams) String() string { return proto.CompactTextString(m) }
func (*UpsampleLayerParams) ProtoMessage()    {}
func (*UpsampleLayerParams) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{36}
}

func (m *UpsampleLayerParams) GetScalingFactor() []uint64 {
	if m != nil {
		return m.ScalingFactor
	}
	return nil
}

// *
// A layer that performs elementwise addition of a bias,
// which is broadcasted to match the input shape.
// ::
//  	y = BiasLayer(x)
// Requires 1 input and produces 1 output.
//
// Input
//     A blob with shape ``[C, H, W]``.
// Output
//     A blob with the same shape as the input.
type BiasLayerParams struct {
	// *
	// The shape of the bias.
	// Must be one of the following:
	// ``[1]``, ``[C]``, ``[1, H, W]`` or ``[C, H, W]``.
	Shape []uint64 `protobuf:"varint,1,rep,packed,name=shape" json:"shape,omitempty"`
	// *
	// The bias values.
	// The size must be equal to the product of the ``shape`` dimensions.
	Bias *WeightParams `protobuf:"bytes,2,opt,name=bias" json:"bias,omitempty"`
}

func (m *BiasLayerParams) Reset()                    { *m = BiasLayerParams{} }
func (m *BiasLayerParams) String() string            { return proto.CompactTextString(m) }
func (*BiasLayerParams) ProtoMessage()               {}
func (*BiasLayerParams) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{37} }

func (m *BiasLayerParams) GetShape() []uint64 {
	if m != nil {
		return m.Shape
	}
	return nil
}

func (m *BiasLayerParams) GetBias() *WeightParams {
	if m != nil {
		return m.Bias
	}
	return nil
}

// *
// A layer that performs elmentwise multiplication by a scale factor
// and optionally adds a bias;
// both the scale and bias are broadcasted to match the input shape.
// ::
//  	y = ScaleLayer(x)
// Requires 1 input and produces 1 output.
//
// Input
//     A blob with shape ``[C, H, W]``.
// Output
//     A blob with the same shape as the input.
type ScaleLayerParams struct {
	// *
	// The shape of the scale.
	// Must be one of the following:
	// ``[1]``, ``[C]``, ``[1, H, W]`` or ``[C, H, W]``.
	ShapeScale []uint64 `protobuf:"varint,1,rep,packed,name=shapeScale" json:"shapeScale,omitempty"`
	// *
	// The scale values.
	// The size must be equal to the product of the ``shape`` dimensions.
	Scale   *WeightParams `protobuf:"bytes,2,opt,name=scale" json:"scale,omitempty"`
	HasBias bool          `protobuf:"varint,3,opt,name=hasBias,proto3" json:"hasBias,omitempty"`
	// *
	// The shape of the bias.
	// Must be one of the following:
	// ``[1]``, ``[C]``, ``[1, H, W]`` or ``[C, H, W]``.
	ShapeBias []uint64 `protobuf:"varint,4,rep,packed,name=shapeBias" json:"shapeBias,omitempty"`
	// *
	// The bias values.
	// The size must be equal to the product of the ``shape`` dimensions.
	Bias *WeightParams `protobuf:"bytes,5,opt,name=bias" json:"bias,omitempty"`
}

func (m *ScaleLayerParams) Reset()                    { *m = ScaleLayerParams{} }
func (m *ScaleLayerParams) String() string            { return proto.CompactTextString(m) }
func (*ScaleLayerParams) ProtoMessage()               {}
func (*ScaleLayerParams) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{38} }

func (m *ScaleLayerParams) GetShapeScale() []uint64 {
	if m != nil {
		return m.ShapeScale
	}
	return nil
}

func (m *ScaleLayerParams) GetScale() *WeightParams {
	if m != nil {
		return m.Scale
	}
	return nil
}

func (m *ScaleLayerParams) GetHasBias() bool {
	if m != nil {
		return m.HasBias
	}
	return false
}

func (m *ScaleLayerParams) GetShapeBias() []uint64 {
	if m != nil {
		return m.ShapeBias
	}
	return nil
}

func (m *ScaleLayerParams) GetBias() *WeightParams {
	if m != nil {
		return m.Bias
	}
	return nil
}

// *
// A layer that loads data as a parameter and provides it as an output.
// ::
//  	y = LoadConstantLayer()
// Takes no input. Produces 1 output.
//
// Input
//     None
// Output:
//     A blob with shape ``[C, H, W]``
type LoadConstantLayerParams struct {
	// *
	// The shape of the constant to be loaded,
	// which must be``[C, H, W]``.
	Shape []uint64 `protobuf:"varint,1,rep,packed,name=shape" json:"shape,omitempty"`
	// *
	// The data values,
	// of size ``C * H * W``.
	Data *WeightParams `protobuf:"bytes,2,opt,name=data" json:"data,omitempty"`
}

func (m *LoadConstantLayerParams) Reset()         { *m = LoadConstantLayerParams{} }
func (m *LoadConstantLayerParams) String() string { return proto.CompactTextString(m) }
func (*LoadConstantLayerParams) ProtoMessage()    {}
func (*LoadConstantLayerParams) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{39}
}

func (m *LoadConstantLayerParams) GetShape() []uint64 {
	if m != nil {
		return m.Shape
	}
	return nil
}

func (m *LoadConstantLayerParams) GetData() *WeightParams {
	if m != nil {
		return m.Data
	}
	return nil
}

// *
// A layer that performs L2 normalization, i.e. divides by the
// the square root of the sum of squares of all elements of input.
// ::
// 		y = L2NormalizeLayer(x)
// Requires 1 input and produces 1 output.
//
// Input
//     A blob with shape ``[C]`` or ``[C, H, W]``.
// Output
//     A blob with the same shape as the input.
//
// This layer is described by the following formula:
//
// .. math::
//     x_i \leftarrow \dfrac{x_i}{\sqrt{\sum{x_i^2} + \epsilon}}
type L2NormalizeLayerParams struct {
	// *
	// A small constant to avoid division by 0 while normalizing variance.
	// Defaults to ``1e-6`` if not set or set to ``0``.
	Epsilon float32 `protobuf:"fixed32,1,opt,name=epsilon,proto3" json:"epsilon,omitempty"`
}

func (m *L2NormalizeLayerParams) Reset()         { *m = L2NormalizeLayerParams{} }
func (m *L2NormalizeLayerParams) String() string { return proto.CompactTextString(m) }
func (*L2NormalizeLayerParams) ProtoMessage()    {}
func (*L2NormalizeLayerParams) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{40}
}

func (m *L2NormalizeLayerParams) GetEpsilon() float32 {
	if m != nil {
		return m.Epsilon
	}
	return 0
}

// *
// A layer that flattens the input.
// ::
// 		y = FlattenLayer(x)
// Requires 1 input and produces 1 output.
//
// Input
//     A blob with shape ``[C, H, W]``.
// Output
//     A blob with shape ``[C * H * W, 1, 1]``
//
// There are two flatten orders: ``CHANNEL_FIRST`` and ``CHANNEL_LAST``.
// ``CHANNEL_FIRST`` does not require data to be rearranged,
// because row major ordering is used by internal storage.
// ``CHANNEL_LAST`` requires data to be rearranged.
type FlattenLayerParams struct {
	Mode FlattenLayerParams_FlattenOrder `protobuf:"varint,1,opt,name=mode,proto3,enum=CoreML.FlattenLayerParams_FlattenOrder" json:"mode,omitempty"`
}

func (m *FlattenLayerParams) Reset()                    { *m = FlattenLayerParams{} }
func (m *FlattenLayerParams) String() string            { return proto.CompactTextString(m) }
func (*FlattenLayerParams) ProtoMessage()               {}
func (*FlattenLayerParams) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{41} }

func (m *FlattenLayerParams) GetMode() FlattenLayerParams_FlattenOrder {
	if m != nil {
		return m.Mode
	}
	return FlattenLayerParams_CHANNEL_FIRST
}

// *
// A layer that recasts the input into a new shape.
// ::
//  	y = ReshapeLayer(x)
// Requires 1 input and produces 1 output.
//
// Input
//     A blob with shape ``[C, H, W]`` or ``[Seq, C, H, W]``.
// Output
//     A blob with shape ``[C_out, H_out, W_out]``
//     or ``[Seq_out, C_out, H_out, W_out]``.
//
// There are two reshape orders: ``CHANNEL_FIRST`` and ``CHANNEL_LAST``.
// ``CHANNEL_FIRST`` is equivalent to
// flattening the input to ``[C * H * W, 1, 1]`` in channel first order
// and then reshaping it to the target shape;
// no data rearrangement is required.
// ``CHANNEL_LAST`` is equivalent to
// flattening the input to ``[H * W * C, 1, 1]`` in channel last order,
// reshaping it to ``[H_out, W_out, C_out]`` (it is now in "H_out-major""
// order), and then permuting it to ``[C_out, H_out, W_out]``; both the
// flattening and permuting requires the data to be rearranged.
type ReshapeLayerParams struct {
	// *
	// The shape of the output.
	// Must be of length 3 or 4.
	// If set to 3, ``targetShape`` is interpreted as
	// ``[C_out, H_out, W_out]``, and sequence length of the input is preserved.
	// If set to 4, ``targetShape`` is interpreted as
	// ``[Seq_out, C_out, H_out, W_out]``,
	// where ``Seq_out`` is the new sequence length.
	TargetShape []int64                         `protobuf:"varint,1,rep,packed,name=targetShape" json:"targetShape,omitempty"`
	Mode        ReshapeLayerParams_ReshapeOrder `protobuf:"varint,2,opt,name=mode,proto3,enum=CoreML.ReshapeLayerParams_ReshapeOrder" json:"mode,omitempty"`
}

func (m *ReshapeLayerParams) Reset()                    { *m = ReshapeLayerParams{} }
func (m *ReshapeLayerParams) String() string            { return proto.CompactTextString(m) }
func (*ReshapeLayerParams) ProtoMessage()               {}
func (*ReshapeLayerParams) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{42} }

func (m *ReshapeLayerParams) GetTargetShape() []int64 {
	if m != nil {
		return m.TargetShape
	}
	return nil
}

func (m *ReshapeLayerParams) GetMode() ReshapeLayerParams_ReshapeOrder {
	if m != nil {
		return m.Mode
	}
	return ReshapeLayerParams_CHANNEL_FIRST
}

// *
// A layer that rearranges the dimensions and data of an input.
// ::
//  	y = PermuteLayer(x)
// Requires 1 input and produces 1 output.
//
// Input
//     A sequence of 3-dimensional blobs. ``InputShape = [Seq, C, H, W]``.
// Output
//     A sequence of a different length of 3-dimensional blobs.
//     Shape: ``[InputShape[axis[0]], InputShape[axis[1]],
//     InputShape[axis[2]], InputShape[axis[3]]]``. Hence output is a sequence
// of length ``InputShape[axis[0]]``.
//
// Examples:
//
// - If ``axis`` is set to ``[0, 3, 1, 2]``,
//   then the output has shape ``[W,C,H]``
//   and has the same sequence length that of the input.
// - If ``axis`` is set to ``[3, 1, 2, 0]``,
//   and the input is a sequence of data
//   with length ``Seq`` and shape ``[C, 1, 1]``,
//   then the output is a unit sequence of data with shape ``[C, 1, Seq]``.
// - If ``axis`` is set to ``[0, 3, 2, 1]``,
//   the output is a reverse of the input: ``[C, H, W] -> [W, H, C]``.
// - If ``axis`` is not set, or is set to ``[0, 1, 2, 3]``,
//   the output is the same as the input.
type PermuteLayerParams struct {
	// *
	// The order in which to permute the dimensions.
	// Must have length 4 and a permutation of ``[0, 1, 2, 3]``.
	Axis []uint64 `protobuf:"varint,1,rep,packed,name=axis" json:"axis,omitempty"`
}

func (m *PermuteLayerParams) Reset()                    { *m = PermuteLayerParams{} }
func (m *PermuteLayerParams) String() string            { return proto.CompactTextString(m) }
func (*PermuteLayerParams) ProtoMessage()               {}
func (*PermuteLayerParams) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{43} }

func (m *PermuteLayerParams) GetAxis() []uint64 {
	if m != nil {
		return m.Axis
	}
	return nil
}

// *
// A layer that reduces the input to a scalar value using a specified operation.
// ::
// 		y = ReduceLayer(x)
// Requires 1 input and produces 1 output.
//
// Input
//     A blob with shape ``[C, H, W]``.
// Output
//     A scalar value.
type ReduceLayerParams struct {
	Mode ReduceLayerParams_ReduceOperation `protobuf:"varint,1,opt,name=mode,proto3,enum=CoreML.ReduceLayerParams_ReduceOperation" json:"mode,omitempty"`
	// *
	// Used if mode is ``LOGSUM``.
	// Defaults to ``1e-6`` if not set or is set to ``0``.
	Epsilon float32 `protobuf:"fixed32,2,opt,name=epsilon,proto3" json:"epsilon,omitempty"`
}

func (m *ReduceLayerParams) Reset()                    { *m = ReduceLayerParams{} }
func (m *ReduceLayerParams) String() string            { return proto.CompactTextString(m) }
func (*ReduceLayerParams) ProtoMessage()               {}
func (*ReduceLayerParams) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{44} }

func (m *ReduceLayerParams) GetMode() ReduceLayerParams_ReduceOperation {
	if m != nil {
		return m.Mode
	}
	return ReduceLayerParams_SUM
}

func (m *ReduceLayerParams) GetEpsilon() float32 {
	if m != nil {
		return m.Epsilon
	}
	return 0
}

// *
// A layer that crops the spatial dimensions of an input.
// If two inputs are provided, the shape of the second input is used as the
// reference shape.
// ::
//  	y = CropLayer(x1) or y = CropLayer(x1,x2)
// Requires 1 or 2 inputs and produces 1 output.
//
// Input
//     - 1 input case: A blob with shape ``[C, H_in, W_in]``.
//     - 2 input case: 1st blob with shape ``[C, H_in, W_in]``, 2nd blob with
// shape ``[C, H_out, W_out]``.
//
// Output
//     A blob with shape ``[C, H_out, W_out]``.
//
// If one input is used, output is computed as follows:
// ::
// 		y = x1[:, topCropAmount:H_in - bottomCropAmount,
// leftCropAmount:W_in - rightCropAmount]
//
// 		topCropAmount == Height startEdgeSize ==
// borderAmounts[0].startEdgeSize bottomCropAmount == Height endEdgeSize ==
// borderAmounts[0].endEdgeSize leftCropAmount == Width startEdgeSize ==
// borderAmounts[1].startEdgeSize rightCropAmount == Width endEdgeSize ==
// borderAmounts[1].endEdgeSize
//
// 		H_out = H_in - topCropAmount - bottomCropAmount
// 		W_out = W_in - leftCropAmount - rightCropAmount
//
// If two inputs are used, output is computed as follows:
// ::
// 		y = x1[:, offset[0]:offset[0] + H_out, offset[1]:offset[1] +
// W_out]
type CropLayerParams struct {
	// *
	// The amounts to be cropped from the input.
	// Used only if a single input is provided.
	CropAmounts *BorderAmounts `protobuf:"bytes,1,opt,name=cropAmounts" json:"cropAmounts,omitempty"`
	// *
	// The offset amounts.
	// Used only if two inputs are provided.
	// Must be of length 2, in order ``[H, W]``.
	Offset []uint64 `protobuf:"varint,5,rep,packed,name=offset" json:"offset,omitempty"`
}

func (m *CropLayerParams) Reset()                    { *m = CropLayerParams{} }
func (m *CropLayerParams) String() string            { return proto.CompactTextString(m) }
func (*CropLayerParams) ProtoMessage()               {}
func (*CropLayerParams) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{45} }

func (m *CropLayerParams) GetCropAmounts() *BorderAmounts {
	if m != nil {
		return m.CropAmounts
	}
	return nil
}

func (m *CropLayerParams) GetOffset() []uint64 {
	if m != nil {
		return m.Offset
	}
	return nil
}

// *
// A layer that computes the elementwise average of the inputs.
// ::
// 		y = AverageLayer(x1,x2,...)
// Requires multiple inputs and produces 1 output.
//
// Input
//     Multiple blobs, each with shape ``[C]`` or ``[C, H, W]``.
// Output
//     A blob with the same shape as each input.
type AverageLayerParams struct {
}

func (m *AverageLayerParams) Reset()                    { *m = AverageLayerParams{} }
func (m *AverageLayerParams) String() string            { return proto.CompactTextString(m) }
func (*AverageLayerParams) ProtoMessage()               {}
func (*AverageLayerParams) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{46} }

// *
// A layer that computes the elementwise maximum over the inputs.
// ::
// 		y = MaxLayer(x1,x2,...)
// Requires multiple inputs and produces 1 output.
//
// Input
//     Multiple blobs, each with shape ``[C]`` or ``[C, H, W]``.
// Output
//     A blob with the same shape as each input.
type MaxLayerParams struct {
}

func (m *MaxLayerParams) Reset()                    { *m = MaxLayerParams{} }
func (m *MaxLayerParams) String() string            { return proto.CompactTextString(m) }
func (*MaxLayerParams) ProtoMessage()               {}
func (*MaxLayerParams) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{47} }

// *
// A layer that computes the elementwise minimum over the inputs.
// ::
// 		y = MinLayer(x1,x2,...)
// Requires multiple inputs and produces 1 output.
//
// Input
//     Multiple blobs, each with shape ``[C]`` or ``[C, H, W]``.
// Output
//     A blob with the same shape as each input.
type MinLayerParams struct {
}

func (m *MinLayerParams) Reset()                    { *m = MinLayerParams{} }
func (m *MinLayerParams) String() string            { return proto.CompactTextString(m) }
func (*MinLayerParams) ProtoMessage()               {}
func (*MinLayerParams) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{48} }

// *
// A layer that computes the dot product of two vectors.
// ::
// 		y = DotProductLayer(x1,x2)
// Requires 2 inputs and produces 1 output.
//
// Input
//     Two blobs with shape ``[C]``.
// Output
//     A scalar.
type DotProductLayerParams struct {
	// *
	// If true, inputs are normalized first,
	// thereby computing the cosine similarity.
	CosineSimilarity bool `protobuf:"varint,1,opt,name=cosineSimilarity,proto3" json:"cosineSimilarity,omitempty"`
}

func (m *DotProductLayerParams) Reset()         { *m = DotProductLayerParams{} }
func (m *DotProductLayerParams) String() string { return proto.CompactTextString(m) }
func (*DotProductLayerParams) ProtoMessage()    {}
func (*DotProductLayerParams) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{49}
}

func (m *DotProductLayerParams) GetCosineSimilarity() bool {
	if m != nil {
		return m.CosineSimilarity
	}
	return false
}

// *
// A layer that performs mean variance normalization.
// ::
// 		y = MeanVarianceNormalizeLayer(x)
// Requires 1 input and produces 1 output.
//
// Input
//     A blob with shape ``[C]`` or ``[C, H, W]``.
// Output
//     A blob with the same shape as the input.
//
// If ``acrossChannels == true``
// normalization is performed on flattened input.
//
// If ``acrossChannels == false``
// normalization is performed within a channel,
// across spatial dimensions.
type MeanVarianceNormalizeLayerParams struct {
	// *
	// If true, mean and variance are computed across channels.
	AcrossChannels bool `protobuf:"varint,1,opt,name=acrossChannels,proto3" json:"acrossChannels,omitempty"`
	// *
	// If false, only mean is subtracted.
	NormalizeVariance bool `protobuf:"varint,2,opt,name=normalizeVariance,proto3" json:"normalizeVariance,omitempty"`
	// *
	// A small constant to avoid division by 0 while normalizing variance.
	// Defaults to ``1e-6`` if not set or set to ``0``.
	Epsilon float32 `protobuf:"fixed32,3,opt,name=epsilon,proto3" json:"epsilon,omitempty"`
}

func (m *MeanVarianceNormalizeLayerParams) Reset()         { *m = MeanVarianceNormalizeLayerParams{} }
func (m *MeanVarianceNormalizeLayerParams) String() string { return proto.CompactTextString(m) }
func (*MeanVarianceNormalizeLayerParams) ProtoMessage()    {}
func (*MeanVarianceNormalizeLayerParams) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{50}
}

func (m *MeanVarianceNormalizeLayerParams) GetAcrossChannels() bool {
	if m != nil {
		return m.AcrossChannels
	}
	return false
}

func (m *MeanVarianceNormalizeLayerParams) GetNormalizeVariance() bool {
	if m != nil {
		return m.NormalizeVariance
	}
	return false
}

func (m *MeanVarianceNormalizeLayerParams) GetEpsilon() float32 {
	if m != nil {
		return m.Epsilon
	}
	return 0
}

// *
// A layer that repeats a sequence.
// ::
// 		y = SequenceRepeatLayer(x)
// Requires 1 input and produces 1 output.
//
// Input
//     A sequence of blobs, i.e. shape is either ``[Seq, C]`` or ``[Seq, C, H,
// W]``. Output A sequence of length ``nRepetitions * Seq`` with shape
// corresponding to the input, i.e. shape is either ``[nRepetitions * Seq,
// C]`` or ``[nRepetitions * Seq, C, H, W]``.
type SequenceRepeatLayerParams struct {
	// *
	// Number of repetitions.
	// Defaults to ``1`` if not set or set to ``0``.
	NRepetitions uint64 `protobuf:"varint,1,opt,name=nRepetitions,proto3" json:"nRepetitions,omitempty"`
}

func (m *SequenceRepeatLayerParams) Reset()         { *m = SequenceRepeatLayerParams{} }
func (m *SequenceRepeatLayerParams) String() string { return proto.CompactTextString(m) }
func (*SequenceRepeatLayerParams) ProtoMessage()    {}
func (*SequenceRepeatLayerParams) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{51}
}

func (m *SequenceRepeatLayerParams) GetNRepetitions() uint64 {
	if m != nil {
		return m.NRepetitions
	}
	return 0
}

// *
// A simple recurrent layer.
// ::
// 		y_t = SimpleRecurrentLayer(x_t, y_{t-1})
//
// Input
//    A sequence of vectors of size ``inputVectorSize``
//    with shape ``[Seq, inputVectorSize]``.
// Output
//    A vector of size ``outputVectorSize``. It is either the final output or a
// sequence of outputs at all time steps. - Output Shape:
// ``[1,outputVectorSize]`` , if ``sequenceOutput == false`` - Output Shape:
// ``[Seq,outputVectorSize]`` , if ``sequenceOutput == true``
//
// This layer is described by the following equation:
//
// .. math::
//     \boldsymbol{y_t} = f(\mathrm{clip}(W \boldsymbol{x_t} + \
//                                        R \boldsymbol{y_{t-1}} + b))
//
// - ``W`` is a 2-dimensional weight matrix
//   (``[outputVectorSize, inputVectorSize]``, row-major)
// - ``R`` is a 2-dimensional recursion matrix
//   (``[outputVectorSize, outputVectorSize]``, row-major)
// - ``b`` is a 1-dimensional bias vector (``[outputVectorSize]``)
// - ``f()`` is an activation
// - ``clip()`` is a function that constrains values between ``[-50.0, 50.0]``
type SimpleRecurrentLayerParams struct {
	InputVectorSize  uint64 `protobuf:"varint,1,opt,name=inputVectorSize,proto3" json:"inputVectorSize,omitempty"`
	OutputVectorSize uint64 `protobuf:"varint,2,opt,name=outputVectorSize,proto3" json:"outputVectorSize,omitempty"`
	// *
	// Activations supported are Linear, Sigmoid, Tanh, ReLU, Scaled Tanh (alpha =
	// 1.71, beta = 2/3), Hard sigmoid (alpha = 0.2, beta = 0.5)
	Activation *ActivationParams `protobuf:"bytes,10,opt,name=activation" json:"activation,omitempty"`
	// *
	// If false output is just the result after final state update.
	// If true, output is a sequence, containing outputs at all time steps.
	SequenceOutput  bool          `protobuf:"varint,15,opt,name=sequenceOutput,proto3" json:"sequenceOutput,omitempty"`
	HasBiasVector   bool          `protobuf:"varint,20,opt,name=hasBiasVector,proto3" json:"hasBiasVector,omitempty"`
	WeightMatrix    *WeightParams `protobuf:"bytes,30,opt,name=weightMatrix" json:"weightMatrix,omitempty"`
	RecursionMatrix *WeightParams `protobuf:"bytes,31,opt,name=recursionMatrix" json:"recursionMatrix,omitempty"`
	BiasVector      *WeightParams `protobuf:"bytes,32,opt,name=biasVector" json:"biasVector,omitempty"`
	ReverseInput    bool          `protobuf:"varint,100,opt,name=reverseInput,proto3" json:"reverseInput,omitempty"`
}

func (m *SimpleRecurrentLayerParams) Reset()         { *m = SimpleRecurrentLayerParams{} }
func (m *SimpleRecurrentLayerParams) String() string { return proto.CompactTextString(m) }
func (*SimpleRecurrentLayerParams) ProtoMessage()    {}
func (*SimpleRecurrentLayerParams) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{52}
}

func (m *SimpleRecurrentLayerParams) GetInputVectorSize() uint64 {
	if m != nil {
		return m.InputVectorSize
	}
	return 0
}

func (m *SimpleRecurrentLayerParams) GetOutputVectorSize() uint64 {
	if m != nil {
		return m.OutputVectorSize
	}
	return 0
}

func (m *SimpleRecurrentLayerParams) GetActivation() *ActivationParams {
	if m != nil {
		return m.Activation
	}
	return nil
}

func (m *SimpleRecurrentLayerParams) GetSequenceOutput() bool {
	if m != nil {
		return m.SequenceOutput
	}
	return false
}

func (m *SimpleRecurrentLayerParams) GetHasBiasVector() bool {
	if m != nil {
		return m.HasBiasVector
	}
	return false
}

func (m *SimpleRecurrentLayerParams) GetWeightMatrix() *WeightParams {
	if m != nil {
		return m.WeightMatrix
	}
	return nil
}

func (m *SimpleRecurrentLayerParams) GetRecursionMatrix() *WeightParams {
	if m != nil {
		return m.RecursionMatrix
	}
	return nil
}

func (m *SimpleRecurrentLayerParams) GetBiasVector() *WeightParams {
	if m != nil {
		return m.BiasVector
	}
	return nil
}

func (m *SimpleRecurrentLayerParams) GetReverseInput() bool {
	if m != nil {
		return m.ReverseInput
	}
	return false
}

// *
// Gated-Recurrent Unit (GRU) Layer
// ::
// 		y_t = GRULayer(x_t, y_{t-1})
//
// Input
//    A sequence of vectors of size ``inputVectorSize``
//    with shape ``[Seq, inputVectorSize]``.
// Output
//    A vector of size ``outputVectorSize``. It is either the final output or a
// sequence of outputs at all time steps. - Output Shape:
// ``[1,outputVectorSize]`` , if ``sequenceOutput == false`` - Output Shape:
// ``[Seq,outputVectorSize]`` , if ``sequenceOutput == true``
//
// This layer is described by the following equations:
//
// Update Gate
//     .. math::
//         \boldsymbol{z_t} = \
//             f(\mathrm{clip}(W_z \boldsymbol{x_t} + \
//                             R_z \boldsymbol{y_{t-1}} + b_z)
//
// Reset Gate
//     .. math::
//         \boldsymbol{r_t} = \
//             f(\mathrm{clip}(W_r \boldsymbol{x_t} + \
//                             R_r \boldsymbol{y_{t-1}} + b_r))
//
// Cell Memory State
//     .. math::
//         \boldsymbol{c_t} = \
//             \boldsymbol{y_{t-1}} \odot \boldsymbol{r_t}
//
// Output Gate
//     .. math::
//         \boldsymbol{o_t} = \
//             g(\mathrm{clip}(W_o \boldsymbol{x_t} + \
//                             R_o \boldsymbol{c_t} + b_o))
//
// Output
//     .. math::
//         \boldsymbol{y_t} = \
//             (1 - \boldsymbol{z_t}) \odot \boldsymbol{o_t} + \
//              \boldsymbol{z_t} \odot \boldsymbol{y_{t-1}}
//
// - ``W_z``, ``W_r``, ``W_o`` are 2-dimensional input weight matrices
//   (``[outputVectorSize, inputVectorSize]``, row-major)
// - ``R_z``, ``R_r``, ``R_o`` are 2-dimensional recursion matrices
//   (``[outputVectorSize, outputVectorSize]``, row-major)
// - ``b_z``, ``b_r``, ``b_o`` are 1-dimensional bias vectors
//   (``[outputVectorSize]``)
// - ``f()``, ``g()`` are activations
// - ``clip()`` is a function that constrains values between ``[-50.0, 50.0]``
// - ``⊙`` denotes the elementwise product of matrices
type GRULayerParams struct {
	InputVectorSize  uint64 `protobuf:"varint,1,opt,name=inputVectorSize,proto3" json:"inputVectorSize,omitempty"`
	OutputVectorSize uint64 `protobuf:"varint,2,opt,name=outputVectorSize,proto3" json:"outputVectorSize,omitempty"`
	// *
	// 2 element array representing activations [f(), g()] in that order.
	// Typical values used = [sigmoid, tanh].
	// Activations supported are Linear, Sigmoid, Tanh, ReLU, Scaled Tanh (alpha =
	// 1.71, beta = 2/3), Hard sigmoid (alpha = 0.2, beta = 0.5)
	Activations []*ActivationParams `protobuf:"bytes,10,rep,name=activations" json:"activations,omitempty"`
	// *
	// If false output is just the result after final state update.
	// If true, output is a sequence, containing outputs at all time steps.
	SequenceOutput bool `protobuf:"varint,15,opt,name=sequenceOutput,proto3" json:"sequenceOutput,omitempty"`
	// *
	// If false, no biases (``b_z``, ``b_r``, ``b_o``) are added.
	HasBiasVectors            bool          `protobuf:"varint,20,opt,name=hasBiasVectors,proto3" json:"hasBiasVectors,omitempty"`
	UpdateGateWeightMatrix    *WeightParams `protobuf:"bytes,30,opt,name=updateGateWeightMatrix" json:"updateGateWeightMatrix,omitempty"`
	ResetGateWeightMatrix     *WeightParams `protobuf:"bytes,31,opt,name=resetGateWeightMatrix" json:"resetGateWeightMatrix,omitempty"`
	OutputGateWeightMatrix    *WeightParams `protobuf:"bytes,32,opt,name=outputGateWeightMatrix" json:"outputGateWeightMatrix,omitempty"`
	UpdateGateRecursionMatrix *WeightParams `protobuf:"bytes,50,opt,name=updateGateRecursionMatrix" json:"updateGateRecursionMatrix,omitempty"`
	ResetGateRecursionMatrix  *WeightParams `protobuf:"bytes,51,opt,name=resetGateRecursionMatrix" json:"resetGateRecursionMatrix,omitempty"`
	OutputGateRecursionMatrix *WeightParams `protobuf:"bytes,52,opt,name=outputGateRecursionMatrix" json:"outputGateRecursionMatrix,omitempty"`
	UpdateGateBiasVector      *WeightParams `protobuf:"bytes,70,opt,name=updateGateBiasVector" json:"updateGateBiasVector,omitempty"`
	ResetGateBiasVector       *WeightParams `protobuf:"bytes,71,opt,name=resetGateBiasVector" json:"resetGateBiasVector,omitempty"`
	OutputGateBiasVector      *WeightParams `protobuf:"bytes,72,opt,name=outputGateBiasVector" json:"outputGateBiasVector,omitempty"`
	// / If true, then the node processes the input sequence from right to left
	ReverseInput bool `protobuf:"varint,100,opt,name=reverseInput,proto3" json:"reverseInput,omitempty"`
}

func (m *GRULayerParams) Reset()                    { *m = GRULayerParams{} }
func (m *GRULayerParams) String() string            { return proto.CompactTextString(m) }
func (*GRULayerParams) ProtoMessage()               {}
func (*GRULayerParams) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{53} }

func (m *GRULayerParams) GetInputVectorSize() uint64 {
	if m != nil {
		return m.InputVectorSize
	}
	return 0
}

func (m *GRULayerParams) GetOutputVectorSize() uint64 {
	if m != nil {
		return m.OutputVectorSize
	}
	return 0
}

func (m *GRULayerParams) GetActivations() []*ActivationParams {
	if m != nil {
		return m.Activations
	}
	return nil
}

func (m *GRULayerParams) GetSequenceOutput() bool {
	if m != nil {
		return m.SequenceOutput
	}
	return false
}

func (m *GRULayerParams) GetHasBiasVectors() bool {
	if m != nil {
		return m.HasBiasVectors
	}
	return false
}

func (m *GRULayerParams) GetUpdateGateWeightMatrix() *WeightParams {
	if m != nil {
		return m.UpdateGateWeightMatrix
	}
	return nil
}

func (m *GRULayerParams) GetResetGateWeightMatrix() *WeightParams {
	if m != nil {
		return m.ResetGateWeightMatrix
	}
	return nil
}

func (m *GRULayerParams) GetOutputGateWeightMatrix() *WeightParams {
	if m != nil {
		return m.OutputGateWeightMatrix
	}
	return nil
}

func (m *GRULayerParams) GetUpdateGateRecursionMatrix() *WeightParams {
	if m != nil {
		return m.UpdateGateRecursionMatrix
	}
	return nil
}

func (m *GRULayerParams) GetResetGateRecursionMatrix() *WeightParams {
	if m != nil {
		return m.ResetGateRecursionMatrix
	}
	return nil
}

func (m *GRULayerParams) GetOutputGateRecursionMatrix() *WeightParams {
	if m != nil {
		return m.OutputGateRecursionMatrix
	}
	return nil
}

func (m *GRULayerParams) GetUpdateGateBiasVector() *WeightParams {
	if m != nil {
		return m.UpdateGateBiasVector
	}
	return nil
}

func (m *GRULayerParams) GetResetGateBiasVector() *WeightParams {
	if m != nil {
		return m.ResetGateBiasVector
	}
	return nil
}

func (m *GRULayerParams) GetOutputGateBiasVector() *WeightParams {
	if m != nil {
		return m.OutputGateBiasVector
	}
	return nil
}

func (m *GRULayerParams) GetReverseInput() bool {
	if m != nil {
		return m.ReverseInput
	}
	return false
}

// *
// Long short-term memory (LSTM) parameters.
//
// This is described by the following equations:
//
// Input Gate
//     .. math::
//         \boldsymbol{i_t} = \
//             f(\mathrm{clip}(W_i \boldsymbol{x_t} + \
//                             R_i \boldsymbol{y_{t-1}} + \
//                             p_i \odot c_{t-1} + b_i))
//
// Forget Gate
//     .. math::
//         \boldsymbol{f_t} = \
//             f(\mathrm{clip}(W_f \boldsymbol{x_t} + \
//                             R_f \boldsymbol{y_{t-1}} + \
//                             p_f \odot c_{t-1} + b_f))
//
// Block Input
//     .. math::
//         \boldsymbol{z_t} = \
//             g(\mathrm{clip}(W_z \boldsymbol{x_t} + \
//                             R_z \boldsymbol{y_{t-1}} + b_z))
//
// Cell Memory State
//     .. math::
//         \boldsymbol{c_t} = \
//             \boldsymbol{c_{t-1}} \odot \boldsymbol{f_t} + \
//             \boldsymbol{i_t} \odot \boldsymbol{z_t}
//
// Output Gate
//     .. math::
//         \boldsymbol{o_t} = \
//             f(\mathrm{clip}(W_o \boldsymbol{x_t} + \
//                             R_o \boldsymbol{y_{t-1}} + \
//                             p_o \odot c_t + b_o))
//
// Output
//     .. math::
//         \boldsymbol{y_t} = \
//             h(\boldsymbol{c_t}) \odot \boldsymbol{o_t}
//
// - ``W_i``, ``W_f``, ``W_z``, ``W_o`` are 2-dimensional input weight matrices
//   (``[outputVectorSize, inputVectorSize]``, row-major)
// - ``R_i``, ``R_f``, ``R_z``, ``R_o`` are 2-dimensional recursion matrices
//   (``[outputVectorSize, outputVectorSize]``, row-major)
// - ``b_i``, ``b_f``, ``b_z``, ``b_o`` are 1-dimensional bias vectors
//   (``[outputVectorSize]``)
// - ``p_``, ``p_f``, ``p_o`` are 1-dimensional peephole vectors
//   (``[outputVectorSize]``)
// - ``f()``, ``g()``, ``h()`` are activations
// - ``clip()`` is a function that constrains values between ``[-50.0, 50.0]``
// - ``⊙`` denotes the elementwise product of matrices
type LSTMParams struct {
	// *
	// If true, output is a sequence, containing outputs at all time steps.
	// If false, output is just the result after final state update.
	SequenceOutput bool `protobuf:"varint,10,opt,name=sequenceOutput,proto3" json:"sequenceOutput,omitempty"`
	// *
	// If false, no biases (``b_i``, ``b_f``, ``b_z``, ``b_o``) are added.
	HasBiasVectors bool `protobuf:"varint,20,opt,name=hasBiasVectors,proto3" json:"hasBiasVectors,omitempty"`
	// *
	// If true, a vector of ``1`` values is added to ``b_f``.
	ForgetBias bool `protobuf:"varint,30,opt,name=forgetBias,proto3" json:"forgetBias,omitempty"`
	// *
	// If true, peephole vectors are included.
	HasPeepholeVectors bool `protobuf:"varint,40,opt,name=hasPeepholeVectors,proto3" json:"hasPeepholeVectors,omitempty"`
	// *
	// If the coupled Input and Forget flag is on, the behaviour of
	// ``c_t`` is changed to the following (i.e. forget gate is not used):
	//
	// .. math::
	//     \boldsymbol{c_t} = \
	//         \boldsymbol{c_{t-1}} \odot (1 - \boldsymbol{i_t}) + \
	//         \boldsymbol{i_t} \odot \boldsymbol{z_t}
	//
	CoupledInputAndForgetGate bool `protobuf:"varint,50,opt,name=coupledInputAndForgetGate,proto3" json:"coupledInputAndForgetGate,omitempty"`
	// *
	// Places a limit on the maximum and minimum values of ``c_t``.
	// c_t = min(c_t, cellClipThreshold)
	// c_t = max(c_t, -cellClipThreshold)
	// If 0, it is set to its default value = 50.0.
	CellClipThreshold float32 `protobuf:"fixed32,60,opt,name=cellClipThreshold,proto3" json:"cellClipThreshold,omitempty"`
}

func (m *LSTMParams) Reset()                    { *m = LSTMParams{} }
func (m *LSTMParams) String() string            { return proto.CompactTextString(m) }
func (*LSTMParams) ProtoMessage()               {}
func (*LSTMParams) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{54} }

func (m *LSTMParams) GetSequenceOutput() bool {
	if m != nil {
		return m.SequenceOutput
	}
	return false
}

func (m *LSTMParams) GetHasBiasVectors() bool {
	if m != nil {
		return m.HasBiasVectors
	}
	return false
}

func (m *LSTMParams) GetForgetBias() bool {
	if m != nil {
		return m.ForgetBias
	}
	return false
}

func (m *LSTMParams) GetHasPeepholeVectors() bool {
	if m != nil {
		return m.HasPeepholeVectors
	}
	return false
}

func (m *LSTMParams) GetCoupledInputAndForgetGate() bool {
	if m != nil {
		return m.CoupledInputAndForgetGate
	}
	return false
}

func (m *LSTMParams) GetCellClipThreshold() float32 {
	if m != nil {
		return m.CellClipThreshold
	}
	return 0
}

// *
// Weights for long short-term memory (LSTM) layers
type LSTMWeightParams struct {
	InputGateWeightMatrix     *WeightParams `protobuf:"bytes,1,opt,name=inputGateWeightMatrix" json:"inputGateWeightMatrix,omitempty"`
	ForgetGateWeightMatrix    *WeightParams `protobuf:"bytes,2,opt,name=forgetGateWeightMatrix" json:"forgetGateWeightMatrix,omitempty"`
	BlockInputWeightMatrix    *WeightParams `protobuf:"bytes,3,opt,name=blockInputWeightMatrix" json:"blockInputWeightMatrix,omitempty"`
	OutputGateWeightMatrix    *WeightParams `protobuf:"bytes,4,opt,name=outputGateWeightMatrix" json:"outputGateWeightMatrix,omitempty"`
	InputGateRecursionMatrix  *WeightParams `protobuf:"bytes,20,opt,name=inputGateRecursionMatrix" json:"inputGateRecursionMatrix,omitempty"`
	ForgetGateRecursionMatrix *WeightParams `protobuf:"bytes,21,opt,name=forgetGateRecursionMatrix" json:"forgetGateRecursionMatrix,omitempty"`
	BlockInputRecursionMatrix *WeightParams `protobuf:"bytes,22,opt,name=blockInputRecursionMatrix" json:"blockInputRecursionMatrix,omitempty"`
	OutputGateRecursionMatrix *WeightParams `protobuf:"bytes,23,opt,name=outputGateRecursionMatrix" json:"outputGateRecursionMatrix,omitempty"`
	// biases:
	InputGateBiasVector  *WeightParams `protobuf:"bytes,40,opt,name=inputGateBiasVector" json:"inputGateBiasVector,omitempty"`
	ForgetGateBiasVector *WeightParams `protobuf:"bytes,41,opt,name=forgetGateBiasVector" json:"forgetGateBiasVector,omitempty"`
	BlockInputBiasVector *WeightParams `protobuf:"bytes,42,opt,name=blockInputBiasVector" json:"blockInputBiasVector,omitempty"`
	OutputGateBiasVector *WeightParams `protobuf:"bytes,43,opt,name=outputGateBiasVector" json:"outputGateBiasVector,omitempty"`
	// peepholes:
	InputGatePeepholeVector  *WeightParams `protobuf:"bytes,60,opt,name=inputGatePeepholeVector" json:"inputGatePeepholeVector,omitempty"`
	ForgetGatePeepholeVector *WeightParams `protobuf:"bytes,61,opt,name=forgetGatePeepholeVector" json:"forgetGatePeepholeVector,omitempty"`
	OutputGatePeepholeVector *WeightParams `protobuf:"bytes,62,opt,name=outputGatePeepholeVector" json:"outputGatePeepholeVector,omitempty"`
}

func (m *LSTMWeightParams) Reset()                    { *m = LSTMWeightParams{} }
func (m *LSTMWeightParams) String() string            { return proto.CompactTextString(m) }
func (*LSTMWeightParams) ProtoMessage()               {}
func (*LSTMWeightParams) Descriptor() ([]byte, []int) { return fileDescriptorNeuralNetwork, []int{55} }

func (m *LSTMWeightParams) GetInputGateWeightMatrix() *WeightParams {
	if m != nil {
		return m.InputGateWeightMatrix
	}
	return nil
}

func (m *LSTMWeightParams) GetForgetGateWeightMatrix() *WeightParams {
	if m != nil {
		return m.ForgetGateWeightMatrix
	}
	return nil
}

func (m *LSTMWeightParams) GetBlockInputWeightMatrix() *WeightParams {
	if m != nil {
		return m.BlockInputWeightMatrix
	}
	return nil
}

func (m *LSTMWeightParams) GetOutputGateWeightMatrix() *WeightParams {
	if m != nil {
		return m.OutputGateWeightMatrix
	}
	return nil
}

func (m *LSTMWeightParams) GetInputGateRecursionMatrix() *WeightParams {
	if m != nil {
		return m.InputGateRecursionMatrix
	}
	return nil
}

func (m *LSTMWeightParams) GetForgetGateRecursionMatrix() *WeightParams {
	if m != nil {
		return m.ForgetGateRecursionMatrix
	}
	return nil
}

func (m *LSTMWeightParams) GetBlockInputRecursionMatrix() *WeightParams {
	if m != nil {
		return m.BlockInputRecursionMatrix
	}
	return nil
}

func (m *LSTMWeightParams) GetOutputGateRecursionMatrix() *WeightParams {
	if m != nil {
		return m.OutputGateRecursionMatrix
	}
	return nil
}

func (m *LSTMWeightParams) GetInputGateBiasVector() *WeightParams {
	if m != nil {
		return m.InputGateBiasVector
	}
	return nil
}

func (m *LSTMWeightParams) GetForgetGateBiasVector() *WeightParams {
	if m != nil {
		return m.ForgetGateBiasVector
	}
	return nil
}

func (m *LSTMWeightParams) GetBlockInputBiasVector() *WeightParams {
	if m != nil {
		return m.BlockInputBiasVector
	}
	return nil
}

func (m *LSTMWeightParams) GetOutputGateBiasVector() *WeightParams {
	if m != nil {
		return m.OutputGateBiasVector
	}
	return nil
}

func (m *LSTMWeightParams) GetInputGatePeepholeVector() *WeightParams {
	if m != nil {
		return m.InputGatePeepholeVector
	}
	return nil
}

func (m *LSTMWeightParams) GetForgetGatePeepholeVector() *WeightParams {
	if m != nil {
		return m.ForgetGatePeepholeVector
	}
	return nil
}

func (m *LSTMWeightParams) GetOutputGatePeepholeVector() *WeightParams {
	if m != nil {
		return m.OutputGatePeepholeVector
	}
	return nil
}

// *
// A unidirectional long short-term memory (LSTM) layer.
// ::
// 		(y_t, c_t) = UniDirectionalLSTMLayer(x_t, y_{t-1}, c_{t-1})
//
// Input
//    A sequence of vectors of size ``inputVectorSize``
//    with shape ``[Seq, inputVectorSize]``.
// Output
//    A vector of size ``outputVectorSize``. It is either the final output or a
// sequence of outputs at all time steps. - Output Shape:
// ``[1,outputVectorSize]`` , if ``sequenceOutput == false`` - Output Shape:
// ``[Seq,outputVectorSize]`` , if ``sequenceOutput == true``
//
type UniDirectionalLSTMLayerParams struct {
	InputVectorSize  uint64 `protobuf:"varint,1,opt,name=inputVectorSize,proto3" json:"inputVectorSize,omitempty"`
	OutputVectorSize uint64 `protobuf:"varint,2,opt,name=outputVectorSize,proto3" json:"outputVectorSize,omitempty"`
	// *
	// 3 element array representing activations [f(),g(),h()] in that order.
	// Typical values used = [sigmoid, tanh, tanh].
	// Activations supported are Linear, Sigmoid, Tanh, ReLU, Scaled Tanh (alpha =
	// 1.71, beta = 2/3), Hard sigmoid (alpha = 0.2, beta = 0.5)
	Activations  []*ActivationParams `protobuf:"bytes,10,rep,name=activations" json:"activations,omitempty"`
	Params       *LSTMParams         `protobuf:"bytes,15,opt,name=params" json:"params,omitempty"`
	WeightParams *LSTMWeightParams   `protobuf:"bytes,20,opt,name=weightParams" json:"weightParams,omitempty"`
	// / If true, then the node processes the input sequence from right to left
	ReverseInput bool `protobuf:"varint,100,opt,name=reverseInput,proto3" json:"reverseInput,omitempty"`
}

func (m *UniDirectionalLSTMLayerParams) Reset()         { *m = UniDirectionalLSTMLayerParams{} }
func (m *UniDirectionalLSTMLayerParams) String() string { return proto.CompactTextString(m) }
func (*UniDirectionalLSTMLayerParams) ProtoMessage()    {}
func (*UniDirectionalLSTMLayerParams) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{56}
}

func (m *UniDirectionalLSTMLayerParams) GetInputVectorSize() uint64 {
	if m != nil {
		return m.InputVectorSize
	}
	return 0
}

func (m *UniDirectionalLSTMLayerParams) GetOutputVectorSize() uint64 {
	if m != nil {
		return m.OutputVectorSize
	}
	return 0
}

func (m *UniDirectionalLSTMLayerParams) GetActivations() []*ActivationParams {
	if m != nil {
		return m.Activations
	}
	return nil
}

func (m *UniDirectionalLSTMLayerParams) GetParams() *LSTMParams {
	if m != nil {
		return m.Params
	}
	return nil
}

func (m *UniDirectionalLSTMLayerParams) GetWeightParams() *LSTMWeightParams {
	if m != nil {
		return m.WeightParams
	}
	return nil
}

func (m *UniDirectionalLSTMLayerParams) GetReverseInput() bool {
	if m != nil {
		return m.ReverseInput
	}
	return false
}

// *
// Bidirectional long short-term memory (LSTM) layer
// ::
// 		(y_t, c_t, y_t_reverse, c_t_reverse) = BiDirectionalLSTMLayer(x_t,
// y_{t-1}, c_{t-1}, y_{t-1}_reverse, c_{t-1}_reverse)
//
// Input
//    A sequence of vectors of size ``inputVectorSize``
//    with shape ``[Seq, inputVectorSize]``.
// Output
//    A vector of size ``2 * outputVectorSize``. It is either the final output
// or a sequence of outputs at all time steps. - Output Shape: ``[1, 2 *
// outputVectorSize]`` , if ``sequenceOutput == false`` - Output Shape: ``[Seq,
// 2 * outputVectorSize]`` , if ``sequenceOutput == true``
//
// The first LSTM operates on the input sequence in the forward direction.
// The second LSTM operates on the input sequence in the reverse direction.
//
// Example: given the input sequence ``[x_1, x_2, x_3]``,
// where ``x_i`` are vectors at time index ``i``:
//
// The forward LSTM output is ``[yf_1, yf_2, yf_3]``,
//
// where ``yf_i`` are vectors of size ``outputVectorSize``:
//
// - ``yf_1`` is the output at the end of sequence {``x_1``}
// - ``yf_2`` is the output at the end of sequence {``x_1``, ``x_2``}
// - ``yf_3`` is the output at the end of sequence {``x_1``, ``x_2``, ``x_3``}
//
// The backward LSTM output: ``[yb_1, yb_2, yb_3]``,
//
// where ``yb_i`` are vectors of size ``outputVectorSize``:
//
// - ``yb_1`` is the output at the end of sequence {``x_3``}
// - ``yb_2`` is the output at the end of sequence {``x_3``, ``x_2``}
// - ``yb_3`` is the output at the end of sequence {``x_3``, ``x_2``, ``x_1``}
//
// Output of the bi-dir layer:
//
// - if ``sequenceOutput = True`` : { ``[yf_1, yb_3]``,  ``[yf_2, yb_2]``,
// ``[yf_3, yb_1]`` } - if ``sequenceOutput = False`` : { ``[yf_3, yb_3]`` }
type BiDirectionalLSTMLayerParams struct {
	// *
	// Size of the input vectors.
	InputVectorSize uint64 `protobuf:"varint,1,opt,name=inputVectorSize,proto3" json:"inputVectorSize,omitempty"`
	// *
	// Size of the outputs vectors.
	// It is same for both forward and backward LSTMs.
	OutputVectorSize uint64 `protobuf:"varint,2,opt,name=outputVectorSize,proto3" json:"outputVectorSize,omitempty"`
	// *
	// 3 element array representing activations [f(),g(),h()] in that order.
	// Typical values used = [sigmoid, tanh, tanh].
	// Activations supported are Linear, Sigmoid, Tanh, ReLU, Scaled Tanh (alpha =
	// 1.71, beta = 2/3), Hard sigmoid (alpha = 0.2, beta = 0.5)
	ActivationsForwardLSTM []*ActivationParams `protobuf:"bytes,10,rep,name=activationsForwardLSTM" json:"activationsForwardLSTM,omitempty"`
	// *
	// Currently, backward LSTM activations
	// must be same as the ones for the forward LSTM.
	ActivationsBackwardLSTM []*ActivationParams `protobuf:"bytes,11,rep,name=activationsBackwardLSTM" json:"activationsBackwardLSTM,omitempty"`
	// *
	// Common parameters shared by the forward and backward LSTMs.
	Params *LSTMParams `protobuf:"bytes,15,opt,name=params" json:"params,omitempty"`
	// *
	// Weights and biases.
	// Must be a length 2 message,
	// for the forward and backward LSTM respectively.
	WeightParams []*LSTMWeightParams `protobuf:"bytes,20,rep,name=weightParams" json:"weightParams,omitempty"`
}

func (m *BiDirectionalLSTMLayerParams) Reset()         { *m = BiDirectionalLSTMLayerParams{} }
func (m *BiDirectionalLSTMLayerParams) String() string { return proto.CompactTextString(m) }
func (*BiDirectionalLSTMLayerParams) ProtoMessage()    {}
func (*BiDirectionalLSTMLayerParams) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{57}
}

func (m *BiDirectionalLSTMLayerParams) GetInputVectorSize() uint64 {
	if m != nil {
		return m.InputVectorSize
	}
	return 0
}

func (m *BiDirectionalLSTMLayerParams) GetOutputVectorSize() uint64 {
	if m != nil {
		return m.OutputVectorSize
	}
	return 0
}

func (m *BiDirectionalLSTMLayerParams) GetActivationsForwardLSTM() []*ActivationParams {
	if m != nil {
		return m.ActivationsForwardLSTM
	}
	return nil
}

func (m *BiDirectionalLSTMLayerParams) GetActivationsBackwardLSTM() []*ActivationParams {
	if m != nil {
		return m.ActivationsBackwardLSTM
	}
	return nil
}

func (m *BiDirectionalLSTMLayerParams) GetParams() *LSTMParams {
	if m != nil {
		return m.Params
	}
	return nil
}

func (m *BiDirectionalLSTMLayerParams) GetWeightParams() []*LSTMWeightParams {
	if m != nil {
		return m.WeightParams
	}
	return nil
}

// *
// A neural network specialized as a classifier.
type NeuralNetworkClassifier struct {
	Layers        []*NeuralNetworkLayer         `protobuf:"bytes,1,rep,name=layers" json:"layers,omitempty"`
	Preprocessing []*NeuralNetworkPreprocessing `protobuf:"bytes,2,rep,name=preprocessing" json:"preprocessing,omitempty"`
	// *
	// Mapping from indexed vector of probabilities to class label
	//
	// Types that are valid to be assigned to ClassLabels:
	//	*NeuralNetworkClassifier_StringClassLabels
	//	*NeuralNetworkClassifier_Int64ClassLabels
	ClassLabels isNeuralNetworkClassifier_ClassLabels `protobuf_oneof:"ClassLabels"`
}

func (m *NeuralNetworkClassifier) Reset()         { *m = NeuralNetworkClassifier{} }
func (m *NeuralNetworkClassifier) String() string { return proto.CompactTextString(m) }
func (*NeuralNetworkClassifier) ProtoMessage()    {}
func (*NeuralNetworkClassifier) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{58}
}

type isNeuralNetworkClassifier_ClassLabels interface {
	isNeuralNetworkClassifier_ClassLabels()
	MarshalTo([]byte) (int, error)
	Size() int
}

type NeuralNetworkClassifier_StringClassLabels struct {
	StringClassLabels *StringVector `protobuf:"bytes,100,opt,name=stringClassLabels,oneof"`
}
type NeuralNetworkClassifier_Int64ClassLabels struct {
	Int64ClassLabels *Int64Vector `protobuf:"bytes,101,opt,name=int64ClassLabels,oneof"`
}

func (*NeuralNetworkClassifier_StringClassLabels) isNeuralNetworkClassifier_ClassLabels() {}
func (*NeuralNetworkClassifier_Int64ClassLabels) isNeuralNetworkClassifier_ClassLabels()  {}

func (m *NeuralNetworkClassifier) GetClassLabels() isNeuralNetworkClassifier_ClassLabels {
	if m != nil {
		return m.ClassLabels
	}
	return nil
}

func (m *NeuralNetworkClassifier) GetLayers() []*NeuralNetworkLayer {
	if m != nil {
		return m.Layers
	}
	return nil
}

func (m *NeuralNetworkClassifier) GetPreprocessing() []*NeuralNetworkPreprocessing {
	if m != nil {
		return m.Preprocessing
	}
	return nil
}

func (m *NeuralNetworkClassifier) GetStringClassLabels() *StringVector {
	if x, ok := m.GetClassLabels().(*NeuralNetworkClassifier_StringClassLabels); ok {
		return x.StringClassLabels
	}
	return nil
}

func (m *NeuralNetworkClassifier) GetInt64ClassLabels() *Int64Vector {
	if x, ok := m.GetClassLabels().(*NeuralNetworkClassifier_Int64ClassLabels); ok {
		return x.Int64ClassLabels
	}
	return nil
}

// XXX_OneofFuncs is for the internal use of the proto package.
func (*NeuralNetworkClassifier) XXX_OneofFuncs() (func(msg proto.Message, b *proto.Buffer) error, func(msg proto.Message, tag, wire int, b *proto.Buffer) (bool, error), func(msg proto.Message) (n int), []interface{}) {
	return _NeuralNetworkClassifier_OneofMarshaler, _NeuralNetworkClassifier_OneofUnmarshaler, _NeuralNetworkClassifier_OneofSizer, []interface{}{
		(*NeuralNetworkClassifier_StringClassLabels)(nil),
		(*NeuralNetworkClassifier_Int64ClassLabels)(nil),
	}
}

func _NeuralNetworkClassifier_OneofMarshaler(msg proto.Message, b *proto.Buffer) error {
	m := msg.(*NeuralNetworkClassifier)
	// ClassLabels
	switch x := m.ClassLabels.(type) {
	case *NeuralNetworkClassifier_StringClassLabels:
		_ = b.EncodeVarint(100<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.StringClassLabels); err != nil {
			return err
		}
	case *NeuralNetworkClassifier_Int64ClassLabels:
		_ = b.EncodeVarint(101<<3 | proto.WireBytes)
		if err := b.EncodeMessage(x.Int64ClassLabels); err != nil {
			return err
		}
	case nil:
	default:
		return fmt.Errorf("NeuralNetworkClassifier.ClassLabels has unexpected type %T", x)
	}
	return nil
}

func _NeuralNetworkClassifier_OneofUnmarshaler(msg proto.Message, tag, wire int, b *proto.Buffer) (bool, error) {
	m := msg.(*NeuralNetworkClassifier)
	switch tag {
	case 100: // ClassLabels.stringClassLabels
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(StringVector)
		err := b.DecodeMessage(msg)
		m.ClassLabels = &NeuralNetworkClassifier_StringClassLabels{msg}
		return true, err
	case 101: // ClassLabels.int64ClassLabels
		if wire != proto.WireBytes {
			return true, proto.ErrInternalBadWireType
		}
		msg := new(Int64Vector)
		err := b.DecodeMessage(msg)
		m.ClassLabels = &NeuralNetworkClassifier_Int64ClassLabels{msg}
		return true, err
	default:
		return false, nil
	}
}

func _NeuralNetworkClassifier_OneofSizer(msg proto.Message) (n int) {
	m := msg.(*NeuralNetworkClassifier)
	// ClassLabels
	switch x := m.ClassLabels.(type) {
	case *NeuralNetworkClassifier_StringClassLabels:
		s := proto.Size(x.StringClassLabels)
		n += proto.SizeVarint(100<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case *NeuralNetworkClassifier_Int64ClassLabels:
		s := proto.Size(x.Int64ClassLabels)
		n += proto.SizeVarint(101<<3 | proto.WireBytes)
		n += proto.SizeVarint(uint64(s))
		n += s
	case nil:
	default:
		panic(fmt.Sprintf("proto: unexpected type %T in oneof", x))
	}
	return n
}

// *
// A neural network specialized as a regressor.
type NeuralNetworkRegressor struct {
	Layers        []*NeuralNetworkLayer         `protobuf:"bytes,1,rep,name=layers" json:"layers,omitempty"`
	Preprocessing []*NeuralNetworkPreprocessing `protobuf:"bytes,2,rep,name=preprocessing" json:"preprocessing,omitempty"`
}

func (m *NeuralNetworkRegressor) Reset()         { *m = NeuralNetworkRegressor{} }
func (m *NeuralNetworkRegressor) String() string { return proto.CompactTextString(m) }
func (*NeuralNetworkRegressor) ProtoMessage()    {}
func (*NeuralNetworkRegressor) Descriptor() ([]byte, []int) {
	return fileDescriptorNeuralNetwork, []int{59}
}

func (m *NeuralNetworkRegressor) GetLayers() []*NeuralNetworkLayer {
	if m != nil {
		return m.Layers
	}
	return nil
}

func (m *NeuralNetworkRegressor) GetPreprocessing() []*NeuralNetworkPreprocessing {
	if m != nil {
		return m.Preprocessing
	}
	return nil
}

func init() {
	proto.RegisterType((*NeuralNetwork)(nil), "CoreML.NeuralNetwork")
	proto.RegisterType((*NeuralNetworkImageScaler)(nil), "CoreML.NeuralNetworkImageScaler")
	proto.RegisterType((*NeuralNetworkMeanImage)(nil), "CoreML.NeuralNetworkMeanImage")
	proto.RegisterType((*NeuralNetworkPreprocessing)(nil), "CoreML.NeuralNetworkPreprocessing")
	proto.RegisterType((*ActivationReLU)(nil), "CoreML.ActivationReLU")
	proto.RegisterType((*ActivationLeakyReLU)(nil), "CoreML.ActivationLeakyReLU")
	proto.RegisterType((*ActivationTanh)(nil), "CoreML.ActivationTanh")
	proto.RegisterType((*ActivationScaledTanh)(nil), "CoreML.ActivationScaledTanh")
	proto.RegisterType((*ActivationSigmoid)(nil), "CoreML.ActivationSigmoid")
	proto.RegisterType((*ActivationLinear)(nil), "CoreML.ActivationLinear")
	proto.RegisterType((*ActivationSigmoidHard)(nil), "CoreML.ActivationSigmoidHard")
	proto.RegisterType((*ActivationPReLU)(nil), "CoreML.ActivationPReLU")
	proto.RegisterType((*ActivationELU)(nil), "CoreML.ActivationELU")
	proto.RegisterType((*ActivationThresholdedReLU)(nil), "CoreML.ActivationThresholdedReLU")
	proto.RegisterType((*ActivationSoftsign)(nil), "CoreML.ActivationSoftsign")
	proto.RegisterType((*ActivationSoftplus)(nil), "CoreML.ActivationSoftplus")
	proto.RegisterType((*ActivationParametricSoftplus)(nil), "CoreML.ActivationParametricSoftplus")
	proto.RegisterType((*ActivationParams)(nil), "CoreML.ActivationParams")
	proto.RegisterType((*NeuralNetworkLayer)(nil), "CoreML.NeuralNetworkLayer")
	proto.RegisterType((*BorderAmounts)(nil), "CoreML.BorderAmounts")
	proto.RegisterType((*BorderAmounts_EdgeSizes)(nil), "CoreML.BorderAmounts.EdgeSizes")
	proto.RegisterType((*ValidPadding)(nil), "CoreML.ValidPadding")
	proto.RegisterType((*SamePadding)(nil), "CoreML.SamePadding")
	proto.RegisterType((*WeightParams)(nil), "CoreML.WeightParams")
	proto.RegisterType((*ConvolutionLayerParams)(nil), "CoreML.ConvolutionLayerParams")
	proto.RegisterType((*InnerProductLayerParams)(nil), "CoreML.InnerProductLayerParams")
	proto.RegisterType((*EmbeddingLayerParams)(nil), "CoreML.EmbeddingLayerParams")
	proto.RegisterType((*BatchnormLayerParams)(nil), "CoreML.BatchnormLayerParams")
	proto.RegisterType((*PoolingLayerParams)(nil), "CoreML.PoolingLayerParams")
	proto.RegisterType((*PoolingLayerParams_ValidCompletePadding)(nil), "CoreML.PoolingLayerParams.ValidCompletePadding")
	proto.RegisterType((*PaddingLayerParams)(nil), "CoreML.PaddingLayerParams")
	proto.RegisterType((*PaddingLayerParams_PaddingConstant)(nil), "CoreML.PaddingLayerParams.PaddingConstant")
	proto.RegisterType((*PaddingLayerParams_PaddingReflection)(nil), "CoreML.PaddingLayerParams.PaddingReflection")
	proto.RegisterType((*PaddingLayerParams_PaddingReplication)(nil), "CoreML.PaddingLayerParams.PaddingReplication")
	proto.RegisterType((*ConcatLayerParams)(nil), "CoreML.ConcatLayerParams")
	proto.RegisterType((*LRNLayerParams)(nil), "CoreML.LRNLayerParams")
	proto.RegisterType((*SoftmaxLayerParams)(nil), "CoreML.SoftmaxLayerParams")
	proto.RegisterType((*SplitLayerParams)(nil), "CoreML.SplitLayerParams")
	proto.RegisterType((*AddLayerParams)(nil), "CoreML.AddLayerParams")
	proto.RegisterType((*MultiplyLayerParams)(nil), "CoreML.MultiplyLayerParams")
	proto.RegisterType((*UnaryFunctionLayerParams)(nil), "CoreML.UnaryFunctionLayerParams")
	proto.RegisterType((*UpsampleLayerParams)(nil), "CoreML.UpsampleLayerParams")
	proto.RegisterType((*BiasLayerParams)(nil), "CoreML.BiasLayerParams")
	proto.RegisterType((*ScaleLayerParams)(nil), "CoreML.ScaleLayerParams")
	proto.RegisterType((*LoadConstantLayerParams)(nil), "CoreML.LoadConstantLayerParams")
	proto.RegisterType((*L2NormalizeLayerParams)(nil), "CoreML.L2NormalizeLayerParams")
	proto.RegisterType((*FlattenLayerParams)(nil), "CoreML.FlattenLayerParams")
	proto.RegisterType((*ReshapeLayerParams)(nil), "CoreML.ReshapeLayerParams")
	proto.RegisterType((*PermuteLayerParams)(nil), "CoreML.PermuteLayerParams")
	proto.RegisterType((*ReduceLayerParams)(nil), "CoreML.ReduceLayerParams")
	proto.RegisterType((*CropLayerParams)(nil), "CoreML.CropLayerParams")
	proto.RegisterType((*AverageLayerParams)(nil), "CoreML.AverageLayerParams")
	proto.RegisterType((*MaxLayerParams)(nil), "CoreML.MaxLayerParams")
	proto.RegisterType((*MinLayerParams)(nil), "CoreML.MinLayerParams")
	proto.RegisterType((*DotProductLayerParams)(nil), "CoreML.DotProductLayerParams")
	proto.RegisterType((*MeanVarianceNormalizeLayerParams)(nil), "CoreML.MeanVarianceNormalizeLayerParams")
	proto.RegisterType((*SequenceRepeatLayerParams)(nil), "CoreML.SequenceRepeatLayerParams")
	proto.RegisterType((*SimpleRecurrentLayerParams)(nil), "CoreML.SimpleRecurrentLayerParams")
	proto.RegisterType((*GRULayerParams)(nil), "CoreML.GRULayerParams")
	proto.RegisterType((*LSTMParams)(nil), "CoreML.LSTMParams")
	proto.RegisterType((*LSTMWeightParams)(nil), "CoreML.LSTMWeightParams")
	proto.RegisterType((*UniDirectionalLSTMLayerParams)(nil), "CoreML.UniDirectionalLSTMLayerParams")
	proto.RegisterType((*BiDirectionalLSTMLayerParams)(nil), "CoreML.BiDirectionalLSTMLayerParams")
	proto.RegisterType((*NeuralNetworkClassifier)(nil), "CoreML.NeuralNetworkClassifier")
	proto.RegisterType((*NeuralNetworkRegressor)(nil), "CoreML.NeuralNetworkRegressor")
	proto.RegisterEnum("CoreML.SamePadding_SamePaddingMode", SamePadding_SamePaddingMode_name, SamePadding_SamePaddingMode_value)
	proto.RegisterEnum("CoreML.PoolingLayerParams_PoolingType", PoolingLayerParams_PoolingType_name, PoolingLayerParams_PoolingType_value)
	proto.RegisterEnum("CoreML.UnaryFunctionLayerParams_Operation", UnaryFunctionLayerParams_Operation_name, UnaryFunctionLayerParams_Operation_value)
	proto.RegisterEnum("CoreML.FlattenLayerParams_FlattenOrder", FlattenLayerParams_FlattenOrder_name, FlattenLayerParams_FlattenOrder_value)
	proto.RegisterEnum("CoreML.ReshapeLayerParams_ReshapeOrder", ReshapeLayerParams_ReshapeOrder_name, ReshapeLayerParams_ReshapeOrder_value)
	proto.RegisterEnum("CoreML.ReduceLayerParams_ReduceOperation", ReduceLayerParams_ReduceOperation_name, ReduceLayerParams_ReduceOperation_value)
}
func (m *NeuralNetwork) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *NeuralNetwork) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.Layers) > 0 {
		for _, msg := range m.Layers {
			dAtA[i] = 0xa
			i++
			i = encodeVarintNeuralNetwork(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	if len(m.Preprocessing) > 0 {
		for _, msg := range m.Preprocessing {
			dAtA[i] = 0x12
			i++
			i = encodeVarintNeuralNetwork(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	return i, nil
}

func (m *NeuralNetworkImageScaler) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *NeuralNetworkImageScaler) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.ChannelScale != 0 {
		dAtA[i] = 0x55
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.ChannelScale))))
	}
	if m.BlueBias != 0 {
		dAtA[i] = 0xa5
		i++
		dAtA[i] = 0x1
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.BlueBias))))
	}
	if m.GreenBias != 0 {
		dAtA[i] = 0xad
		i++
		dAtA[i] = 0x1
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.GreenBias))))
	}
	if m.RedBias != 0 {
		dAtA[i] = 0xb5
		i++
		dAtA[i] = 0x1
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.RedBias))))
	}
	if m.GrayBias != 0 {
		dAtA[i] = 0xf5
		i++
		dAtA[i] = 0x1
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.GrayBias))))
	}
	return i, nil
}

func (m *NeuralNetworkMeanImage) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *NeuralNetworkMeanImage) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.MeanImage) > 0 {
		dAtA[i] = 0xa
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(len(m.MeanImage)*4))
		for _, num := range m.MeanImage {
			f1 := math.Float32bits(float32(num))
			dAtA[i] = uint8(f1)
			i++
			dAtA[i] = uint8(f1 >> 8)
			i++
			dAtA[i] = uint8(f1 >> 16)
			i++
			dAtA[i] = uint8(f1 >> 24)
			i++
		}
	}
	return i, nil
}

func (m *NeuralNetworkPreprocessing) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *NeuralNetworkPreprocessing) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.FeatureName) > 0 {
		dAtA[i] = 0xa
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(len(m.FeatureName)))
		i += copy(dAtA[i:], m.FeatureName)
	}
	if m.Preprocessor != nil {
		nn2, err := m.Preprocessor.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += nn2
	}
	return i, nil
}

func (m *NeuralNetworkPreprocessing_Scaler) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Scaler != nil {
		dAtA[i] = 0x52
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Scaler.Size()))
		n3, err := m.Scaler.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n3
	}
	return i, nil
}
func (m *NeuralNetworkPreprocessing_MeanImage) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.MeanImage != nil {
		dAtA[i] = 0x5a
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.MeanImage.Size()))
		n4, err := m.MeanImage.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n4
	}
	return i, nil
}
func (m *ActivationReLU) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ActivationReLU) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	return i, nil
}

func (m *ActivationLeakyReLU) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ActivationLeakyReLU) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.Alpha != 0 {
		dAtA[i] = 0xd
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.Alpha))))
	}
	return i, nil
}

func (m *ActivationTanh) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ActivationTanh) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	return i, nil
}

func (m *ActivationScaledTanh) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ActivationScaledTanh) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.Alpha != 0 {
		dAtA[i] = 0xd
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.Alpha))))
	}
	if m.Beta != 0 {
		dAtA[i] = 0x15
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.Beta))))
	}
	return i, nil
}

func (m *ActivationSigmoid) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ActivationSigmoid) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	return i, nil
}

func (m *ActivationLinear) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ActivationLinear) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.Alpha != 0 {
		dAtA[i] = 0xd
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.Alpha))))
	}
	if m.Beta != 0 {
		dAtA[i] = 0x15
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.Beta))))
	}
	return i, nil
}

func (m *ActivationSigmoidHard) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ActivationSigmoidHard) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.Alpha != 0 {
		dAtA[i] = 0xd
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.Alpha))))
	}
	if m.Beta != 0 {
		dAtA[i] = 0x15
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.Beta))))
	}
	return i, nil
}

func (m *ActivationPReLU) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ActivationPReLU) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.Alpha != nil {
		dAtA[i] = 0xa
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Alpha.Size()))
		n5, err := m.Alpha.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n5
	}
	return i, nil
}

func (m *ActivationELU) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ActivationELU) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.Alpha != 0 {
		dAtA[i] = 0xd
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.Alpha))))
	}
	return i, nil
}

func (m *ActivationThresholdedReLU) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ActivationThresholdedReLU) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.Alpha != 0 {
		dAtA[i] = 0xd
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.Alpha))))
	}
	return i, nil
}

func (m *ActivationSoftsign) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ActivationSoftsign) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	return i, nil
}

func (m *ActivationSoftplus) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ActivationSoftplus) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	return i, nil
}

func (m *ActivationParametricSoftplus) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ActivationParametricSoftplus) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.Alpha != nil {
		dAtA[i] = 0xa
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Alpha.Size()))
		n6, err := m.Alpha.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n6
	}
	if m.Beta != nil {
		dAtA[i] = 0x12
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Beta.Size()))
		n7, err := m.Beta.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n7
	}
	return i, nil
}

func (m *ActivationParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ActivationParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.NonlinearityType != nil {
		nn8, err := m.NonlinearityType.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += nn8
	}
	return i, nil
}

func (m *ActivationParams_Linear) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Linear != nil {
		dAtA[i] = 0x2a
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Linear.Size()))
		n9, err := m.Linear.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n9
	}
	return i, nil
}
func (m *ActivationParams_ReLU) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.ReLU != nil {
		dAtA[i] = 0x52
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.ReLU.Size()))
		n10, err := m.ReLU.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n10
	}
	return i, nil
}
func (m *ActivationParams_LeakyReLU) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.LeakyReLU != nil {
		dAtA[i] = 0x7a
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.LeakyReLU.Size()))
		n11, err := m.LeakyReLU.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n11
	}
	return i, nil
}
func (m *ActivationParams_ThresholdedReLU) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.ThresholdedReLU != nil {
		dAtA[i] = 0xa2
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.ThresholdedReLU.Size()))
		n12, err := m.ThresholdedReLU.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n12
	}
	return i, nil
}
func (m *ActivationParams_PReLU) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.PReLU != nil {
		dAtA[i] = 0xca
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.PReLU.Size()))
		n13, err := m.PReLU.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n13
	}
	return i, nil
}
func (m *ActivationParams_Tanh) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Tanh != nil {
		dAtA[i] = 0xf2
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Tanh.Size()))
		n14, err := m.Tanh.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n14
	}
	return i, nil
}
func (m *ActivationParams_ScaledTanh) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.ScaledTanh != nil {
		dAtA[i] = 0xfa
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.ScaledTanh.Size()))
		n15, err := m.ScaledTanh.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n15
	}
	return i, nil
}
func (m *ActivationParams_Sigmoid) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Sigmoid != nil {
		dAtA[i] = 0xc2
		i++
		dAtA[i] = 0x2
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Sigmoid.Size()))
		n16, err := m.Sigmoid.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n16
	}
	return i, nil
}
func (m *ActivationParams_SigmoidHard) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.SigmoidHard != nil {
		dAtA[i] = 0xca
		i++
		dAtA[i] = 0x2
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.SigmoidHard.Size()))
		n17, err := m.SigmoidHard.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n17
	}
	return i, nil
}
func (m *ActivationParams_ELU) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.ELU != nil {
		dAtA[i] = 0x92
		i++
		dAtA[i] = 0x3
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.ELU.Size()))
		n18, err := m.ELU.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n18
	}
	return i, nil
}
func (m *ActivationParams_Softsign) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Softsign != nil {
		dAtA[i] = 0xe2
		i++
		dAtA[i] = 0x3
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Softsign.Size()))
		n19, err := m.Softsign.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n19
	}
	return i, nil
}
func (m *ActivationParams_Softplus) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Softplus != nil {
		dAtA[i] = 0xb2
		i++
		dAtA[i] = 0x4
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Softplus.Size()))
		n20, err := m.Softplus.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n20
	}
	return i, nil
}
func (m *ActivationParams_ParametricSoftplus) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.ParametricSoftplus != nil {
		dAtA[i] = 0xba
		i++
		dAtA[i] = 0x4
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.ParametricSoftplus.Size()))
		n21, err := m.ParametricSoftplus.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n21
	}
	return i, nil
}
func (m *NeuralNetworkLayer) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *NeuralNetworkLayer) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.Name) > 0 {
		dAtA[i] = 0xa
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(len(m.Name)))
		i += copy(dAtA[i:], m.Name)
	}
	if len(m.Input) > 0 {
		for _, s := range m.Input {
			dAtA[i] = 0x12
			i++
			l = len(s)
			for l >= 1<<7 {
				dAtA[i] = uint8(uint64(l)&0x7f | 0x80)
				l >>= 7
				i++
			}
			dAtA[i] = uint8(l)
			i++
			i += copy(dAtA[i:], s)
		}
	}
	if len(m.Output) > 0 {
		for _, s := range m.Output {
			dAtA[i] = 0x1a
			i++
			l = len(s)
			for l >= 1<<7 {
				dAtA[i] = uint8(uint64(l)&0x7f | 0x80)
				l >>= 7
				i++
			}
			dAtA[i] = uint8(l)
			i++
			i += copy(dAtA[i:], s)
		}
	}
	if m.Layer != nil {
		nn22, err := m.Layer.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += nn22
	}
	return i, nil
}

func (m *NeuralNetworkLayer_Convolution) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Convolution != nil {
		dAtA[i] = 0xa2
		i++
		dAtA[i] = 0x6
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Convolution.Size()))
		n23, err := m.Convolution.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n23
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Pooling) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Pooling != nil {
		dAtA[i] = 0xc2
		i++
		dAtA[i] = 0x7
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Pooling.Size()))
		n24, err := m.Pooling.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n24
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Activation) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Activation != nil {
		dAtA[i] = 0x92
		i++
		dAtA[i] = 0x8
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Activation.Size()))
		n25, err := m.Activation.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n25
	}
	return i, nil
}
func (m *NeuralNetworkLayer_InnerProduct) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.InnerProduct != nil {
		dAtA[i] = 0xe2
		i++
		dAtA[i] = 0x8
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.InnerProduct.Size()))
		n26, err := m.InnerProduct.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n26
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Embedding) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Embedding != nil {
		dAtA[i] = 0xb2
		i++
		dAtA[i] = 0x9
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Embedding.Size()))
		n27, err := m.Embedding.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n27
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Batchnorm) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Batchnorm != nil {
		dAtA[i] = 0x82
		i++
		dAtA[i] = 0xa
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Batchnorm.Size()))
		n28, err := m.Batchnorm.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n28
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Mvn) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Mvn != nil {
		dAtA[i] = 0xaa
		i++
		dAtA[i] = 0xa
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Mvn.Size()))
		n29, err := m.Mvn.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n29
	}
	return i, nil
}
func (m *NeuralNetworkLayer_L2Normalize) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.L2Normalize != nil {
		dAtA[i] = 0xd2
		i++
		dAtA[i] = 0xa
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.L2Normalize.Size()))
		n30, err := m.L2Normalize.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n30
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Softmax) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Softmax != nil {
		dAtA[i] = 0xfa
		i++
		dAtA[i] = 0xa
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Softmax.Size()))
		n31, err := m.Softmax.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n31
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Lrn) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Lrn != nil {
		dAtA[i] = 0xa2
		i++
		dAtA[i] = 0xb
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Lrn.Size()))
		n32, err := m.Lrn.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n32
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Crop) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Crop != nil {
		dAtA[i] = 0xf2
		i++
		dAtA[i] = 0xb
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Crop.Size()))
		n33, err := m.Crop.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n33
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Padding) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Padding != nil {
		dAtA[i] = 0xc2
		i++
		dAtA[i] = 0xc
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Padding.Size()))
		n34, err := m.Padding.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n34
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Upsample) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Upsample != nil {
		dAtA[i] = 0x92
		i++
		dAtA[i] = 0xd
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Upsample.Size()))
		n35, err := m.Upsample.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n35
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Unary) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Unary != nil {
		dAtA[i] = 0xe2
		i++
		dAtA[i] = 0xd
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Unary.Size()))
		n36, err := m.Unary.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n36
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Add) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Add != nil {
		dAtA[i] = 0xb2
		i++
		dAtA[i] = 0xe
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Add.Size()))
		n37, err := m.Add.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n37
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Multiply) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Multiply != nil {
		dAtA[i] = 0xba
		i++
		dAtA[i] = 0xe
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Multiply.Size()))
		n38, err := m.Multiply.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n38
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Average) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Average != nil {
		dAtA[i] = 0x82
		i++
		dAtA[i] = 0xf
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Average.Size()))
		n39, err := m.Average.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n39
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Scale) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Scale != nil {
		dAtA[i] = 0xaa
		i++
		dAtA[i] = 0xf
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Scale.Size()))
		n40, err := m.Scale.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n40
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Bias) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Bias != nil {
		dAtA[i] = 0xd2
		i++
		dAtA[i] = 0xf
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Bias.Size()))
		n41, err := m.Bias.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n41
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Max) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Max != nil {
		dAtA[i] = 0xa2
		i++
		dAtA[i] = 0x10
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Max.Size()))
		n42, err := m.Max.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n42
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Min) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Min != nil {
		dAtA[i] = 0xaa
		i++
		dAtA[i] = 0x10
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Min.Size()))
		n43, err := m.Min.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n43
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Dot) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Dot != nil {
		dAtA[i] = 0xf2
		i++
		dAtA[i] = 0x10
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Dot.Size()))
		n44, err := m.Dot.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n44
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Reduce) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Reduce != nil {
		dAtA[i] = 0xc2
		i++
		dAtA[i] = 0x11
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Reduce.Size()))
		n45, err := m.Reduce.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n45
	}
	return i, nil
}
func (m *NeuralNetworkLayer_LoadConstant) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.LoadConstant != nil {
		dAtA[i] = 0x92
		i++
		dAtA[i] = 0x12
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.LoadConstant.Size()))
		n46, err := m.LoadConstant.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n46
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Reshape) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Reshape != nil {
		dAtA[i] = 0xe2
		i++
		dAtA[i] = 0x12
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Reshape.Size()))
		n47, err := m.Reshape.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n47
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Flatten) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Flatten != nil {
		dAtA[i] = 0xea
		i++
		dAtA[i] = 0x12
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Flatten.Size()))
		n48, err := m.Flatten.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n48
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Permute) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Permute != nil {
		dAtA[i] = 0xb2
		i++
		dAtA[i] = 0x13
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Permute.Size()))
		n49, err := m.Permute.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n49
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Concat) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Concat != nil {
		dAtA[i] = 0x82
		i++
		dAtA[i] = 0x14
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Concat.Size()))
		n50, err := m.Concat.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n50
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Split) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Split != nil {
		dAtA[i] = 0xd2
		i++
		dAtA[i] = 0x14
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Split.Size()))
		n51, err := m.Split.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n51
	}
	return i, nil
}
func (m *NeuralNetworkLayer_SequenceRepeat) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.SequenceRepeat != nil {
		dAtA[i] = 0xa2
		i++
		dAtA[i] = 0x15
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.SequenceRepeat.Size()))
		n52, err := m.SequenceRepeat.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n52
	}
	return i, nil
}
func (m *NeuralNetworkLayer_SimpleRecurrent) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.SimpleRecurrent != nil {
		dAtA[i] = 0x82
		i++
		dAtA[i] = 0x19
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.SimpleRecurrent.Size()))
		n53, err := m.SimpleRecurrent.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n53
	}
	return i, nil
}
func (m *NeuralNetworkLayer_Gru) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Gru != nil {
		dAtA[i] = 0xd2
		i++
		dAtA[i] = 0x19
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Gru.Size()))
		n54, err := m.Gru.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n54
	}
	return i, nil
}
func (m *NeuralNetworkLayer_UniDirectionalLSTM) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.UniDirectionalLSTM != nil {
		dAtA[i] = 0xa2
		i++
		dAtA[i] = 0x1a
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.UniDirectionalLSTM.Size()))
		n55, err := m.UniDirectionalLSTM.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n55
	}
	return i, nil
}
func (m *NeuralNetworkLayer_BiDirectionalLSTM) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.BiDirectionalLSTM != nil {
		dAtA[i] = 0xf2
		i++
		dAtA[i] = 0x1a
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.BiDirectionalLSTM.Size()))
		n56, err := m.BiDirectionalLSTM.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n56
	}
	return i, nil
}
func (m *BorderAmounts) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *BorderAmounts) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.BorderAmounts) > 0 {
		for _, msg := range m.BorderAmounts {
			dAtA[i] = 0x52
			i++
			i = encodeVarintNeuralNetwork(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	return i, nil
}

func (m *BorderAmounts_EdgeSizes) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *BorderAmounts_EdgeSizes) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.StartEdgeSize != 0 {
		dAtA[i] = 0x8
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.StartEdgeSize))
	}
	if m.EndEdgeSize != 0 {
		dAtA[i] = 0x10
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.EndEdgeSize))
	}
	return i, nil
}

func (m *ValidPadding) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ValidPadding) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.PaddingAmounts != nil {
		dAtA[i] = 0xa
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.PaddingAmounts.Size()))
		n57, err := m.PaddingAmounts.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n57
	}
	return i, nil
}

func (m *SamePadding) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SamePadding) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.AsymmetryMode != 0 {
		dAtA[i] = 0x8
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.AsymmetryMode))
	}
	return i, nil
}

func (m *WeightParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *WeightParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.FloatValue) > 0 {
		dAtA[i] = 0xa
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(len(m.FloatValue)*4))
		for _, num := range m.FloatValue {
			f58 := math.Float32bits(float32(num))
			dAtA[i] = uint8(f58)
			i++
			dAtA[i] = uint8(f58 >> 8)
			i++
			dAtA[i] = uint8(f58 >> 16)
			i++
			dAtA[i] = uint8(f58 >> 24)
			i++
		}
	}
	return i, nil
}

func (m *ConvolutionLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ConvolutionLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.OutputChannels != 0 {
		dAtA[i] = 0x8
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.OutputChannels))
	}
	if m.KernelChannels != 0 {
		dAtA[i] = 0x10
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.KernelChannels))
	}
	if m.NGroups != 0 {
		dAtA[i] = 0x50
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.NGroups))
	}
	if len(m.KernelSize) > 0 {
		dAtA60 := make([]byte, len(m.KernelSize)*10)
		var j59 int
		for _, num := range m.KernelSize {
			for num >= 1<<7 {
				dAtA60[j59] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j59++
			}
			dAtA60[j59] = uint8(num)
			j59++
		}
		dAtA[i] = 0xa2
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(j59))
		i += copy(dAtA[i:], dAtA60[:j59])
	}
	if len(m.Stride) > 0 {
		dAtA62 := make([]byte, len(m.Stride)*10)
		var j61 int
		for _, num := range m.Stride {
			for num >= 1<<7 {
				dAtA62[j61] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j61++
			}
			dAtA62[j61] = uint8(num)
			j61++
		}
		dAtA[i] = 0xf2
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(j61))
		i += copy(dAtA[i:], dAtA62[:j61])
	}
	if len(m.DilationFactor) > 0 {
		dAtA64 := make([]byte, len(m.DilationFactor)*10)
		var j63 int
		for _, num := range m.DilationFactor {
			for num >= 1<<7 {
				dAtA64[j63] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j63++
			}
			dAtA64[j63] = uint8(num)
			j63++
		}
		dAtA[i] = 0xc2
		i++
		dAtA[i] = 0x2
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(j63))
		i += copy(dAtA[i:], dAtA64[:j63])
	}
	if m.ConvolutionPaddingType != nil {
		nn65, err := m.ConvolutionPaddingType.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += nn65
	}
	if m.IsDeconvolution {
		dAtA[i] = 0xe0
		i++
		dAtA[i] = 0x3
		i++
		if m.IsDeconvolution {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	if m.HasBias {
		dAtA[i] = 0xb0
		i++
		dAtA[i] = 0x4
		i++
		if m.HasBias {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	if m.Weights != nil {
		dAtA[i] = 0xd2
		i++
		dAtA[i] = 0x5
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Weights.Size()))
		n66, err := m.Weights.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n66
	}
	if m.Bias != nil {
		dAtA[i] = 0xda
		i++
		dAtA[i] = 0x5
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Bias.Size()))
		n67, err := m.Bias.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n67
	}
	if len(m.OutputShape) > 0 {
		dAtA69 := make([]byte, len(m.OutputShape)*10)
		var j68 int
		for _, num := range m.OutputShape {
			for num >= 1<<7 {
				dAtA69[j68] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j68++
			}
			dAtA69[j68] = uint8(num)
			j68++
		}
		dAtA[i] = 0xa2
		i++
		dAtA[i] = 0x6
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(j68))
		i += copy(dAtA[i:], dAtA69[:j68])
	}
	return i, nil
}

func (m *ConvolutionLayerParams_Valid) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Valid != nil {
		dAtA[i] = 0x92
		i++
		dAtA[i] = 0x3
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Valid.Size()))
		n70, err := m.Valid.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n70
	}
	return i, nil
}
func (m *ConvolutionLayerParams_Same) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Same != nil {
		dAtA[i] = 0x9a
		i++
		dAtA[i] = 0x3
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Same.Size()))
		n71, err := m.Same.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n71
	}
	return i, nil
}
func (m *InnerProductLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *InnerProductLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.InputChannels != 0 {
		dAtA[i] = 0x8
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.InputChannels))
	}
	if m.OutputChannels != 0 {
		dAtA[i] = 0x10
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.OutputChannels))
	}
	if m.HasBias {
		dAtA[i] = 0x50
		i++
		if m.HasBias {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	if m.Weights != nil {
		dAtA[i] = 0xa2
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Weights.Size()))
		n72, err := m.Weights.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n72
	}
	if m.Bias != nil {
		dAtA[i] = 0xaa
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Bias.Size()))
		n73, err := m.Bias.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n73
	}
	return i, nil
}

func (m *EmbeddingLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *EmbeddingLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.InputDim != 0 {
		dAtA[i] = 0x8
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.InputDim))
	}
	if m.OutputChannels != 0 {
		dAtA[i] = 0x10
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.OutputChannels))
	}
	if m.HasBias {
		dAtA[i] = 0x50
		i++
		if m.HasBias {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	if m.Weights != nil {
		dAtA[i] = 0xa2
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Weights.Size()))
		n74, err := m.Weights.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n74
	}
	if m.Bias != nil {
		dAtA[i] = 0xaa
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Bias.Size()))
		n75, err := m.Bias.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n75
	}
	return i, nil
}

func (m *BatchnormLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *BatchnormLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.Channels != 0 {
		dAtA[i] = 0x8
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Channels))
	}
	if m.ComputeMeanVar {
		dAtA[i] = 0x28
		i++
		if m.ComputeMeanVar {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	if m.InstanceNormalization {
		dAtA[i] = 0x30
		i++
		if m.InstanceNormalization {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	if m.Epsilon != 0 {
		dAtA[i] = 0x55
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.Epsilon))))
	}
	if m.Gamma != nil {
		dAtA[i] = 0x7a
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Gamma.Size()))
		n76, err := m.Gamma.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n76
	}
	if m.Beta != nil {
		dAtA[i] = 0x82
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Beta.Size()))
		n77, err := m.Beta.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n77
	}
	if m.Mean != nil {
		dAtA[i] = 0x8a
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Mean.Size()))
		n78, err := m.Mean.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n78
	}
	if m.Variance != nil {
		dAtA[i] = 0x92
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Variance.Size()))
		n79, err := m.Variance.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n79
	}
	return i, nil
}

func (m *PoolingLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *PoolingLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.Type != 0 {
		dAtA[i] = 0x8
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Type))
	}
	if len(m.KernelSize) > 0 {
		dAtA81 := make([]byte, len(m.KernelSize)*10)
		var j80 int
		for _, num := range m.KernelSize {
			for num >= 1<<7 {
				dAtA81[j80] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j80++
			}
			dAtA81[j80] = uint8(num)
			j80++
		}
		dAtA[i] = 0x52
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(j80))
		i += copy(dAtA[i:], dAtA81[:j80])
	}
	if len(m.Stride) > 0 {
		dAtA83 := make([]byte, len(m.Stride)*10)
		var j82 int
		for _, num := range m.Stride {
			for num >= 1<<7 {
				dAtA83[j82] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j82++
			}
			dAtA83[j82] = uint8(num)
			j82++
		}
		dAtA[i] = 0xa2
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(j82))
		i += copy(dAtA[i:], dAtA83[:j82])
	}
	if m.PoolingPaddingType != nil {
		nn84, err := m.PoolingPaddingType.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += nn84
	}
	if m.AvgPoolExcludePadding {
		dAtA[i] = 0x90
		i++
		dAtA[i] = 0x3
		i++
		if m.AvgPoolExcludePadding {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	if m.GlobalPooling {
		dAtA[i] = 0xe0
		i++
		dAtA[i] = 0x3
		i++
		if m.GlobalPooling {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	return i, nil
}

func (m *PoolingLayerParams_Valid) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Valid != nil {
		dAtA[i] = 0xf2
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Valid.Size()))
		n85, err := m.Valid.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n85
	}
	return i, nil
}
func (m *PoolingLayerParams_Same) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Same != nil {
		dAtA[i] = 0xfa
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Same.Size()))
		n86, err := m.Same.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n86
	}
	return i, nil
}
func (m *PoolingLayerParams_IncludeLastPixel) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.IncludeLastPixel != nil {
		dAtA[i] = 0x82
		i++
		dAtA[i] = 0x2
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.IncludeLastPixel.Size()))
		n87, err := m.IncludeLastPixel.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n87
	}
	return i, nil
}
func (m *PoolingLayerParams_ValidCompletePadding) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *PoolingLayerParams_ValidCompletePadding) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.PaddingAmounts) > 0 {
		dAtA89 := make([]byte, len(m.PaddingAmounts)*10)
		var j88 int
		for _, num := range m.PaddingAmounts {
			for num >= 1<<7 {
				dAtA89[j88] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j88++
			}
			dAtA89[j88] = uint8(num)
			j88++
		}
		dAtA[i] = 0x52
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(j88))
		i += copy(dAtA[i:], dAtA89[:j88])
	}
	return i, nil
}

func (m *PaddingLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *PaddingLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.PaddingType != nil {
		nn90, err := m.PaddingType.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += nn90
	}
	if m.PaddingAmounts != nil {
		dAtA[i] = 0x52
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.PaddingAmounts.Size()))
		n91, err := m.PaddingAmounts.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n91
	}
	return i, nil
}

func (m *PaddingLayerParams_Constant) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Constant != nil {
		dAtA[i] = 0xa
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Constant.Size()))
		n92, err := m.Constant.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n92
	}
	return i, nil
}
func (m *PaddingLayerParams_Reflection) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Reflection != nil {
		dAtA[i] = 0x12
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Reflection.Size()))
		n93, err := m.Reflection.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n93
	}
	return i, nil
}
func (m *PaddingLayerParams_Replication) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Replication != nil {
		dAtA[i] = 0x1a
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Replication.Size()))
		n94, err := m.Replication.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n94
	}
	return i, nil
}
func (m *PaddingLayerParams_PaddingConstant) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *PaddingLayerParams_PaddingConstant) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.Value != 0 {
		dAtA[i] = 0xd
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.Value))))
	}
	return i, nil
}

func (m *PaddingLayerParams_PaddingReflection) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *PaddingLayerParams_PaddingReflection) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	return i, nil
}

func (m *PaddingLayerParams_PaddingReplication) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *PaddingLayerParams_PaddingReplication) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	return i, nil
}

func (m *ConcatLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ConcatLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.SequenceConcat {
		dAtA[i] = 0xa0
		i++
		dAtA[i] = 0x6
		i++
		if m.SequenceConcat {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	return i, nil
}

func (m *LRNLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *LRNLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.Alpha != 0 {
		dAtA[i] = 0xd
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.Alpha))))
	}
	if m.Beta != 0 {
		dAtA[i] = 0x15
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.Beta))))
	}
	if m.LocalSize != 0 {
		dAtA[i] = 0x18
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.LocalSize))
	}
	if m.K != 0 {
		dAtA[i] = 0x25
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.K))))
	}
	return i, nil
}

func (m *SoftmaxLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SoftmaxLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	return i, nil
}

func (m *SplitLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SplitLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.NOutputs != 0 {
		dAtA[i] = 0x8
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.NOutputs))
	}
	return i, nil
}

func (m *AddLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *AddLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.Alpha != 0 {
		dAtA[i] = 0xd
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.Alpha))))
	}
	return i, nil
}

func (m *MultiplyLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *MultiplyLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.Alpha != 0 {
		dAtA[i] = 0xd
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.Alpha))))
	}
	return i, nil
}

func (m *UnaryFunctionLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *UnaryFunctionLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.Type != 0 {
		dAtA[i] = 0x8
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Type))
	}
	if m.Alpha != 0 {
		dAtA[i] = 0x15
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.Alpha))))
	}
	if m.Epsilon != 0 {
		dAtA[i] = 0x1d
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.Epsilon))))
	}
	if m.Shift != 0 {
		dAtA[i] = 0x25
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.Shift))))
	}
	if m.Scale != 0 {
		dAtA[i] = 0x2d
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.Scale))))
	}
	return i, nil
}

func (m *UpsampleLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *UpsampleLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.ScalingFactor) > 0 {
		dAtA96 := make([]byte, len(m.ScalingFactor)*10)
		var j95 int
		for _, num := range m.ScalingFactor {
			for num >= 1<<7 {
				dAtA96[j95] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j95++
			}
			dAtA96[j95] = uint8(num)
			j95++
		}
		dAtA[i] = 0xa
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(j95))
		i += copy(dAtA[i:], dAtA96[:j95])
	}
	return i, nil
}

func (m *BiasLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *BiasLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.Shape) > 0 {
		dAtA98 := make([]byte, len(m.Shape)*10)
		var j97 int
		for _, num := range m.Shape {
			for num >= 1<<7 {
				dAtA98[j97] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j97++
			}
			dAtA98[j97] = uint8(num)
			j97++
		}
		dAtA[i] = 0xa
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(j97))
		i += copy(dAtA[i:], dAtA98[:j97])
	}
	if m.Bias != nil {
		dAtA[i] = 0x12
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Bias.Size()))
		n99, err := m.Bias.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n99
	}
	return i, nil
}

func (m *ScaleLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ScaleLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.ShapeScale) > 0 {
		dAtA101 := make([]byte, len(m.ShapeScale)*10)
		var j100 int
		for _, num := range m.ShapeScale {
			for num >= 1<<7 {
				dAtA101[j100] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j100++
			}
			dAtA101[j100] = uint8(num)
			j100++
		}
		dAtA[i] = 0xa
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(j100))
		i += copy(dAtA[i:], dAtA101[:j100])
	}
	if m.Scale != nil {
		dAtA[i] = 0x12
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Scale.Size()))
		n102, err := m.Scale.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n102
	}
	if m.HasBias {
		dAtA[i] = 0x18
		i++
		if m.HasBias {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	if len(m.ShapeBias) > 0 {
		dAtA104 := make([]byte, len(m.ShapeBias)*10)
		var j103 int
		for _, num := range m.ShapeBias {
			for num >= 1<<7 {
				dAtA104[j103] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j103++
			}
			dAtA104[j103] = uint8(num)
			j103++
		}
		dAtA[i] = 0x22
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(j103))
		i += copy(dAtA[i:], dAtA104[:j103])
	}
	if m.Bias != nil {
		dAtA[i] = 0x2a
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Bias.Size()))
		n105, err := m.Bias.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n105
	}
	return i, nil
}

func (m *LoadConstantLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *LoadConstantLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.Shape) > 0 {
		dAtA107 := make([]byte, len(m.Shape)*10)
		var j106 int
		for _, num := range m.Shape {
			for num >= 1<<7 {
				dAtA107[j106] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j106++
			}
			dAtA107[j106] = uint8(num)
			j106++
		}
		dAtA[i] = 0xa
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(j106))
		i += copy(dAtA[i:], dAtA107[:j106])
	}
	if m.Data != nil {
		dAtA[i] = 0x12
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Data.Size()))
		n108, err := m.Data.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n108
	}
	return i, nil
}

func (m *L2NormalizeLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *L2NormalizeLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.Epsilon != 0 {
		dAtA[i] = 0xd
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.Epsilon))))
	}
	return i, nil
}

func (m *FlattenLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *FlattenLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.Mode != 0 {
		dAtA[i] = 0x8
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Mode))
	}
	return i, nil
}

func (m *ReshapeLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ReshapeLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.TargetShape) > 0 {
		dAtA110 := make([]byte, len(m.TargetShape)*10)
		var j109 int
		for _, num1 := range m.TargetShape {
			num := uint64(num1)
			for num >= 1<<7 {
				dAtA110[j109] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j109++
			}
			dAtA110[j109] = uint8(num)
			j109++
		}
		dAtA[i] = 0xa
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(j109))
		i += copy(dAtA[i:], dAtA110[:j109])
	}
	if m.Mode != 0 {
		dAtA[i] = 0x10
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Mode))
	}
	return i, nil
}

func (m *PermuteLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *PermuteLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.Axis) > 0 {
		dAtA112 := make([]byte, len(m.Axis)*10)
		var j111 int
		for _, num := range m.Axis {
			for num >= 1<<7 {
				dAtA112[j111] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j111++
			}
			dAtA112[j111] = uint8(num)
			j111++
		}
		dAtA[i] = 0xa
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(j111))
		i += copy(dAtA[i:], dAtA112[:j111])
	}
	return i, nil
}

func (m *ReduceLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *ReduceLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.Mode != 0 {
		dAtA[i] = 0x8
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Mode))
	}
	if m.Epsilon != 0 {
		dAtA[i] = 0x15
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.Epsilon))))
	}
	return i, nil
}

func (m *CropLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *CropLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.CropAmounts != nil {
		dAtA[i] = 0xa
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.CropAmounts.Size()))
		n113, err := m.CropAmounts.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n113
	}
	if len(m.Offset) > 0 {
		dAtA115 := make([]byte, len(m.Offset)*10)
		var j114 int
		for _, num := range m.Offset {
			for num >= 1<<7 {
				dAtA115[j114] = uint8(uint64(num)&0x7f | 0x80)
				num >>= 7
				j114++
			}
			dAtA115[j114] = uint8(num)
			j114++
		}
		dAtA[i] = 0x2a
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(j114))
		i += copy(dAtA[i:], dAtA115[:j114])
	}
	return i, nil
}

func (m *AverageLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *AverageLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	return i, nil
}

func (m *MaxLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *MaxLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	return i, nil
}

func (m *MinLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *MinLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	return i, nil
}

func (m *DotProductLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *DotProductLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.CosineSimilarity {
		dAtA[i] = 0x8
		i++
		if m.CosineSimilarity {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	return i, nil
}

func (m *MeanVarianceNormalizeLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *MeanVarianceNormalizeLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.AcrossChannels {
		dAtA[i] = 0x8
		i++
		if m.AcrossChannels {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	if m.NormalizeVariance {
		dAtA[i] = 0x10
		i++
		if m.NormalizeVariance {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	if m.Epsilon != 0 {
		dAtA[i] = 0x1d
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.Epsilon))))
	}
	return i, nil
}

func (m *SequenceRepeatLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SequenceRepeatLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.NRepetitions != 0 {
		dAtA[i] = 0x8
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.NRepetitions))
	}
	return i, nil
}

func (m *SimpleRecurrentLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *SimpleRecurrentLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.InputVectorSize != 0 {
		dAtA[i] = 0x8
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.InputVectorSize))
	}
	if m.OutputVectorSize != 0 {
		dAtA[i] = 0x10
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.OutputVectorSize))
	}
	if m.Activation != nil {
		dAtA[i] = 0x52
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Activation.Size()))
		n116, err := m.Activation.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n116
	}
	if m.SequenceOutput {
		dAtA[i] = 0x78
		i++
		if m.SequenceOutput {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	if m.HasBiasVector {
		dAtA[i] = 0xa0
		i++
		dAtA[i] = 0x1
		i++
		if m.HasBiasVector {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	if m.WeightMatrix != nil {
		dAtA[i] = 0xf2
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.WeightMatrix.Size()))
		n117, err := m.WeightMatrix.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n117
	}
	if m.RecursionMatrix != nil {
		dAtA[i] = 0xfa
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.RecursionMatrix.Size()))
		n118, err := m.RecursionMatrix.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n118
	}
	if m.BiasVector != nil {
		dAtA[i] = 0x82
		i++
		dAtA[i] = 0x2
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.BiasVector.Size()))
		n119, err := m.BiasVector.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n119
	}
	if m.ReverseInput {
		dAtA[i] = 0xa0
		i++
		dAtA[i] = 0x6
		i++
		if m.ReverseInput {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	return i, nil
}

func (m *GRULayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *GRULayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.InputVectorSize != 0 {
		dAtA[i] = 0x8
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.InputVectorSize))
	}
	if m.OutputVectorSize != 0 {
		dAtA[i] = 0x10
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.OutputVectorSize))
	}
	if len(m.Activations) > 0 {
		for _, msg := range m.Activations {
			dAtA[i] = 0x52
			i++
			i = encodeVarintNeuralNetwork(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	if m.SequenceOutput {
		dAtA[i] = 0x78
		i++
		if m.SequenceOutput {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	if m.HasBiasVectors {
		dAtA[i] = 0xa0
		i++
		dAtA[i] = 0x1
		i++
		if m.HasBiasVectors {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	if m.UpdateGateWeightMatrix != nil {
		dAtA[i] = 0xf2
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.UpdateGateWeightMatrix.Size()))
		n120, err := m.UpdateGateWeightMatrix.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n120
	}
	if m.ResetGateWeightMatrix != nil {
		dAtA[i] = 0xfa
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.ResetGateWeightMatrix.Size()))
		n121, err := m.ResetGateWeightMatrix.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n121
	}
	if m.OutputGateWeightMatrix != nil {
		dAtA[i] = 0x82
		i++
		dAtA[i] = 0x2
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.OutputGateWeightMatrix.Size()))
		n122, err := m.OutputGateWeightMatrix.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n122
	}
	if m.UpdateGateRecursionMatrix != nil {
		dAtA[i] = 0x92
		i++
		dAtA[i] = 0x3
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.UpdateGateRecursionMatrix.Size()))
		n123, err := m.UpdateGateRecursionMatrix.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n123
	}
	if m.ResetGateRecursionMatrix != nil {
		dAtA[i] = 0x9a
		i++
		dAtA[i] = 0x3
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.ResetGateRecursionMatrix.Size()))
		n124, err := m.ResetGateRecursionMatrix.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n124
	}
	if m.OutputGateRecursionMatrix != nil {
		dAtA[i] = 0xa2
		i++
		dAtA[i] = 0x3
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.OutputGateRecursionMatrix.Size()))
		n125, err := m.OutputGateRecursionMatrix.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n125
	}
	if m.UpdateGateBiasVector != nil {
		dAtA[i] = 0xb2
		i++
		dAtA[i] = 0x4
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.UpdateGateBiasVector.Size()))
		n126, err := m.UpdateGateBiasVector.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n126
	}
	if m.ResetGateBiasVector != nil {
		dAtA[i] = 0xba
		i++
		dAtA[i] = 0x4
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.ResetGateBiasVector.Size()))
		n127, err := m.ResetGateBiasVector.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n127
	}
	if m.OutputGateBiasVector != nil {
		dAtA[i] = 0xc2
		i++
		dAtA[i] = 0x4
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.OutputGateBiasVector.Size()))
		n128, err := m.OutputGateBiasVector.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n128
	}
	if m.ReverseInput {
		dAtA[i] = 0xa0
		i++
		dAtA[i] = 0x6
		i++
		if m.ReverseInput {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	return i, nil
}

func (m *LSTMParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *LSTMParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.SequenceOutput {
		dAtA[i] = 0x50
		i++
		if m.SequenceOutput {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	if m.HasBiasVectors {
		dAtA[i] = 0xa0
		i++
		dAtA[i] = 0x1
		i++
		if m.HasBiasVectors {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	if m.ForgetBias {
		dAtA[i] = 0xf0
		i++
		dAtA[i] = 0x1
		i++
		if m.ForgetBias {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	if m.HasPeepholeVectors {
		dAtA[i] = 0xc0
		i++
		dAtA[i] = 0x2
		i++
		if m.HasPeepholeVectors {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	if m.CoupledInputAndForgetGate {
		dAtA[i] = 0x90
		i++
		dAtA[i] = 0x3
		i++
		if m.CoupledInputAndForgetGate {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	if m.CellClipThreshold != 0 {
		dAtA[i] = 0xe5
		i++
		dAtA[i] = 0x3
		i++
		i = encodeFixed32NeuralNetwork(dAtA, i, uint32(math.Float32bits(float32(m.CellClipThreshold))))
	}
	return i, nil
}

func (m *LSTMWeightParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *LSTMWeightParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.InputGateWeightMatrix != nil {
		dAtA[i] = 0xa
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.InputGateWeightMatrix.Size()))
		n129, err := m.InputGateWeightMatrix.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n129
	}
	if m.ForgetGateWeightMatrix != nil {
		dAtA[i] = 0x12
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.ForgetGateWeightMatrix.Size()))
		n130, err := m.ForgetGateWeightMatrix.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n130
	}
	if m.BlockInputWeightMatrix != nil {
		dAtA[i] = 0x1a
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.BlockInputWeightMatrix.Size()))
		n131, err := m.BlockInputWeightMatrix.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n131
	}
	if m.OutputGateWeightMatrix != nil {
		dAtA[i] = 0x22
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.OutputGateWeightMatrix.Size()))
		n132, err := m.OutputGateWeightMatrix.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n132
	}
	if m.InputGateRecursionMatrix != nil {
		dAtA[i] = 0xa2
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.InputGateRecursionMatrix.Size()))
		n133, err := m.InputGateRecursionMatrix.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n133
	}
	if m.ForgetGateRecursionMatrix != nil {
		dAtA[i] = 0xaa
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.ForgetGateRecursionMatrix.Size()))
		n134, err := m.ForgetGateRecursionMatrix.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n134
	}
	if m.BlockInputRecursionMatrix != nil {
		dAtA[i] = 0xb2
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.BlockInputRecursionMatrix.Size()))
		n135, err := m.BlockInputRecursionMatrix.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n135
	}
	if m.OutputGateRecursionMatrix != nil {
		dAtA[i] = 0xba
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.OutputGateRecursionMatrix.Size()))
		n136, err := m.OutputGateRecursionMatrix.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n136
	}
	if m.InputGateBiasVector != nil {
		dAtA[i] = 0xc2
		i++
		dAtA[i] = 0x2
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.InputGateBiasVector.Size()))
		n137, err := m.InputGateBiasVector.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n137
	}
	if m.ForgetGateBiasVector != nil {
		dAtA[i] = 0xca
		i++
		dAtA[i] = 0x2
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.ForgetGateBiasVector.Size()))
		n138, err := m.ForgetGateBiasVector.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n138
	}
	if m.BlockInputBiasVector != nil {
		dAtA[i] = 0xd2
		i++
		dAtA[i] = 0x2
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.BlockInputBiasVector.Size()))
		n139, err := m.BlockInputBiasVector.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n139
	}
	if m.OutputGateBiasVector != nil {
		dAtA[i] = 0xda
		i++
		dAtA[i] = 0x2
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.OutputGateBiasVector.Size()))
		n140, err := m.OutputGateBiasVector.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n140
	}
	if m.InputGatePeepholeVector != nil {
		dAtA[i] = 0xe2
		i++
		dAtA[i] = 0x3
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.InputGatePeepholeVector.Size()))
		n141, err := m.InputGatePeepholeVector.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n141
	}
	if m.ForgetGatePeepholeVector != nil {
		dAtA[i] = 0xea
		i++
		dAtA[i] = 0x3
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.ForgetGatePeepholeVector.Size()))
		n142, err := m.ForgetGatePeepholeVector.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n142
	}
	if m.OutputGatePeepholeVector != nil {
		dAtA[i] = 0xf2
		i++
		dAtA[i] = 0x3
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.OutputGatePeepholeVector.Size()))
		n143, err := m.OutputGatePeepholeVector.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n143
	}
	return i, nil
}

func (m *UniDirectionalLSTMLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *UniDirectionalLSTMLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.InputVectorSize != 0 {
		dAtA[i] = 0x8
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.InputVectorSize))
	}
	if m.OutputVectorSize != 0 {
		dAtA[i] = 0x10
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.OutputVectorSize))
	}
	if len(m.Activations) > 0 {
		for _, msg := range m.Activations {
			dAtA[i] = 0x52
			i++
			i = encodeVarintNeuralNetwork(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	if m.Params != nil {
		dAtA[i] = 0x7a
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Params.Size()))
		n144, err := m.Params.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n144
	}
	if m.WeightParams != nil {
		dAtA[i] = 0xa2
		i++
		dAtA[i] = 0x1
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.WeightParams.Size()))
		n145, err := m.WeightParams.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n145
	}
	if m.ReverseInput {
		dAtA[i] = 0xa0
		i++
		dAtA[i] = 0x6
		i++
		if m.ReverseInput {
			dAtA[i] = 1
		} else {
			dAtA[i] = 0
		}
		i++
	}
	return i, nil
}

func (m *BiDirectionalLSTMLayerParams) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *BiDirectionalLSTMLayerParams) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if m.InputVectorSize != 0 {
		dAtA[i] = 0x8
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.InputVectorSize))
	}
	if m.OutputVectorSize != 0 {
		dAtA[i] = 0x10
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.OutputVectorSize))
	}
	if len(m.ActivationsForwardLSTM) > 0 {
		for _, msg := range m.ActivationsForwardLSTM {
			dAtA[i] = 0x52
			i++
			i = encodeVarintNeuralNetwork(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	if len(m.ActivationsBackwardLSTM) > 0 {
		for _, msg := range m.ActivationsBackwardLSTM {
			dAtA[i] = 0x5a
			i++
			i = encodeVarintNeuralNetwork(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	if m.Params != nil {
		dAtA[i] = 0x7a
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Params.Size()))
		n146, err := m.Params.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n146
	}
	if len(m.WeightParams) > 0 {
		for _, msg := range m.WeightParams {
			dAtA[i] = 0xa2
			i++
			dAtA[i] = 0x1
			i++
			i = encodeVarintNeuralNetwork(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	return i, nil
}

func (m *NeuralNetworkClassifier) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *NeuralNetworkClassifier) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.Layers) > 0 {
		for _, msg := range m.Layers {
			dAtA[i] = 0xa
			i++
			i = encodeVarintNeuralNetwork(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	if len(m.Preprocessing) > 0 {
		for _, msg := range m.Preprocessing {
			dAtA[i] = 0x12
			i++
			i = encodeVarintNeuralNetwork(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	if m.ClassLabels != nil {
		nn147, err := m.ClassLabels.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += nn147
	}
	return i, nil
}

func (m *NeuralNetworkClassifier_StringClassLabels) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.StringClassLabels != nil {
		dAtA[i] = 0xa2
		i++
		dAtA[i] = 0x6
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.StringClassLabels.Size()))
		n148, err := m.StringClassLabels.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n148
	}
	return i, nil
}
func (m *NeuralNetworkClassifier_Int64ClassLabels) MarshalTo(dAtA []byte) (int, error) {
	i := 0
	if m.Int64ClassLabels != nil {
		dAtA[i] = 0xaa
		i++
		dAtA[i] = 0x6
		i++
		i = encodeVarintNeuralNetwork(dAtA, i, uint64(m.Int64ClassLabels.Size()))
		n149, err := m.Int64ClassLabels.MarshalTo(dAtA[i:])
		if err != nil {
			return 0, err
		}
		i += n149
	}
	return i, nil
}
func (m *NeuralNetworkRegressor) Marshal() (dAtA []byte, err error) {
	size := m.Size()
	dAtA = make([]byte, size)
	n, err := m.MarshalTo(dAtA)
	if err != nil {
		return nil, err
	}
	return dAtA[:n], nil
}

func (m *NeuralNetworkRegressor) MarshalTo(dAtA []byte) (int, error) {
	var i int
	_ = i
	var l int
	_ = l
	if len(m.Layers) > 0 {
		for _, msg := range m.Layers {
			dAtA[i] = 0xa
			i++
			i = encodeVarintNeuralNetwork(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	if len(m.Preprocessing) > 0 {
		for _, msg := range m.Preprocessing {
			dAtA[i] = 0x12
			i++
			i = encodeVarintNeuralNetwork(dAtA, i, uint64(msg.Size()))
			n, err := msg.MarshalTo(dAtA[i:])
			if err != nil {
				return 0, err
			}
			i += n
		}
	}
	return i, nil
}

func encodeFixed64NeuralNetwork(dAtA []byte, offset int, v uint64) int {
	dAtA[offset] = uint8(v)
	dAtA[offset+1] = uint8(v >> 8)
	dAtA[offset+2] = uint8(v >> 16)
	dAtA[offset+3] = uint8(v >> 24)
	dAtA[offset+4] = uint8(v >> 32)
	dAtA[offset+5] = uint8(v >> 40)
	dAtA[offset+6] = uint8(v >> 48)
	dAtA[offset+7] = uint8(v >> 56)
	return offset + 8
}
func encodeFixed32NeuralNetwork(dAtA []byte, offset int, v uint32) int {
	dAtA[offset] = uint8(v)
	dAtA[offset+1] = uint8(v >> 8)
	dAtA[offset+2] = uint8(v >> 16)
	dAtA[offset+3] = uint8(v >> 24)
	return offset + 4
}
func encodeVarintNeuralNetwork(dAtA []byte, offset int, v uint64) int {
	for v >= 1<<7 {
		dAtA[offset] = uint8(v&0x7f | 0x80)
		v >>= 7
		offset++
	}
	dAtA[offset] = uint8(v)
	return offset + 1
}
func (m *NeuralNetwork) Size() (n int) {
	var l int
	_ = l
	if len(m.Layers) > 0 {
		for _, e := range m.Layers {
			l = e.Size()
			n += 1 + l + sovNeuralNetwork(uint64(l))
		}
	}
	if len(m.Preprocessing) > 0 {
		for _, e := range m.Preprocessing {
			l = e.Size()
			n += 1 + l + sovNeuralNetwork(uint64(l))
		}
	}
	return n
}

func (m *NeuralNetworkImageScaler) Size() (n int) {
	var l int
	_ = l
	if m.ChannelScale != 0 {
		n += 5
	}
	if m.BlueBias != 0 {
		n += 6
	}
	if m.GreenBias != 0 {
		n += 6
	}
	if m.RedBias != 0 {
		n += 6
	}
	if m.GrayBias != 0 {
		n += 6
	}
	return n
}

func (m *NeuralNetworkMeanImage) Size() (n int) {
	var l int
	_ = l
	if len(m.MeanImage) > 0 {
		n += 1 + sovNeuralNetwork(uint64(len(m.MeanImage)*4)) + len(m.MeanImage)*4
	}
	return n
}

func (m *NeuralNetworkPreprocessing) Size() (n int) {
	var l int
	_ = l
	l = len(m.FeatureName)
	if l > 0 {
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	if m.Preprocessor != nil {
		n += m.Preprocessor.Size()
	}
	return n
}

func (m *NeuralNetworkPreprocessing_Scaler) Size() (n int) {
	var l int
	_ = l
	if m.Scaler != nil {
		l = m.Scaler.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkPreprocessing_MeanImage) Size() (n int) {
	var l int
	_ = l
	if m.MeanImage != nil {
		l = m.MeanImage.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *ActivationReLU) Size() (n int) {
	var l int
	_ = l
	return n
}

func (m *ActivationLeakyReLU) Size() (n int) {
	var l int
	_ = l
	if m.Alpha != 0 {
		n += 5
	}
	return n
}

func (m *ActivationTanh) Size() (n int) {
	var l int
	_ = l
	return n
}

func (m *ActivationScaledTanh) Size() (n int) {
	var l int
	_ = l
	if m.Alpha != 0 {
		n += 5
	}
	if m.Beta != 0 {
		n += 5
	}
	return n
}

func (m *ActivationSigmoid) Size() (n int) {
	var l int
	_ = l
	return n
}

func (m *ActivationLinear) Size() (n int) {
	var l int
	_ = l
	if m.Alpha != 0 {
		n += 5
	}
	if m.Beta != 0 {
		n += 5
	}
	return n
}

func (m *ActivationSigmoidHard) Size() (n int) {
	var l int
	_ = l
	if m.Alpha != 0 {
		n += 5
	}
	if m.Beta != 0 {
		n += 5
	}
	return n
}

func (m *ActivationPReLU) Size() (n int) {
	var l int
	_ = l
	if m.Alpha != nil {
		l = m.Alpha.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}

func (m *ActivationELU) Size() (n int) {
	var l int
	_ = l
	if m.Alpha != 0 {
		n += 5
	}
	return n
}

func (m *ActivationThresholdedReLU) Size() (n int) {
	var l int
	_ = l
	if m.Alpha != 0 {
		n += 5
	}
	return n
}

func (m *ActivationSoftsign) Size() (n int) {
	var l int
	_ = l
	return n
}

func (m *ActivationSoftplus) Size() (n int) {
	var l int
	_ = l
	return n
}

func (m *ActivationParametricSoftplus) Size() (n int) {
	var l int
	_ = l
	if m.Alpha != nil {
		l = m.Alpha.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	if m.Beta != nil {
		l = m.Beta.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}

func (m *ActivationParams) Size() (n int) {
	var l int
	_ = l
	if m.NonlinearityType != nil {
		n += m.NonlinearityType.Size()
	}
	return n
}

func (m *ActivationParams_Linear) Size() (n int) {
	var l int
	_ = l
	if m.Linear != nil {
		l = m.Linear.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *ActivationParams_ReLU) Size() (n int) {
	var l int
	_ = l
	if m.ReLU != nil {
		l = m.ReLU.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *ActivationParams_LeakyReLU) Size() (n int) {
	var l int
	_ = l
	if m.LeakyReLU != nil {
		l = m.LeakyReLU.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *ActivationParams_ThresholdedReLU) Size() (n int) {
	var l int
	_ = l
	if m.ThresholdedReLU != nil {
		l = m.ThresholdedReLU.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *ActivationParams_PReLU) Size() (n int) {
	var l int
	_ = l
	if m.PReLU != nil {
		l = m.PReLU.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *ActivationParams_Tanh) Size() (n int) {
	var l int
	_ = l
	if m.Tanh != nil {
		l = m.Tanh.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *ActivationParams_ScaledTanh) Size() (n int) {
	var l int
	_ = l
	if m.ScaledTanh != nil {
		l = m.ScaledTanh.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *ActivationParams_Sigmoid) Size() (n int) {
	var l int
	_ = l
	if m.Sigmoid != nil {
		l = m.Sigmoid.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *ActivationParams_SigmoidHard) Size() (n int) {
	var l int
	_ = l
	if m.SigmoidHard != nil {
		l = m.SigmoidHard.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *ActivationParams_ELU) Size() (n int) {
	var l int
	_ = l
	if m.ELU != nil {
		l = m.ELU.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *ActivationParams_Softsign) Size() (n int) {
	var l int
	_ = l
	if m.Softsign != nil {
		l = m.Softsign.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *ActivationParams_Softplus) Size() (n int) {
	var l int
	_ = l
	if m.Softplus != nil {
		l = m.Softplus.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *ActivationParams_ParametricSoftplus) Size() (n int) {
	var l int
	_ = l
	if m.ParametricSoftplus != nil {
		l = m.ParametricSoftplus.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer) Size() (n int) {
	var l int
	_ = l
	l = len(m.Name)
	if l > 0 {
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	if len(m.Input) > 0 {
		for _, s := range m.Input {
			l = len(s)
			n += 1 + l + sovNeuralNetwork(uint64(l))
		}
	}
	if len(m.Output) > 0 {
		for _, s := range m.Output {
			l = len(s)
			n += 1 + l + sovNeuralNetwork(uint64(l))
		}
	}
	if m.Layer != nil {
		n += m.Layer.Size()
	}
	return n
}

func (m *NeuralNetworkLayer_Convolution) Size() (n int) {
	var l int
	_ = l
	if m.Convolution != nil {
		l = m.Convolution.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Pooling) Size() (n int) {
	var l int
	_ = l
	if m.Pooling != nil {
		l = m.Pooling.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Activation) Size() (n int) {
	var l int
	_ = l
	if m.Activation != nil {
		l = m.Activation.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_InnerProduct) Size() (n int) {
	var l int
	_ = l
	if m.InnerProduct != nil {
		l = m.InnerProduct.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Embedding) Size() (n int) {
	var l int
	_ = l
	if m.Embedding != nil {
		l = m.Embedding.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Batchnorm) Size() (n int) {
	var l int
	_ = l
	if m.Batchnorm != nil {
		l = m.Batchnorm.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Mvn) Size() (n int) {
	var l int
	_ = l
	if m.Mvn != nil {
		l = m.Mvn.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_L2Normalize) Size() (n int) {
	var l int
	_ = l
	if m.L2Normalize != nil {
		l = m.L2Normalize.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Softmax) Size() (n int) {
	var l int
	_ = l
	if m.Softmax != nil {
		l = m.Softmax.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Lrn) Size() (n int) {
	var l int
	_ = l
	if m.Lrn != nil {
		l = m.Lrn.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Crop) Size() (n int) {
	var l int
	_ = l
	if m.Crop != nil {
		l = m.Crop.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Padding) Size() (n int) {
	var l int
	_ = l
	if m.Padding != nil {
		l = m.Padding.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Upsample) Size() (n int) {
	var l int
	_ = l
	if m.Upsample != nil {
		l = m.Upsample.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Unary) Size() (n int) {
	var l int
	_ = l
	if m.Unary != nil {
		l = m.Unary.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Add) Size() (n int) {
	var l int
	_ = l
	if m.Add != nil {
		l = m.Add.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Multiply) Size() (n int) {
	var l int
	_ = l
	if m.Multiply != nil {
		l = m.Multiply.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Average) Size() (n int) {
	var l int
	_ = l
	if m.Average != nil {
		l = m.Average.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Scale) Size() (n int) {
	var l int
	_ = l
	if m.Scale != nil {
		l = m.Scale.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Bias) Size() (n int) {
	var l int
	_ = l
	if m.Bias != nil {
		l = m.Bias.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Max) Size() (n int) {
	var l int
	_ = l
	if m.Max != nil {
		l = m.Max.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Min) Size() (n int) {
	var l int
	_ = l
	if m.Min != nil {
		l = m.Min.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Dot) Size() (n int) {
	var l int
	_ = l
	if m.Dot != nil {
		l = m.Dot.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Reduce) Size() (n int) {
	var l int
	_ = l
	if m.Reduce != nil {
		l = m.Reduce.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_LoadConstant) Size() (n int) {
	var l int
	_ = l
	if m.LoadConstant != nil {
		l = m.LoadConstant.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Reshape) Size() (n int) {
	var l int
	_ = l
	if m.Reshape != nil {
		l = m.Reshape.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Flatten) Size() (n int) {
	var l int
	_ = l
	if m.Flatten != nil {
		l = m.Flatten.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Permute) Size() (n int) {
	var l int
	_ = l
	if m.Permute != nil {
		l = m.Permute.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Concat) Size() (n int) {
	var l int
	_ = l
	if m.Concat != nil {
		l = m.Concat.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Split) Size() (n int) {
	var l int
	_ = l
	if m.Split != nil {
		l = m.Split.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_SequenceRepeat) Size() (n int) {
	var l int
	_ = l
	if m.SequenceRepeat != nil {
		l = m.SequenceRepeat.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_SimpleRecurrent) Size() (n int) {
	var l int
	_ = l
	if m.SimpleRecurrent != nil {
		l = m.SimpleRecurrent.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_Gru) Size() (n int) {
	var l int
	_ = l
	if m.Gru != nil {
		l = m.Gru.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_UniDirectionalLSTM) Size() (n int) {
	var l int
	_ = l
	if m.UniDirectionalLSTM != nil {
		l = m.UniDirectionalLSTM.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkLayer_BiDirectionalLSTM) Size() (n int) {
	var l int
	_ = l
	if m.BiDirectionalLSTM != nil {
		l = m.BiDirectionalLSTM.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *BorderAmounts) Size() (n int) {
	var l int
	_ = l
	if len(m.BorderAmounts) > 0 {
		for _, e := range m.BorderAmounts {
			l = e.Size()
			n += 1 + l + sovNeuralNetwork(uint64(l))
		}
	}
	return n
}

func (m *BorderAmounts_EdgeSizes) Size() (n int) {
	var l int
	_ = l
	if m.StartEdgeSize != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.StartEdgeSize))
	}
	if m.EndEdgeSize != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.EndEdgeSize))
	}
	return n
}

func (m *ValidPadding) Size() (n int) {
	var l int
	_ = l
	if m.PaddingAmounts != nil {
		l = m.PaddingAmounts.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}

func (m *SamePadding) Size() (n int) {
	var l int
	_ = l
	if m.AsymmetryMode != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.AsymmetryMode))
	}
	return n
}

func (m *WeightParams) Size() (n int) {
	var l int
	_ = l
	if len(m.FloatValue) > 0 {
		n += 1 + sovNeuralNetwork(uint64(len(m.FloatValue)*4)) + len(m.FloatValue)*4
	}
	return n
}

func (m *ConvolutionLayerParams) Size() (n int) {
	var l int
	_ = l
	if m.OutputChannels != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.OutputChannels))
	}
	if m.KernelChannels != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.KernelChannels))
	}
	if m.NGroups != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.NGroups))
	}
	if len(m.KernelSize) > 0 {
		l = 0
		for _, e := range m.KernelSize {
			l += sovNeuralNetwork(uint64(e))
		}
		n += 2 + sovNeuralNetwork(uint64(l)) + l
	}
	if len(m.Stride) > 0 {
		l = 0
		for _, e := range m.Stride {
			l += sovNeuralNetwork(uint64(e))
		}
		n += 2 + sovNeuralNetwork(uint64(l)) + l
	}
	if len(m.DilationFactor) > 0 {
		l = 0
		for _, e := range m.DilationFactor {
			l += sovNeuralNetwork(uint64(e))
		}
		n += 2 + sovNeuralNetwork(uint64(l)) + l
	}
	if m.ConvolutionPaddingType != nil {
		n += m.ConvolutionPaddingType.Size()
	}
	if m.IsDeconvolution {
		n += 3
	}
	if m.HasBias {
		n += 3
	}
	if m.Weights != nil {
		l = m.Weights.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.Bias != nil {
		l = m.Bias.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if len(m.OutputShape) > 0 {
		l = 0
		for _, e := range m.OutputShape {
			l += sovNeuralNetwork(uint64(e))
		}
		n += 2 + sovNeuralNetwork(uint64(l)) + l
	}
	return n
}

func (m *ConvolutionLayerParams_Valid) Size() (n int) {
	var l int
	_ = l
	if m.Valid != nil {
		l = m.Valid.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *ConvolutionLayerParams_Same) Size() (n int) {
	var l int
	_ = l
	if m.Same != nil {
		l = m.Same.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *InnerProductLayerParams) Size() (n int) {
	var l int
	_ = l
	if m.InputChannels != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.InputChannels))
	}
	if m.OutputChannels != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.OutputChannels))
	}
	if m.HasBias {
		n += 2
	}
	if m.Weights != nil {
		l = m.Weights.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.Bias != nil {
		l = m.Bias.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}

func (m *EmbeddingLayerParams) Size() (n int) {
	var l int
	_ = l
	if m.InputDim != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.InputDim))
	}
	if m.OutputChannels != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.OutputChannels))
	}
	if m.HasBias {
		n += 2
	}
	if m.Weights != nil {
		l = m.Weights.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.Bias != nil {
		l = m.Bias.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}

func (m *BatchnormLayerParams) Size() (n int) {
	var l int
	_ = l
	if m.Channels != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.Channels))
	}
	if m.ComputeMeanVar {
		n += 2
	}
	if m.InstanceNormalization {
		n += 2
	}
	if m.Epsilon != 0 {
		n += 5
	}
	if m.Gamma != nil {
		l = m.Gamma.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	if m.Beta != nil {
		l = m.Beta.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.Mean != nil {
		l = m.Mean.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.Variance != nil {
		l = m.Variance.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}

func (m *PoolingLayerParams) Size() (n int) {
	var l int
	_ = l
	if m.Type != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.Type))
	}
	if len(m.KernelSize) > 0 {
		l = 0
		for _, e := range m.KernelSize {
			l += sovNeuralNetwork(uint64(e))
		}
		n += 1 + sovNeuralNetwork(uint64(l)) + l
	}
	if len(m.Stride) > 0 {
		l = 0
		for _, e := range m.Stride {
			l += sovNeuralNetwork(uint64(e))
		}
		n += 2 + sovNeuralNetwork(uint64(l)) + l
	}
	if m.PoolingPaddingType != nil {
		n += m.PoolingPaddingType.Size()
	}
	if m.AvgPoolExcludePadding {
		n += 3
	}
	if m.GlobalPooling {
		n += 3
	}
	return n
}

func (m *PoolingLayerParams_Valid) Size() (n int) {
	var l int
	_ = l
	if m.Valid != nil {
		l = m.Valid.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *PoolingLayerParams_Same) Size() (n int) {
	var l int
	_ = l
	if m.Same != nil {
		l = m.Same.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *PoolingLayerParams_IncludeLastPixel) Size() (n int) {
	var l int
	_ = l
	if m.IncludeLastPixel != nil {
		l = m.IncludeLastPixel.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *PoolingLayerParams_ValidCompletePadding) Size() (n int) {
	var l int
	_ = l
	if len(m.PaddingAmounts) > 0 {
		l = 0
		for _, e := range m.PaddingAmounts {
			l += sovNeuralNetwork(uint64(e))
		}
		n += 1 + sovNeuralNetwork(uint64(l)) + l
	}
	return n
}

func (m *PaddingLayerParams) Size() (n int) {
	var l int
	_ = l
	if m.PaddingType != nil {
		n += m.PaddingType.Size()
	}
	if m.PaddingAmounts != nil {
		l = m.PaddingAmounts.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}

func (m *PaddingLayerParams_Constant) Size() (n int) {
	var l int
	_ = l
	if m.Constant != nil {
		l = m.Constant.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *PaddingLayerParams_Reflection) Size() (n int) {
	var l int
	_ = l
	if m.Reflection != nil {
		l = m.Reflection.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *PaddingLayerParams_Replication) Size() (n int) {
	var l int
	_ = l
	if m.Replication != nil {
		l = m.Replication.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *PaddingLayerParams_PaddingConstant) Size() (n int) {
	var l int
	_ = l
	if m.Value != 0 {
		n += 5
	}
	return n
}

func (m *PaddingLayerParams_PaddingReflection) Size() (n int) {
	var l int
	_ = l
	return n
}

func (m *PaddingLayerParams_PaddingReplication) Size() (n int) {
	var l int
	_ = l
	return n
}

func (m *ConcatLayerParams) Size() (n int) {
	var l int
	_ = l
	if m.SequenceConcat {
		n += 3
	}
	return n
}

func (m *LRNLayerParams) Size() (n int) {
	var l int
	_ = l
	if m.Alpha != 0 {
		n += 5
	}
	if m.Beta != 0 {
		n += 5
	}
	if m.LocalSize != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.LocalSize))
	}
	if m.K != 0 {
		n += 5
	}
	return n
}

func (m *SoftmaxLayerParams) Size() (n int) {
	var l int
	_ = l
	return n
}

func (m *SplitLayerParams) Size() (n int) {
	var l int
	_ = l
	if m.NOutputs != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.NOutputs))
	}
	return n
}

func (m *AddLayerParams) Size() (n int) {
	var l int
	_ = l
	if m.Alpha != 0 {
		n += 5
	}
	return n
}

func (m *MultiplyLayerParams) Size() (n int) {
	var l int
	_ = l
	if m.Alpha != 0 {
		n += 5
	}
	return n
}

func (m *UnaryFunctionLayerParams) Size() (n int) {
	var l int
	_ = l
	if m.Type != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.Type))
	}
	if m.Alpha != 0 {
		n += 5
	}
	if m.Epsilon != 0 {
		n += 5
	}
	if m.Shift != 0 {
		n += 5
	}
	if m.Scale != 0 {
		n += 5
	}
	return n
}

func (m *UpsampleLayerParams) Size() (n int) {
	var l int
	_ = l
	if len(m.ScalingFactor) > 0 {
		l = 0
		for _, e := range m.ScalingFactor {
			l += sovNeuralNetwork(uint64(e))
		}
		n += 1 + sovNeuralNetwork(uint64(l)) + l
	}
	return n
}

func (m *BiasLayerParams) Size() (n int) {
	var l int
	_ = l
	if len(m.Shape) > 0 {
		l = 0
		for _, e := range m.Shape {
			l += sovNeuralNetwork(uint64(e))
		}
		n += 1 + sovNeuralNetwork(uint64(l)) + l
	}
	if m.Bias != nil {
		l = m.Bias.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}

func (m *ScaleLayerParams) Size() (n int) {
	var l int
	_ = l
	if len(m.ShapeScale) > 0 {
		l = 0
		for _, e := range m.ShapeScale {
			l += sovNeuralNetwork(uint64(e))
		}
		n += 1 + sovNeuralNetwork(uint64(l)) + l
	}
	if m.Scale != nil {
		l = m.Scale.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	if m.HasBias {
		n += 2
	}
	if len(m.ShapeBias) > 0 {
		l = 0
		for _, e := range m.ShapeBias {
			l += sovNeuralNetwork(uint64(e))
		}
		n += 1 + sovNeuralNetwork(uint64(l)) + l
	}
	if m.Bias != nil {
		l = m.Bias.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}

func (m *LoadConstantLayerParams) Size() (n int) {
	var l int
	_ = l
	if len(m.Shape) > 0 {
		l = 0
		for _, e := range m.Shape {
			l += sovNeuralNetwork(uint64(e))
		}
		n += 1 + sovNeuralNetwork(uint64(l)) + l
	}
	if m.Data != nil {
		l = m.Data.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}

func (m *L2NormalizeLayerParams) Size() (n int) {
	var l int
	_ = l
	if m.Epsilon != 0 {
		n += 5
	}
	return n
}

func (m *FlattenLayerParams) Size() (n int) {
	var l int
	_ = l
	if m.Mode != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.Mode))
	}
	return n
}

func (m *ReshapeLayerParams) Size() (n int) {
	var l int
	_ = l
	if len(m.TargetShape) > 0 {
		l = 0
		for _, e := range m.TargetShape {
			l += sovNeuralNetwork(uint64(e))
		}
		n += 1 + sovNeuralNetwork(uint64(l)) + l
	}
	if m.Mode != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.Mode))
	}
	return n
}

func (m *PermuteLayerParams) Size() (n int) {
	var l int
	_ = l
	if len(m.Axis) > 0 {
		l = 0
		for _, e := range m.Axis {
			l += sovNeuralNetwork(uint64(e))
		}
		n += 1 + sovNeuralNetwork(uint64(l)) + l
	}
	return n
}

func (m *ReduceLayerParams) Size() (n int) {
	var l int
	_ = l
	if m.Mode != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.Mode))
	}
	if m.Epsilon != 0 {
		n += 5
	}
	return n
}

func (m *CropLayerParams) Size() (n int) {
	var l int
	_ = l
	if m.CropAmounts != nil {
		l = m.CropAmounts.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	if len(m.Offset) > 0 {
		l = 0
		for _, e := range m.Offset {
			l += sovNeuralNetwork(uint64(e))
		}
		n += 1 + sovNeuralNetwork(uint64(l)) + l
	}
	return n
}

func (m *AverageLayerParams) Size() (n int) {
	var l int
	_ = l
	return n
}

func (m *MaxLayerParams) Size() (n int) {
	var l int
	_ = l
	return n
}

func (m *MinLayerParams) Size() (n int) {
	var l int
	_ = l
	return n
}

func (m *DotProductLayerParams) Size() (n int) {
	var l int
	_ = l
	if m.CosineSimilarity {
		n += 2
	}
	return n
}

func (m *MeanVarianceNormalizeLayerParams) Size() (n int) {
	var l int
	_ = l
	if m.AcrossChannels {
		n += 2
	}
	if m.NormalizeVariance {
		n += 2
	}
	if m.Epsilon != 0 {
		n += 5
	}
	return n
}

func (m *SequenceRepeatLayerParams) Size() (n int) {
	var l int
	_ = l
	if m.NRepetitions != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.NRepetitions))
	}
	return n
}

func (m *SimpleRecurrentLayerParams) Size() (n int) {
	var l int
	_ = l
	if m.InputVectorSize != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.InputVectorSize))
	}
	if m.OutputVectorSize != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.OutputVectorSize))
	}
	if m.Activation != nil {
		l = m.Activation.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	if m.SequenceOutput {
		n += 2
	}
	if m.HasBiasVector {
		n += 3
	}
	if m.WeightMatrix != nil {
		l = m.WeightMatrix.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.RecursionMatrix != nil {
		l = m.RecursionMatrix.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.BiasVector != nil {
		l = m.BiasVector.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.ReverseInput {
		n += 3
	}
	return n
}

func (m *GRULayerParams) Size() (n int) {
	var l int
	_ = l
	if m.InputVectorSize != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.InputVectorSize))
	}
	if m.OutputVectorSize != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.OutputVectorSize))
	}
	if len(m.Activations) > 0 {
		for _, e := range m.Activations {
			l = e.Size()
			n += 1 + l + sovNeuralNetwork(uint64(l))
		}
	}
	if m.SequenceOutput {
		n += 2
	}
	if m.HasBiasVectors {
		n += 3
	}
	if m.UpdateGateWeightMatrix != nil {
		l = m.UpdateGateWeightMatrix.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.ResetGateWeightMatrix != nil {
		l = m.ResetGateWeightMatrix.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.OutputGateWeightMatrix != nil {
		l = m.OutputGateWeightMatrix.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.UpdateGateRecursionMatrix != nil {
		l = m.UpdateGateRecursionMatrix.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.ResetGateRecursionMatrix != nil {
		l = m.ResetGateRecursionMatrix.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.OutputGateRecursionMatrix != nil {
		l = m.OutputGateRecursionMatrix.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.UpdateGateBiasVector != nil {
		l = m.UpdateGateBiasVector.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.ResetGateBiasVector != nil {
		l = m.ResetGateBiasVector.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.OutputGateBiasVector != nil {
		l = m.OutputGateBiasVector.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.ReverseInput {
		n += 3
	}
	return n
}

func (m *LSTMParams) Size() (n int) {
	var l int
	_ = l
	if m.SequenceOutput {
		n += 2
	}
	if m.HasBiasVectors {
		n += 3
	}
	if m.ForgetBias {
		n += 3
	}
	if m.HasPeepholeVectors {
		n += 3
	}
	if m.CoupledInputAndForgetGate {
		n += 3
	}
	if m.CellClipThreshold != 0 {
		n += 6
	}
	return n
}

func (m *LSTMWeightParams) Size() (n int) {
	var l int
	_ = l
	if m.InputGateWeightMatrix != nil {
		l = m.InputGateWeightMatrix.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	if m.ForgetGateWeightMatrix != nil {
		l = m.ForgetGateWeightMatrix.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	if m.BlockInputWeightMatrix != nil {
		l = m.BlockInputWeightMatrix.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	if m.OutputGateWeightMatrix != nil {
		l = m.OutputGateWeightMatrix.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	if m.InputGateRecursionMatrix != nil {
		l = m.InputGateRecursionMatrix.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.ForgetGateRecursionMatrix != nil {
		l = m.ForgetGateRecursionMatrix.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.BlockInputRecursionMatrix != nil {
		l = m.BlockInputRecursionMatrix.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.OutputGateRecursionMatrix != nil {
		l = m.OutputGateRecursionMatrix.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.InputGateBiasVector != nil {
		l = m.InputGateBiasVector.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.ForgetGateBiasVector != nil {
		l = m.ForgetGateBiasVector.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.BlockInputBiasVector != nil {
		l = m.BlockInputBiasVector.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.OutputGateBiasVector != nil {
		l = m.OutputGateBiasVector.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.InputGatePeepholeVector != nil {
		l = m.InputGatePeepholeVector.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.ForgetGatePeepholeVector != nil {
		l = m.ForgetGatePeepholeVector.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.OutputGatePeepholeVector != nil {
		l = m.OutputGatePeepholeVector.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}

func (m *UniDirectionalLSTMLayerParams) Size() (n int) {
	var l int
	_ = l
	if m.InputVectorSize != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.InputVectorSize))
	}
	if m.OutputVectorSize != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.OutputVectorSize))
	}
	if len(m.Activations) > 0 {
		for _, e := range m.Activations {
			l = e.Size()
			n += 1 + l + sovNeuralNetwork(uint64(l))
		}
	}
	if m.Params != nil {
		l = m.Params.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	if m.WeightParams != nil {
		l = m.WeightParams.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	if m.ReverseInput {
		n += 3
	}
	return n
}

func (m *BiDirectionalLSTMLayerParams) Size() (n int) {
	var l int
	_ = l
	if m.InputVectorSize != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.InputVectorSize))
	}
	if m.OutputVectorSize != 0 {
		n += 1 + sovNeuralNetwork(uint64(m.OutputVectorSize))
	}
	if len(m.ActivationsForwardLSTM) > 0 {
		for _, e := range m.ActivationsForwardLSTM {
			l = e.Size()
			n += 1 + l + sovNeuralNetwork(uint64(l))
		}
	}
	if len(m.ActivationsBackwardLSTM) > 0 {
		for _, e := range m.ActivationsBackwardLSTM {
			l = e.Size()
			n += 1 + l + sovNeuralNetwork(uint64(l))
		}
	}
	if m.Params != nil {
		l = m.Params.Size()
		n += 1 + l + sovNeuralNetwork(uint64(l))
	}
	if len(m.WeightParams) > 0 {
		for _, e := range m.WeightParams {
			l = e.Size()
			n += 2 + l + sovNeuralNetwork(uint64(l))
		}
	}
	return n
}

func (m *NeuralNetworkClassifier) Size() (n int) {
	var l int
	_ = l
	if len(m.Layers) > 0 {
		for _, e := range m.Layers {
			l = e.Size()
			n += 1 + l + sovNeuralNetwork(uint64(l))
		}
	}
	if len(m.Preprocessing) > 0 {
		for _, e := range m.Preprocessing {
			l = e.Size()
			n += 1 + l + sovNeuralNetwork(uint64(l))
		}
	}
	if m.ClassLabels != nil {
		n += m.ClassLabels.Size()
	}
	return n
}

func (m *NeuralNetworkClassifier_StringClassLabels) Size() (n int) {
	var l int
	_ = l
	if m.StringClassLabels != nil {
		l = m.StringClassLabels.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkClassifier_Int64ClassLabels) Size() (n int) {
	var l int
	_ = l
	if m.Int64ClassLabels != nil {
		l = m.Int64ClassLabels.Size()
		n += 2 + l + sovNeuralNetwork(uint64(l))
	}
	return n
}
func (m *NeuralNetworkRegressor) Size() (n int) {
	var l int
	_ = l
	if len(m.Layers) > 0 {
		for _, e := range m.Layers {
			l = e.Size()
			n += 1 + l + sovNeuralNetwork(uint64(l))
		}
	}
	if len(m.Preprocessing) > 0 {
		for _, e := range m.Preprocessing {
			l = e.Size()
			n += 1 + l + sovNeuralNetwork(uint64(l))
		}
	}
	return n
}

func sovNeuralNetwork(x uint64) (n int) {
	for {
		n++
		x >>= 7
		if x == 0 {
			break
		}
	}
	return n
}
func sozNeuralNetwork(x uint64) (n int) {
	return sovNeuralNetwork(uint64((x << 1) ^ uint64((int64(x) >> 63))))
}
func (m *NeuralNetwork) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: NeuralNetwork: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: NeuralNetwork: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Layers", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Layers = append(m.Layers, &NeuralNetworkLayer{})
			if err := m.Layers[len(m.Layers)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Preprocessing", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Preprocessing = append(m.Preprocessing, &NeuralNetworkPreprocessing{})
			if err := m.Preprocessing[len(m.Preprocessing)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *NeuralNetworkImageScaler) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: NeuralNetworkImageScaler: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: NeuralNetworkImageScaler: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 10:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field ChannelScale", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.ChannelScale = float32(math.Float32frombits(v))
		case 20:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field BlueBias", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.BlueBias = float32(math.Float32frombits(v))
		case 21:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field GreenBias", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.GreenBias = float32(math.Float32frombits(v))
		case 22:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field RedBias", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.RedBias = float32(math.Float32frombits(v))
		case 30:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field GrayBias", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.GrayBias = float32(math.Float32frombits(v))
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *NeuralNetworkMeanImage) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: NeuralNetworkMeanImage: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: NeuralNetworkMeanImage: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType == 5 {
				var v uint32
				if (iNdEx + 4) > l {
					return io.ErrUnexpectedEOF
				}
				iNdEx += 4
				v = uint32(dAtA[iNdEx-4])
				v |= uint32(dAtA[iNdEx-3]) << 8
				v |= uint32(dAtA[iNdEx-2]) << 16
				v |= uint32(dAtA[iNdEx-1]) << 24
				v2 := float32(math.Float32frombits(v))
				m.MeanImage = append(m.MeanImage, v2)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthNeuralNetwork
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint32
					if (iNdEx + 4) > l {
						return io.ErrUnexpectedEOF
					}
					iNdEx += 4
					v = uint32(dAtA[iNdEx-4])
					v |= uint32(dAtA[iNdEx-3]) << 8
					v |= uint32(dAtA[iNdEx-2]) << 16
					v |= uint32(dAtA[iNdEx-1]) << 24
					v2 := float32(math.Float32frombits(v))
					m.MeanImage = append(m.MeanImage, v2)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field MeanImage", wireType)
			}
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *NeuralNetworkPreprocessing) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: NeuralNetworkPreprocessing: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: NeuralNetworkPreprocessing: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field FeatureName", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + intStringLen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.FeatureName = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 10:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Scaler", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &NeuralNetworkImageScaler{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Preprocessor = &NeuralNetworkPreprocessing_Scaler{v}
			iNdEx = postIndex
		case 11:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field MeanImage", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &NeuralNetworkMeanImage{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Preprocessor = &NeuralNetworkPreprocessing_MeanImage{v}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ActivationReLU) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ActivationReLU: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ActivationReLU: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ActivationLeakyReLU) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ActivationLeakyReLU: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ActivationLeakyReLU: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Alpha", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.Alpha = float32(math.Float32frombits(v))
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ActivationTanh) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ActivationTanh: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ActivationTanh: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ActivationScaledTanh) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ActivationScaledTanh: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ActivationScaledTanh: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Alpha", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.Alpha = float32(math.Float32frombits(v))
		case 2:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Beta", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.Beta = float32(math.Float32frombits(v))
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ActivationSigmoid) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ActivationSigmoid: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ActivationSigmoid: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ActivationLinear) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ActivationLinear: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ActivationLinear: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Alpha", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.Alpha = float32(math.Float32frombits(v))
		case 2:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Beta", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.Beta = float32(math.Float32frombits(v))
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ActivationSigmoidHard) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ActivationSigmoidHard: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ActivationSigmoidHard: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Alpha", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.Alpha = float32(math.Float32frombits(v))
		case 2:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Beta", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.Beta = float32(math.Float32frombits(v))
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ActivationPReLU) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ActivationPReLU: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ActivationPReLU: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Alpha", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Alpha == nil {
				m.Alpha = &WeightParams{}
			}
			if err := m.Alpha.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ActivationELU) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ActivationELU: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ActivationELU: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Alpha", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.Alpha = float32(math.Float32frombits(v))
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ActivationThresholdedReLU) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ActivationThresholdedReLU: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ActivationThresholdedReLU: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Alpha", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.Alpha = float32(math.Float32frombits(v))
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ActivationSoftsign) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ActivationSoftsign: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ActivationSoftsign: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ActivationSoftplus) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ActivationSoftplus: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ActivationSoftplus: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ActivationParametricSoftplus) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ActivationParametricSoftplus: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ActivationParametricSoftplus: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Alpha", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Alpha == nil {
				m.Alpha = &WeightParams{}
			}
			if err := m.Alpha.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Beta", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Beta == nil {
				m.Beta = &WeightParams{}
			}
			if err := m.Beta.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ActivationParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ActivationParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ActivationParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Linear", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &ActivationLinear{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.NonlinearityType = &ActivationParams_Linear{v}
			iNdEx = postIndex
		case 10:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ReLU", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &ActivationReLU{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.NonlinearityType = &ActivationParams_ReLU{v}
			iNdEx = postIndex
		case 15:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field LeakyReLU", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &ActivationLeakyReLU{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.NonlinearityType = &ActivationParams_LeakyReLU{v}
			iNdEx = postIndex
		case 20:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ThresholdedReLU", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &ActivationThresholdedReLU{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.NonlinearityType = &ActivationParams_ThresholdedReLU{v}
			iNdEx = postIndex
		case 25:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field PReLU", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &ActivationPReLU{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.NonlinearityType = &ActivationParams_PReLU{v}
			iNdEx = postIndex
		case 30:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Tanh", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &ActivationTanh{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.NonlinearityType = &ActivationParams_Tanh{v}
			iNdEx = postIndex
		case 31:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ScaledTanh", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &ActivationScaledTanh{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.NonlinearityType = &ActivationParams_ScaledTanh{v}
			iNdEx = postIndex
		case 40:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Sigmoid", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &ActivationSigmoid{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.NonlinearityType = &ActivationParams_Sigmoid{v}
			iNdEx = postIndex
		case 41:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SigmoidHard", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &ActivationSigmoidHard{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.NonlinearityType = &ActivationParams_SigmoidHard{v}
			iNdEx = postIndex
		case 50:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ELU", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &ActivationELU{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.NonlinearityType = &ActivationParams_ELU{v}
			iNdEx = postIndex
		case 60:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Softsign", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &ActivationSoftsign{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.NonlinearityType = &ActivationParams_Softsign{v}
			iNdEx = postIndex
		case 70:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Softplus", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &ActivationSoftplus{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.NonlinearityType = &ActivationParams_Softplus{v}
			iNdEx = postIndex
		case 71:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ParametricSoftplus", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &ActivationParametricSoftplus{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.NonlinearityType = &ActivationParams_ParametricSoftplus{v}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *NeuralNetworkLayer) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: NeuralNetworkLayer: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: NeuralNetworkLayer: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Name", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + intStringLen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Name = string(dAtA[iNdEx:postIndex])
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Input", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + intStringLen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Input = append(m.Input, string(dAtA[iNdEx:postIndex]))
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Output", wireType)
			}
			var stringLen uint64
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				stringLen |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			intStringLen := int(stringLen)
			if intStringLen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + intStringLen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Output = append(m.Output, string(dAtA[iNdEx:postIndex]))
			iNdEx = postIndex
		case 100:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Convolution", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &ConvolutionLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Convolution{v}
			iNdEx = postIndex
		case 120:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Pooling", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &PoolingLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Pooling{v}
			iNdEx = postIndex
		case 130:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Activation", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &ActivationParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Activation{v}
			iNdEx = postIndex
		case 140:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field InnerProduct", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &InnerProductLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_InnerProduct{v}
			iNdEx = postIndex
		case 150:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Embedding", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &EmbeddingLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Embedding{v}
			iNdEx = postIndex
		case 160:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Batchnorm", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &BatchnormLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Batchnorm{v}
			iNdEx = postIndex
		case 165:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Mvn", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &MeanVarianceNormalizeLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Mvn{v}
			iNdEx = postIndex
		case 170:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field L2Normalize", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &L2NormalizeLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_L2Normalize{v}
			iNdEx = postIndex
		case 175:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Softmax", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &SoftmaxLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Softmax{v}
			iNdEx = postIndex
		case 180:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Lrn", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &LRNLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Lrn{v}
			iNdEx = postIndex
		case 190:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Crop", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &CropLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Crop{v}
			iNdEx = postIndex
		case 200:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Padding", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &PaddingLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Padding{v}
			iNdEx = postIndex
		case 210:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Upsample", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &UpsampleLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Upsample{v}
			iNdEx = postIndex
		case 220:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Unary", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &UnaryFunctionLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Unary{v}
			iNdEx = postIndex
		case 230:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Add", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &AddLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Add{v}
			iNdEx = postIndex
		case 231:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Multiply", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &MultiplyLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Multiply{v}
			iNdEx = postIndex
		case 240:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Average", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &AverageLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Average{v}
			iNdEx = postIndex
		case 245:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Scale", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &ScaleLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Scale{v}
			iNdEx = postIndex
		case 250:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Bias", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &BiasLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Bias{v}
			iNdEx = postIndex
		case 260:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Max", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &MaxLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Max{v}
			iNdEx = postIndex
		case 261:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Min", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &MinLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Min{v}
			iNdEx = postIndex
		case 270:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Dot", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &DotProductLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Dot{v}
			iNdEx = postIndex
		case 280:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Reduce", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &ReduceLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Reduce{v}
			iNdEx = postIndex
		case 290:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field LoadConstant", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &LoadConstantLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_LoadConstant{v}
			iNdEx = postIndex
		case 300:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Reshape", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &ReshapeLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Reshape{v}
			iNdEx = postIndex
		case 301:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Flatten", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &FlattenLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Flatten{v}
			iNdEx = postIndex
		case 310:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Permute", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &PermuteLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Permute{v}
			iNdEx = postIndex
		case 320:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Concat", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &ConcatLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Concat{v}
			iNdEx = postIndex
		case 330:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Split", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &SplitLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Split{v}
			iNdEx = postIndex
		case 340:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SequenceRepeat", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &SequenceRepeatLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_SequenceRepeat{v}
			iNdEx = postIndex
		case 400:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field SimpleRecurrent", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &SimpleRecurrentLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_SimpleRecurrent{v}
			iNdEx = postIndex
		case 410:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Gru", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &GRULayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_Gru{v}
			iNdEx = postIndex
		case 420:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field UniDirectionalLSTM", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &UniDirectionalLSTMLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_UniDirectionalLSTM{v}
			iNdEx = postIndex
		case 430:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field BiDirectionalLSTM", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &BiDirectionalLSTMLayerParams{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.Layer = &NeuralNetworkLayer_BiDirectionalLSTM{v}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *BorderAmounts) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: BorderAmounts: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: BorderAmounts: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 10:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field BorderAmounts", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.BorderAmounts = append(m.BorderAmounts, &BorderAmounts_EdgeSizes{})
			if err := m.BorderAmounts[len(m.BorderAmounts)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *BorderAmounts_EdgeSizes) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: EdgeSizes: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: EdgeSizes: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field StartEdgeSize", wireType)
			}
			m.StartEdgeSize = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.StartEdgeSize |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field EndEdgeSize", wireType)
			}
			m.EndEdgeSize = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.EndEdgeSize |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ValidPadding) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ValidPadding: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ValidPadding: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field PaddingAmounts", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.PaddingAmounts == nil {
				m.PaddingAmounts = &BorderAmounts{}
			}
			if err := m.PaddingAmounts.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SamePadding) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SamePadding: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SamePadding: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field AsymmetryMode", wireType)
			}
			m.AsymmetryMode = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.AsymmetryMode |= (SamePadding_SamePaddingMode(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *WeightParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: WeightParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: WeightParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType == 5 {
				var v uint32
				if (iNdEx + 4) > l {
					return io.ErrUnexpectedEOF
				}
				iNdEx += 4
				v = uint32(dAtA[iNdEx-4])
				v |= uint32(dAtA[iNdEx-3]) << 8
				v |= uint32(dAtA[iNdEx-2]) << 16
				v |= uint32(dAtA[iNdEx-1]) << 24
				v2 := float32(math.Float32frombits(v))
				m.FloatValue = append(m.FloatValue, v2)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthNeuralNetwork
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint32
					if (iNdEx + 4) > l {
						return io.ErrUnexpectedEOF
					}
					iNdEx += 4
					v = uint32(dAtA[iNdEx-4])
					v |= uint32(dAtA[iNdEx-3]) << 8
					v |= uint32(dAtA[iNdEx-2]) << 16
					v |= uint32(dAtA[iNdEx-1]) << 24
					v2 := float32(math.Float32frombits(v))
					m.FloatValue = append(m.FloatValue, v2)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field FloatValue", wireType)
			}
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ConvolutionLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ConvolutionLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ConvolutionLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field OutputChannels", wireType)
			}
			m.OutputChannels = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.OutputChannels |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field KernelChannels", wireType)
			}
			m.KernelChannels = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.KernelChannels |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 10:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field NGroups", wireType)
			}
			m.NGroups = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.NGroups |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 20:
			if wireType == 0 {
				var v uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.KernelSize = append(m.KernelSize, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthNeuralNetwork
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowNeuralNetwork
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint64(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.KernelSize = append(m.KernelSize, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field KernelSize", wireType)
			}
		case 30:
			if wireType == 0 {
				var v uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.Stride = append(m.Stride, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthNeuralNetwork
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowNeuralNetwork
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint64(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.Stride = append(m.Stride, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field Stride", wireType)
			}
		case 40:
			if wireType == 0 {
				var v uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.DilationFactor = append(m.DilationFactor, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthNeuralNetwork
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowNeuralNetwork
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint64(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.DilationFactor = append(m.DilationFactor, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field DilationFactor", wireType)
			}
		case 50:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Valid", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &ValidPadding{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.ConvolutionPaddingType = &ConvolutionLayerParams_Valid{v}
			iNdEx = postIndex
		case 51:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Same", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &SamePadding{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.ConvolutionPaddingType = &ConvolutionLayerParams_Same{v}
			iNdEx = postIndex
		case 60:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field IsDeconvolution", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.IsDeconvolution = bool(v != 0)
		case 70:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field HasBias", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.HasBias = bool(v != 0)
		case 90:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Weights", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Weights == nil {
				m.Weights = &WeightParams{}
			}
			if err := m.Weights.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 91:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Bias", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Bias == nil {
				m.Bias = &WeightParams{}
			}
			if err := m.Bias.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 100:
			if wireType == 0 {
				var v uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.OutputShape = append(m.OutputShape, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthNeuralNetwork
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowNeuralNetwork
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint64(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.OutputShape = append(m.OutputShape, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field OutputShape", wireType)
			}
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *InnerProductLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: InnerProductLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: InnerProductLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field InputChannels", wireType)
			}
			m.InputChannels = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.InputChannels |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field OutputChannels", wireType)
			}
			m.OutputChannels = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.OutputChannels |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 10:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field HasBias", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.HasBias = bool(v != 0)
		case 20:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Weights", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Weights == nil {
				m.Weights = &WeightParams{}
			}
			if err := m.Weights.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 21:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Bias", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Bias == nil {
				m.Bias = &WeightParams{}
			}
			if err := m.Bias.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *EmbeddingLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: EmbeddingLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: EmbeddingLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field InputDim", wireType)
			}
			m.InputDim = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.InputDim |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field OutputChannels", wireType)
			}
			m.OutputChannels = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.OutputChannels |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 10:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field HasBias", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.HasBias = bool(v != 0)
		case 20:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Weights", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Weights == nil {
				m.Weights = &WeightParams{}
			}
			if err := m.Weights.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 21:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Bias", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Bias == nil {
				m.Bias = &WeightParams{}
			}
			if err := m.Bias.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *BatchnormLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: BatchnormLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: BatchnormLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Channels", wireType)
			}
			m.Channels = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Channels |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 5:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ComputeMeanVar", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.ComputeMeanVar = bool(v != 0)
		case 6:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field InstanceNormalization", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.InstanceNormalization = bool(v != 0)
		case 10:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Epsilon", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.Epsilon = float32(math.Float32frombits(v))
		case 15:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Gamma", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Gamma == nil {
				m.Gamma = &WeightParams{}
			}
			if err := m.Gamma.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 16:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Beta", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Beta == nil {
				m.Beta = &WeightParams{}
			}
			if err := m.Beta.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 17:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Mean", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Mean == nil {
				m.Mean = &WeightParams{}
			}
			if err := m.Mean.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 18:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Variance", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Variance == nil {
				m.Variance = &WeightParams{}
			}
			if err := m.Variance.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *PoolingLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: PoolingLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: PoolingLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Type", wireType)
			}
			m.Type = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Type |= (PoolingLayerParams_PoolingType(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 10:
			if wireType == 0 {
				var v uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.KernelSize = append(m.KernelSize, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthNeuralNetwork
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowNeuralNetwork
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint64(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.KernelSize = append(m.KernelSize, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field KernelSize", wireType)
			}
		case 20:
			if wireType == 0 {
				var v uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.Stride = append(m.Stride, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthNeuralNetwork
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowNeuralNetwork
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint64(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.Stride = append(m.Stride, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field Stride", wireType)
			}
		case 30:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Valid", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &ValidPadding{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.PoolingPaddingType = &PoolingLayerParams_Valid{v}
			iNdEx = postIndex
		case 31:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Same", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &SamePadding{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.PoolingPaddingType = &PoolingLayerParams_Same{v}
			iNdEx = postIndex
		case 32:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field IncludeLastPixel", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &PoolingLayerParams_ValidCompletePadding{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.PoolingPaddingType = &PoolingLayerParams_IncludeLastPixel{v}
			iNdEx = postIndex
		case 50:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field AvgPoolExcludePadding", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.AvgPoolExcludePadding = bool(v != 0)
		case 60:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field GlobalPooling", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.GlobalPooling = bool(v != 0)
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *PoolingLayerParams_ValidCompletePadding) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ValidCompletePadding: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ValidCompletePadding: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 10:
			if wireType == 0 {
				var v uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.PaddingAmounts = append(m.PaddingAmounts, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthNeuralNetwork
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowNeuralNetwork
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint64(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.PaddingAmounts = append(m.PaddingAmounts, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field PaddingAmounts", wireType)
			}
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *PaddingLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: PaddingLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: PaddingLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Constant", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &PaddingLayerParams_PaddingConstant{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.PaddingType = &PaddingLayerParams_Constant{v}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Reflection", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &PaddingLayerParams_PaddingReflection{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.PaddingType = &PaddingLayerParams_Reflection{v}
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Replication", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &PaddingLayerParams_PaddingReplication{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.PaddingType = &PaddingLayerParams_Replication{v}
			iNdEx = postIndex
		case 10:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field PaddingAmounts", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.PaddingAmounts == nil {
				m.PaddingAmounts = &BorderAmounts{}
			}
			if err := m.PaddingAmounts.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *PaddingLayerParams_PaddingConstant) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: PaddingConstant: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: PaddingConstant: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Value", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.Value = float32(math.Float32frombits(v))
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *PaddingLayerParams_PaddingReflection) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: PaddingReflection: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: PaddingReflection: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *PaddingLayerParams_PaddingReplication) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: PaddingReplication: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: PaddingReplication: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ConcatLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ConcatLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ConcatLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 100:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field SequenceConcat", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.SequenceConcat = bool(v != 0)
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *LRNLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: LRNLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: LRNLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Alpha", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.Alpha = float32(math.Float32frombits(v))
		case 2:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Beta", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.Beta = float32(math.Float32frombits(v))
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field LocalSize", wireType)
			}
			m.LocalSize = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.LocalSize |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 4:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field K", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.K = float32(math.Float32frombits(v))
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SoftmaxLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SoftmaxLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SoftmaxLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SplitLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SplitLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SplitLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field NOutputs", wireType)
			}
			m.NOutputs = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.NOutputs |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *AddLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: AddLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: AddLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Alpha", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.Alpha = float32(math.Float32frombits(v))
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *MultiplyLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: MultiplyLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: MultiplyLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Alpha", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.Alpha = float32(math.Float32frombits(v))
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *UnaryFunctionLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: UnaryFunctionLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: UnaryFunctionLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Type", wireType)
			}
			m.Type = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Type |= (UnaryFunctionLayerParams_Operation(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Alpha", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.Alpha = float32(math.Float32frombits(v))
		case 3:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Epsilon", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.Epsilon = float32(math.Float32frombits(v))
		case 4:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Shift", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.Shift = float32(math.Float32frombits(v))
		case 5:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Scale", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.Scale = float32(math.Float32frombits(v))
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *UpsampleLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: UpsampleLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: UpsampleLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType == 0 {
				var v uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.ScalingFactor = append(m.ScalingFactor, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthNeuralNetwork
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowNeuralNetwork
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint64(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.ScalingFactor = append(m.ScalingFactor, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field ScalingFactor", wireType)
			}
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *BiasLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: BiasLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: BiasLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType == 0 {
				var v uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.Shape = append(m.Shape, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthNeuralNetwork
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowNeuralNetwork
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint64(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.Shape = append(m.Shape, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field Shape", wireType)
			}
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Bias", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Bias == nil {
				m.Bias = &WeightParams{}
			}
			if err := m.Bias.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ScaleLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ScaleLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ScaleLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType == 0 {
				var v uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.ShapeScale = append(m.ShapeScale, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthNeuralNetwork
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowNeuralNetwork
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint64(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.ShapeScale = append(m.ShapeScale, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field ShapeScale", wireType)
			}
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Scale", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Scale == nil {
				m.Scale = &WeightParams{}
			}
			if err := m.Scale.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field HasBias", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.HasBias = bool(v != 0)
		case 4:
			if wireType == 0 {
				var v uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.ShapeBias = append(m.ShapeBias, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthNeuralNetwork
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowNeuralNetwork
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint64(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.ShapeBias = append(m.ShapeBias, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field ShapeBias", wireType)
			}
		case 5:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Bias", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Bias == nil {
				m.Bias = &WeightParams{}
			}
			if err := m.Bias.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *LoadConstantLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: LoadConstantLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: LoadConstantLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType == 0 {
				var v uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.Shape = append(m.Shape, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthNeuralNetwork
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowNeuralNetwork
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint64(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.Shape = append(m.Shape, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field Shape", wireType)
			}
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Data", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Data == nil {
				m.Data = &WeightParams{}
			}
			if err := m.Data.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *L2NormalizeLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: L2NormalizeLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: L2NormalizeLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Epsilon", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.Epsilon = float32(math.Float32frombits(v))
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *FlattenLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: FlattenLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: FlattenLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Mode", wireType)
			}
			m.Mode = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Mode |= (FlattenLayerParams_FlattenOrder(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ReshapeLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ReshapeLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ReshapeLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType == 0 {
				var v int64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (int64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.TargetShape = append(m.TargetShape, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthNeuralNetwork
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v int64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowNeuralNetwork
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (int64(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.TargetShape = append(m.TargetShape, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field TargetShape", wireType)
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Mode", wireType)
			}
			m.Mode = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Mode |= (ReshapeLayerParams_ReshapeOrder(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *PermuteLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: PermuteLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: PermuteLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType == 0 {
				var v uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.Axis = append(m.Axis, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthNeuralNetwork
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowNeuralNetwork
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint64(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.Axis = append(m.Axis, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field Axis", wireType)
			}
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *ReduceLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: ReduceLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: ReduceLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field Mode", wireType)
			}
			m.Mode = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.Mode |= (ReduceLayerParams_ReduceOperation(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Epsilon", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.Epsilon = float32(math.Float32frombits(v))
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *CropLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: CropLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: CropLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field CropAmounts", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.CropAmounts == nil {
				m.CropAmounts = &BorderAmounts{}
			}
			if err := m.CropAmounts.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 5:
			if wireType == 0 {
				var v uint64
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					v |= (uint64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				m.Offset = append(m.Offset, v)
			} else if wireType == 2 {
				var packedLen int
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					packedLen |= (int(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				if packedLen < 0 {
					return ErrInvalidLengthNeuralNetwork
				}
				postIndex := iNdEx + packedLen
				if postIndex > l {
					return io.ErrUnexpectedEOF
				}
				for iNdEx < postIndex {
					var v uint64
					for shift := uint(0); ; shift += 7 {
						if shift >= 64 {
							return ErrIntOverflowNeuralNetwork
						}
						if iNdEx >= l {
							return io.ErrUnexpectedEOF
						}
						b := dAtA[iNdEx]
						iNdEx++
						v |= (uint64(b) & 0x7F) << shift
						if b < 0x80 {
							break
						}
					}
					m.Offset = append(m.Offset, v)
				}
			} else {
				return fmt.Errorf("proto: wrong wireType = %d for field Offset", wireType)
			}
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *AverageLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: AverageLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: AverageLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *MaxLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: MaxLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: MaxLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *MinLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: MinLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: MinLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *DotProductLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: DotProductLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: DotProductLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field CosineSimilarity", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.CosineSimilarity = bool(v != 0)
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *MeanVarianceNormalizeLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: MeanVarianceNormalizeLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: MeanVarianceNormalizeLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field AcrossChannels", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.AcrossChannels = bool(v != 0)
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field NormalizeVariance", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.NormalizeVariance = bool(v != 0)
		case 3:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field Epsilon", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.Epsilon = float32(math.Float32frombits(v))
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SequenceRepeatLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SequenceRepeatLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SequenceRepeatLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field NRepetitions", wireType)
			}
			m.NRepetitions = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.NRepetitions |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *SimpleRecurrentLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: SimpleRecurrentLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: SimpleRecurrentLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field InputVectorSize", wireType)
			}
			m.InputVectorSize = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.InputVectorSize |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field OutputVectorSize", wireType)
			}
			m.OutputVectorSize = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.OutputVectorSize |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 10:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Activation", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Activation == nil {
				m.Activation = &ActivationParams{}
			}
			if err := m.Activation.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 15:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field SequenceOutput", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.SequenceOutput = bool(v != 0)
		case 20:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field HasBiasVector", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.HasBiasVector = bool(v != 0)
		case 30:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field WeightMatrix", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.WeightMatrix == nil {
				m.WeightMatrix = &WeightParams{}
			}
			if err := m.WeightMatrix.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 31:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field RecursionMatrix", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.RecursionMatrix == nil {
				m.RecursionMatrix = &WeightParams{}
			}
			if err := m.RecursionMatrix.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 32:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field BiasVector", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.BiasVector == nil {
				m.BiasVector = &WeightParams{}
			}
			if err := m.BiasVector.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 100:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ReverseInput", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.ReverseInput = bool(v != 0)
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *GRULayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: GRULayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: GRULayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field InputVectorSize", wireType)
			}
			m.InputVectorSize = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.InputVectorSize |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field OutputVectorSize", wireType)
			}
			m.OutputVectorSize = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.OutputVectorSize |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 10:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Activations", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Activations = append(m.Activations, &ActivationParams{})
			if err := m.Activations[len(m.Activations)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 15:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field SequenceOutput", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.SequenceOutput = bool(v != 0)
		case 20:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field HasBiasVectors", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.HasBiasVectors = bool(v != 0)
		case 30:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field UpdateGateWeightMatrix", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.UpdateGateWeightMatrix == nil {
				m.UpdateGateWeightMatrix = &WeightParams{}
			}
			if err := m.UpdateGateWeightMatrix.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 31:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ResetGateWeightMatrix", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.ResetGateWeightMatrix == nil {
				m.ResetGateWeightMatrix = &WeightParams{}
			}
			if err := m.ResetGateWeightMatrix.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 32:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OutputGateWeightMatrix", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.OutputGateWeightMatrix == nil {
				m.OutputGateWeightMatrix = &WeightParams{}
			}
			if err := m.OutputGateWeightMatrix.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 50:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field UpdateGateRecursionMatrix", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.UpdateGateRecursionMatrix == nil {
				m.UpdateGateRecursionMatrix = &WeightParams{}
			}
			if err := m.UpdateGateRecursionMatrix.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 51:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ResetGateRecursionMatrix", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.ResetGateRecursionMatrix == nil {
				m.ResetGateRecursionMatrix = &WeightParams{}
			}
			if err := m.ResetGateRecursionMatrix.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 52:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OutputGateRecursionMatrix", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.OutputGateRecursionMatrix == nil {
				m.OutputGateRecursionMatrix = &WeightParams{}
			}
			if err := m.OutputGateRecursionMatrix.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 70:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field UpdateGateBiasVector", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.UpdateGateBiasVector == nil {
				m.UpdateGateBiasVector = &WeightParams{}
			}
			if err := m.UpdateGateBiasVector.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 71:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ResetGateBiasVector", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.ResetGateBiasVector == nil {
				m.ResetGateBiasVector = &WeightParams{}
			}
			if err := m.ResetGateBiasVector.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 72:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OutputGateBiasVector", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.OutputGateBiasVector == nil {
				m.OutputGateBiasVector = &WeightParams{}
			}
			if err := m.OutputGateBiasVector.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 100:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ReverseInput", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.ReverseInput = bool(v != 0)
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *LSTMParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: LSTMParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: LSTMParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 10:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field SequenceOutput", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.SequenceOutput = bool(v != 0)
		case 20:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field HasBiasVectors", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.HasBiasVectors = bool(v != 0)
		case 30:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ForgetBias", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.ForgetBias = bool(v != 0)
		case 40:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field HasPeepholeVectors", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.HasPeepholeVectors = bool(v != 0)
		case 50:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field CoupledInputAndForgetGate", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.CoupledInputAndForgetGate = bool(v != 0)
		case 60:
			if wireType != 5 {
				return fmt.Errorf("proto: wrong wireType = %d for field CellClipThreshold", wireType)
			}
			var v uint32
			if (iNdEx + 4) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += 4
			v = uint32(dAtA[iNdEx-4])
			v |= uint32(dAtA[iNdEx-3]) << 8
			v |= uint32(dAtA[iNdEx-2]) << 16
			v |= uint32(dAtA[iNdEx-1]) << 24
			m.CellClipThreshold = float32(math.Float32frombits(v))
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *LSTMWeightParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: LSTMWeightParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: LSTMWeightParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field InputGateWeightMatrix", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.InputGateWeightMatrix == nil {
				m.InputGateWeightMatrix = &WeightParams{}
			}
			if err := m.InputGateWeightMatrix.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ForgetGateWeightMatrix", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.ForgetGateWeightMatrix == nil {
				m.ForgetGateWeightMatrix = &WeightParams{}
			}
			if err := m.ForgetGateWeightMatrix.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 3:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field BlockInputWeightMatrix", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.BlockInputWeightMatrix == nil {
				m.BlockInputWeightMatrix = &WeightParams{}
			}
			if err := m.BlockInputWeightMatrix.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 4:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OutputGateWeightMatrix", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.OutputGateWeightMatrix == nil {
				m.OutputGateWeightMatrix = &WeightParams{}
			}
			if err := m.OutputGateWeightMatrix.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 20:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field InputGateRecursionMatrix", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.InputGateRecursionMatrix == nil {
				m.InputGateRecursionMatrix = &WeightParams{}
			}
			if err := m.InputGateRecursionMatrix.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 21:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ForgetGateRecursionMatrix", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.ForgetGateRecursionMatrix == nil {
				m.ForgetGateRecursionMatrix = &WeightParams{}
			}
			if err := m.ForgetGateRecursionMatrix.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 22:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field BlockInputRecursionMatrix", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.BlockInputRecursionMatrix == nil {
				m.BlockInputRecursionMatrix = &WeightParams{}
			}
			if err := m.BlockInputRecursionMatrix.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 23:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OutputGateRecursionMatrix", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.OutputGateRecursionMatrix == nil {
				m.OutputGateRecursionMatrix = &WeightParams{}
			}
			if err := m.OutputGateRecursionMatrix.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 40:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field InputGateBiasVector", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.InputGateBiasVector == nil {
				m.InputGateBiasVector = &WeightParams{}
			}
			if err := m.InputGateBiasVector.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 41:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ForgetGateBiasVector", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.ForgetGateBiasVector == nil {
				m.ForgetGateBiasVector = &WeightParams{}
			}
			if err := m.ForgetGateBiasVector.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 42:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field BlockInputBiasVector", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.BlockInputBiasVector == nil {
				m.BlockInputBiasVector = &WeightParams{}
			}
			if err := m.BlockInputBiasVector.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 43:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OutputGateBiasVector", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.OutputGateBiasVector == nil {
				m.OutputGateBiasVector = &WeightParams{}
			}
			if err := m.OutputGateBiasVector.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 60:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field InputGatePeepholeVector", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.InputGatePeepholeVector == nil {
				m.InputGatePeepholeVector = &WeightParams{}
			}
			if err := m.InputGatePeepholeVector.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 61:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ForgetGatePeepholeVector", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.ForgetGatePeepholeVector == nil {
				m.ForgetGatePeepholeVector = &WeightParams{}
			}
			if err := m.ForgetGatePeepholeVector.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 62:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field OutputGatePeepholeVector", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.OutputGatePeepholeVector == nil {
				m.OutputGatePeepholeVector = &WeightParams{}
			}
			if err := m.OutputGatePeepholeVector.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *UniDirectionalLSTMLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: UniDirectionalLSTMLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: UniDirectionalLSTMLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field InputVectorSize", wireType)
			}
			m.InputVectorSize = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.InputVectorSize |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field OutputVectorSize", wireType)
			}
			m.OutputVectorSize = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.OutputVectorSize |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 10:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Activations", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Activations = append(m.Activations, &ActivationParams{})
			if err := m.Activations[len(m.Activations)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 15:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Params", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Params == nil {
				m.Params = &LSTMParams{}
			}
			if err := m.Params.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 20:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field WeightParams", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.WeightParams == nil {
				m.WeightParams = &LSTMWeightParams{}
			}
			if err := m.WeightParams.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 100:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field ReverseInput", wireType)
			}
			var v int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				v |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			m.ReverseInput = bool(v != 0)
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *BiDirectionalLSTMLayerParams) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: BiDirectionalLSTMLayerParams: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: BiDirectionalLSTMLayerParams: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field InputVectorSize", wireType)
			}
			m.InputVectorSize = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.InputVectorSize |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 2:
			if wireType != 0 {
				return fmt.Errorf("proto: wrong wireType = %d for field OutputVectorSize", wireType)
			}
			m.OutputVectorSize = 0
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				m.OutputVectorSize |= (uint64(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
		case 10:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ActivationsForwardLSTM", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ActivationsForwardLSTM = append(m.ActivationsForwardLSTM, &ActivationParams{})
			if err := m.ActivationsForwardLSTM[len(m.ActivationsForwardLSTM)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 11:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field ActivationsBackwardLSTM", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.ActivationsBackwardLSTM = append(m.ActivationsBackwardLSTM, &ActivationParams{})
			if err := m.ActivationsBackwardLSTM[len(m.ActivationsBackwardLSTM)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 15:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Params", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			if m.Params == nil {
				m.Params = &LSTMParams{}
			}
			if err := m.Params.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 20:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field WeightParams", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.WeightParams = append(m.WeightParams, &LSTMWeightParams{})
			if err := m.WeightParams[len(m.WeightParams)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *NeuralNetworkClassifier) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: NeuralNetworkClassifier: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: NeuralNetworkClassifier: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Layers", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Layers = append(m.Layers, &NeuralNetworkLayer{})
			if err := m.Layers[len(m.Layers)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Preprocessing", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Preprocessing = append(m.Preprocessing, &NeuralNetworkPreprocessing{})
			if err := m.Preprocessing[len(m.Preprocessing)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 100:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field StringClassLabels", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &StringVector{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.ClassLabels = &NeuralNetworkClassifier_StringClassLabels{v}
			iNdEx = postIndex
		case 101:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Int64ClassLabels", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			v := &Int64Vector{}
			if err := v.Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			m.ClassLabels = &NeuralNetworkClassifier_Int64ClassLabels{v}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func (m *NeuralNetworkRegressor) Unmarshal(dAtA []byte) error {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		preIndex := iNdEx
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		fieldNum := int32(wire >> 3)
		wireType := int(wire & 0x7)
		if wireType == 4 {
			return fmt.Errorf("proto: NeuralNetworkRegressor: wiretype end group for non-group")
		}
		if fieldNum <= 0 {
			return fmt.Errorf("proto: NeuralNetworkRegressor: illegal tag %d (wire type %d)", fieldNum, wire)
		}
		switch fieldNum {
		case 1:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Layers", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Layers = append(m.Layers, &NeuralNetworkLayer{})
			if err := m.Layers[len(m.Layers)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		case 2:
			if wireType != 2 {
				return fmt.Errorf("proto: wrong wireType = %d for field Preprocessing", wireType)
			}
			var msglen int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				msglen |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			if msglen < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			postIndex := iNdEx + msglen
			if postIndex > l {
				return io.ErrUnexpectedEOF
			}
			m.Preprocessing = append(m.Preprocessing, &NeuralNetworkPreprocessing{})
			if err := m.Preprocessing[len(m.Preprocessing)-1].Unmarshal(dAtA[iNdEx:postIndex]); err != nil {
				return err
			}
			iNdEx = postIndex
		default:
			iNdEx = preIndex
			skippy, err := skipNeuralNetwork(dAtA[iNdEx:])
			if err != nil {
				return err
			}
			if skippy < 0 {
				return ErrInvalidLengthNeuralNetwork
			}
			if (iNdEx + skippy) > l {
				return io.ErrUnexpectedEOF
			}
			iNdEx += skippy
		}
	}

	if iNdEx > l {
		return io.ErrUnexpectedEOF
	}
	return nil
}
func skipNeuralNetwork(dAtA []byte) (n int, err error) {
	l := len(dAtA)
	iNdEx := 0
	for iNdEx < l {
		var wire uint64
		for shift := uint(0); ; shift += 7 {
			if shift >= 64 {
				return 0, ErrIntOverflowNeuralNetwork
			}
			if iNdEx >= l {
				return 0, io.ErrUnexpectedEOF
			}
			b := dAtA[iNdEx]
			iNdEx++
			wire |= (uint64(b) & 0x7F) << shift
			if b < 0x80 {
				break
			}
		}
		wireType := int(wire & 0x7)
		switch wireType {
		case 0:
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				iNdEx++
				if dAtA[iNdEx-1] < 0x80 {
					break
				}
			}
			return iNdEx, nil
		case 1:
			iNdEx += 8
			return iNdEx, nil
		case 2:
			var length int
			for shift := uint(0); ; shift += 7 {
				if shift >= 64 {
					return 0, ErrIntOverflowNeuralNetwork
				}
				if iNdEx >= l {
					return 0, io.ErrUnexpectedEOF
				}
				b := dAtA[iNdEx]
				iNdEx++
				length |= (int(b) & 0x7F) << shift
				if b < 0x80 {
					break
				}
			}
			iNdEx += length
			if length < 0 {
				return 0, ErrInvalidLengthNeuralNetwork
			}
			return iNdEx, nil
		case 3:
			for {
				var innerWire uint64
				var start int = iNdEx
				for shift := uint(0); ; shift += 7 {
					if shift >= 64 {
						return 0, ErrIntOverflowNeuralNetwork
					}
					if iNdEx >= l {
						return 0, io.ErrUnexpectedEOF
					}
					b := dAtA[iNdEx]
					iNdEx++
					innerWire |= (uint64(b) & 0x7F) << shift
					if b < 0x80 {
						break
					}
				}
				innerWireType := int(innerWire & 0x7)
				if innerWireType == 4 {
					break
				}
				next, err := skipNeuralNetwork(dAtA[start:])
				if err != nil {
					return 0, err
				}
				iNdEx = start + next
			}
			return iNdEx, nil
		case 4:
			return iNdEx, nil
		case 5:
			iNdEx += 4
			return iNdEx, nil
		default:
			return 0, fmt.Errorf("proto: illegal wireType %d", wireType)
		}
	}
	panic("unreachable")
}

var (
	ErrInvalidLengthNeuralNetwork = fmt.Errorf("proto: negative length found during unmarshaling")
	ErrIntOverflowNeuralNetwork   = fmt.Errorf("proto: integer overflow")
)

func init() { proto.RegisterFile("NeuralNetwork.proto", fileDescriptorNeuralNetwork) }

var fileDescriptorNeuralNetwork = []byte{
	// 3722 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xcc, 0x5b, 0x4d, 0x70, 0x24, 0xc9,
	0x55, 0x56, 0x75, 0xb7, 0xfe, 0x5e, 0xeb, 0xa7, 0x27, 0xd5, 0xa3, 0xa9, 0x11, 0x63, 0xad, 0x28,
	0xec, 0xb5, 0x66, 0x66, 0x91, 0x59, 0xed, 0xb0, 0x5e, 0x76, 0x76, 0x06, 0xd4, 0x9a, 0x96, 0x7a,
	0x1c, 0x2d, 0xa9, 0xb7, 0x5a, 0xd2, 0xae, 0x21, 0x88, 0x8d, 0x54, 0x57, 0x4a, 0xaa, 0x98, 0xea,
	0xaa, 0xa6, 0xaa, 0x7a, 0x76, 0xe4, 0x23, 0x61, 0x38, 0x01, 0xe1, 0x20, 0x02, 0xe3, 0xf0, 0x05,
	0x02, 0x4c, 0x04, 0xc1, 0x8f, 0xcd, 0x81, 0xe0, 0x08, 0x3e, 0x11, 0x8e, 0x3d, 0x38, 0x08, 0xc2,
	0x37, 0x7c, 0x20, 0x96, 0x08, 0xb8, 0x72, 0xe1, 0xc2, 0x89, 0x78, 0x59, 0x3f, 0x9d, 0x99, 0xf5,
	0xa3, 0x19, 0x3b, 0xb0, 0x7d, 0xeb, 0x7c, 0xf9, 0xbe, 0x57, 0x2f, 0xdf, 0xcb, 0x7c, 0xf9, 0xde,
	0xab, 0x6a, 0x58, 0x39, 0x64, 0x63, 0x9f, 0x3a, 0x87, 0x2c, 0xfc, 0xd8, 0xf3, 0x9f, 0x6d, 0x8d,
	0x7c, 0x2f, 0xf4, 0xc8, 0xcc, 0xae, 0xe7, 0xb3, 0x83, 0xee, 0x5a, 0xf3, 0x09, 0x0d, 0x69, 0x3f,
	0xf4, 0xc7, 0x83, 0x70, 0xec, 0xb3, 0x20, 0x9a, 0x35, 0x7e, 0x5f, 0x83, 0x45, 0x09, 0x45, 0xb6,
	0x61, 0xc6, 0xa1, 0x57, 0xcc, 0x0f, 0x74, 0x6d, 0xa3, 0xba, 0x59, 0xdf, 0x5e, 0xdb, 0x8a, 0x04,
	0x6c, 0x49, 0x6c, 0x5d, 0x64, 0x31, 0x63, 0x4e, 0xd2, 0x81, 0xc5, 0x91, 0xcf, 0x46, 0xbe, 0x37,
	0x60, 0x41, 0x60, 0xbb, 0x17, 0x7a, 0x85, 0x43, 0x8d, 0x5c, 0x68, 0x4f, 0xe4, 0x34, 0x65, 0xa0,
	0xf1, 0x6d, 0x0d, 0x74, 0x89, 0xfb, 0xe9, 0x90, 0x5e, 0xb0, 0xfe, 0x80, 0x3a, 0xcc, 0x27, 0x06,
	0x2c, 0x0c, 0x2e, 0xa9, 0xeb, 0x32, 0x87, 0x13, 0x74, 0xd8, 0xd0, 0x36, 0x2b, 0xa6, 0x44, 0x23,
	0x6b, 0x30, 0x77, 0xe6, 0x8c, 0x59, 0xcb, 0xa6, 0x81, 0xde, 0xe4, 0xf3, 0xe9, 0x98, 0xdc, 0x81,
	0xf9, 0x0b, 0x9f, 0x31, 0x97, 0x4f, 0xde, 0xe4, 0x93, 0x13, 0x02, 0xd1, 0x61, 0xd6, 0x67, 0x16,
	0x9f, 0x5b, 0xe5, 0x73, 0xc9, 0x10, 0x65, 0x5e, 0xf8, 0xf4, 0x8a, 0x4f, 0xad, 0x47, 0x32, 0x93,
	0xb1, 0xf1, 0x36, 0xac, 0x4a, 0xfa, 0x1e, 0x30, 0xea, 0x72, 0x9d, 0xf1, 0x69, 0xc3, 0x64, 0xc0,
	0x6d, 0x59, 0x31, 0x27, 0x04, 0xe3, 0x13, 0x0d, 0xd6, 0x8a, 0xcd, 0x42, 0x36, 0xa0, 0x7e, 0xce,
	0x28, 0x7a, 0xea, 0x90, 0x0e, 0x11, 0xae, 0x6d, 0xce, 0x9b, 0x22, 0x89, 0xbc, 0x0b, 0x33, 0x01,
	0x37, 0x0b, 0x37, 0x43, 0x7d, 0x7b, 0x23, 0xd7, 0xd8, 0x82, 0xf9, 0x3a, 0x53, 0x66, 0x8c, 0x20,
	0x8f, 0x45, 0xd5, 0xea, 0x1c, 0xbe, 0x9e, 0x0b, 0x4f, 0x57, 0xd3, 0x99, 0x12, 0x94, 0x6f, 0x2d,
	0xc1, 0xc2, 0xc4, 0x6d, 0x9e, 0x6f, 0x34, 0x60, 0x69, 0x67, 0x10, 0xda, 0xcf, 0x69, 0x68, 0x7b,
	0xae, 0xc9, 0xba, 0x27, 0xc6, 0x7d, 0x58, 0x99, 0x50, 0xba, 0x8c, 0x3e, 0xbb, 0x42, 0x32, 0x69,
	0xc2, 0x34, 0x75, 0x46, 0x97, 0x94, 0x2f, 0xa8, 0x62, 0x46, 0x03, 0x19, 0x7e, 0x4c, 0xdd, 0x4b,
	0xe3, 0xd7, 0xa0, 0x39, 0xa1, 0x70, 0xf5, 0x2d, 0xa4, 0xe7, 0xe3, 0x09, 0x81, 0xda, 0x19, 0x0b,
	0xa9, 0x5e, 0xe1, 0x44, 0xfe, 0xdb, 0x58, 0x81, 0x1b, 0x82, 0x04, 0xfb, 0x62, 0xe8, 0xd9, 0x96,
	0xf1, 0x1e, 0x34, 0x04, 0xad, 0x6c, 0x97, 0x51, 0xff, 0x15, 0x44, 0xee, 0xc0, 0xcd, 0x8c, 0xc8,
	0x0e, 0xf5, 0xad, 0x57, 0x10, 0xf1, 0x08, 0x96, 0x27, 0x22, 0x7a, 0xdc, 0x24, 0xf7, 0x44, 0x70,
	0x7d, 0xbb, 0x99, 0xf8, 0xe1, 0x03, 0x66, 0x5f, 0x5c, 0x86, 0x3d, 0xea, 0xd3, 0x61, 0x90, 0x18,
	0xea, 0x73, 0xb0, 0x38, 0x81, 0xb7, 0x0b, 0xed, 0xf9, 0x26, 0xdc, 0x16, 0xec, 0x79, 0xe9, 0xb3,
	0xe0, 0xd2, 0x73, 0x2c, 0x66, 0x95, 0xb8, 0xa0, 0x09, 0x44, 0x58, 0x9b, 0x77, 0x1e, 0x06, 0xf6,
	0x85, 0x9b, 0xa5, 0x8e, 0x9c, 0x71, 0x60, 0x84, 0x70, 0x47, 0x58, 0x04, 0x2a, 0xc8, 0x42, 0xdf,
	0x1e, 0x24, 0xf3, 0xaf, 0xb2, 0x22, 0xb2, 0x29, 0x18, 0xa9, 0x88, 0x35, 0x32, 0xdd, 0xb7, 0x66,
	0x44, 0xe7, 0x45, 0x53, 0x3c, 0x58, 0x71, 0x37, 0xea, 0xd3, 0x5c, 0x80, 0x9e, 0x08, 0x50, 0xdd,
	0x8c, 0x9b, 0x3f, 0xe2, 0x24, 0x6f, 0x40, 0x0d, 0x0d, 0x11, 0x1f, 0x9b, 0xd5, 0x2c, 0x02, 0x67,
	0x3b, 0x53, 0x26, 0xe7, 0x22, 0x0f, 0x61, 0xde, 0x49, 0xb6, 0xaf, 0xbe, 0xcc, 0x21, 0x3f, 0x97,
	0xf3, 0x90, 0x84, 0x05, 0xcf, 0x49, 0xca, 0x4f, 0x0e, 0x60, 0x39, 0x94, 0xcd, 0xcf, 0x63, 0x52,
	0x7d, 0xfb, 0xe7, 0xb3, 0x22, 0x14, 0x3f, 0x75, 0xa6, 0x4c, 0x15, 0x4b, 0xbe, 0x00, 0xd3, 0x7c,
	0xcf, 0xe8, 0xb7, 0xb9, 0x90, 0x5b, 0x59, 0x21, 0xbd, 0x18, 0x1a, 0xf1, 0xe1, 0x52, 0x43, 0xea,
	0x5e, 0xf2, 0xa0, 0x95, 0xbb, 0x54, 0x3c, 0x54, 0xb8, 0x54, 0xe4, 0x22, 0x8f, 0x01, 0x82, 0xf4,
	0xa8, 0xe9, 0xaf, 0x71, 0xcc, 0x9d, 0x2c, 0x66, 0x72, 0x1c, 0x3b, 0x53, 0xa6, 0x80, 0x20, 0xbf,
	0x0c, 0xb3, 0x41, 0x74, 0x2a, 0xf4, 0x4d, 0x0e, 0xbe, 0x9d, 0x03, 0x8e, 0x8f, 0xcd, 0x94, 0x99,
	0xf0, 0x92, 0x1d, 0xa8, 0x07, 0x93, 0xc3, 0xa4, 0xdf, 0xe5, 0xd0, 0xcf, 0x14, 0x43, 0xa9, 0x8f,
	0x70, 0x11, 0x43, 0xee, 0x42, 0xb5, 0xdd, 0x3d, 0xd1, 0xb7, 0x39, 0xf4, 0x66, 0x16, 0xda, 0xe6,
	0x46, 0x41, 0x1e, 0xf2, 0x0e, 0xcc, 0x05, 0xf1, 0xf6, 0xd6, 0xdf, 0xe3, 0xfc, 0x6b, 0x39, 0x8f,
	0x8a, 0x39, 0x3a, 0x53, 0x66, 0xca, 0x9d, 0x20, 0x71, 0x8b, 0xeb, 0x7b, 0x65, 0x48, 0xe4, 0x48,
	0x90, 0xfc, 0x40, 0x9c, 0x02, 0x19, 0x65, 0x8e, 0x89, 0xbe, 0xcf, 0x65, 0x7c, 0x36, 0xc7, 0x89,
	0x19, 0xde, 0xce, 0x94, 0x99, 0x23, 0xa1, 0x45, 0xa0, 0x71, 0xe8, 0xb9, 0xd1, 0xb6, 0xb6, 0xc3,
	0xab, 0xe3, 0xab, 0x11, 0x33, 0x3e, 0x69, 0x00, 0xc9, 0xde, 0xd4, 0x18, 0x8c, 0xdc, 0xc9, 0x45,
	0xc2, 0x7f, 0x63, 0x24, 0xb0, 0xdd, 0xd1, 0x38, 0xe4, 0xb7, 0xf5, 0xbc, 0x19, 0x0d, 0xc8, 0x2a,
	0xcc, 0x78, 0xe3, 0x10, 0xc9, 0x55, 0x4e, 0x8e, 0x47, 0xa4, 0x05, 0xf5, 0x81, 0xe7, 0x3e, 0xf7,
	0x9c, 0x31, 0xea, 0xa8, 0x5b, 0xf2, 0xad, 0xb1, 0x3b, 0x99, 0xe2, 0x0f, 0x8c, 0xce, 0x27, 0xfa,
	0x49, 0x00, 0x91, 0xb7, 0x61, 0x76, 0xe4, 0x79, 0x0e, 0x66, 0x08, 0x2f, 0x64, 0x0b, 0xf6, 0x22,
	0xb2, 0x8c, 0x4d, 0x98, 0xc9, 0x43, 0x00, 0x9a, 0x9a, 0x47, 0xff, 0x6d, 0xad, 0xe8, 0xac, 0xa7,
	0x48, 0x81, 0x9d, 0xec, 0xc1, 0x82, 0xed, 0xba, 0xcc, 0xef, 0xf9, 0x9e, 0x35, 0x1e, 0x84, 0xfa,
	0xef, 0x45, 0xf0, 0xd7, 0x12, 0xf8, 0x53, 0x61, 0x52, 0x7e, 0xbe, 0x84, 0x23, 0x8f, 0x60, 0x9e,
	0x0d, 0xcf, 0x98, 0x65, 0xa1, 0xfa, 0x5f, 0xd7, 0xe4, 0xe3, 0xd1, 0x4e, 0x66, 0x64, 0x09, 0x13,
	0x04, 0xc2, 0xcf, 0x68, 0x38, 0xb8, 0x74, 0x3d, 0x7f, 0xa8, 0xff, 0xa9, 0x02, 0x6f, 0x25, 0x33,
	0x0a, 0x3c, 0x45, 0x90, 0x47, 0x50, 0x1d, 0x3e, 0x77, 0xf5, 0xbf, 0x88, 0x80, 0x9b, 0x09, 0x10,
	0x2f, 0xe8, 0x53, 0xea, 0xdb, 0xd4, 0x1d, 0xb0, 0x43, 0xcf, 0x1f, 0x52, 0xc7, 0xfe, 0x0a, 0x93,
	0x85, 0x20, 0x8e, 0xec, 0x42, 0xdd, 0xd9, 0x76, 0x13, 0x06, 0xfd, 0xaf, 0x34, 0xd9, 0x7d, 0xdd,
	0xed, 0x02, 0xb0, 0x88, 0x22, 0x5f, 0x84, 0x59, 0xdc, 0xd3, 0x43, 0xfa, 0x42, 0xff, 0x8e, 0x26,
	0xfb, 0xaf, 0x1f, 0xd1, 0x15, 0xff, 0xc5, 0xdc, 0xe4, 0x3e, 0x54, 0x1d, 0xdf, 0xd5, 0xff, 0x5e,
	0x93, 0xe3, 0x50, 0xd7, 0x3c, 0x54, 0x54, 0x75, 0x7c, 0x97, 0x6c, 0x41, 0x6d, 0xe0, 0x7b, 0x23,
	0xfd, 0x1f, 0x35, 0x39, 0xca, 0xed, 0xfa, 0xde, 0x48, 0x66, 0xe7, 0x7c, 0xa8, 0xd5, 0x88, 0x46,
	0x5e, 0xf9, 0x9e, 0xa2, 0x55, 0x8f, 0xe6, 0xf8, 0x24, 0xe1, 0x26, 0xef, 0xc2, 0xdc, 0x78, 0x14,
	0xd0, 0xe1, 0xc8, 0x61, 0xfa, 0xbf, 0x6a, 0x72, 0x68, 0x3f, 0x89, 0x27, 0x64, 0x68, 0xca, 0x4f,
	0x7e, 0x05, 0xa6, 0xc7, 0x2e, 0xf5, 0xaf, 0xf4, 0x1f, 0x6a, 0x72, 0xf6, 0x75, 0x82, 0xd4, 0xbd,
	0xb1, 0x3b, 0xc8, 0x1e, 0x85, 0x08, 0x81, 0xc6, 0xa0, 0x96, 0xa5, 0xff, 0xa7, 0x62, 0x8c, 0x1d,
	0xcb, 0x52, 0x8c, 0x41, 0x2d, 0x0b, 0x75, 0x1c, 0x8e, 0x9d, 0xd0, 0x1e, 0x39, 0x57, 0xfa, 0x7f,
	0x29, 0x3a, 0x1e, 0xc4, 0x13, 0x8a, 0x8e, 0x09, 0x3f, 0x1a, 0x86, 0x3e, 0x67, 0x3e, 0xe6, 0x78,
	0xff, 0xad, 0x18, 0x66, 0x27, 0xa2, 0x2b, 0x86, 0x89, 0xb9, 0xc9, 0x9b, 0x30, 0xcd, 0xc3, 0xba,
	0xfe, 0x3f, 0xca, 0x49, 0xe3, 0xa1, 0x5f, 0x59, 0x14, 0xe7, 0x44, 0xa7, 0x9d, 0x61, 0x7a, 0xfc,
	0xbf, 0x8a, 0xd3, 0x30, 0x47, 0x56, 0x9c, 0x86, 0x7c, 0x68, 0x04, 0xdc, 0x46, 0x5f, 0xad, 0xc8,
	0x46, 0x38, 0x50, 0xb7, 0x50, 0x35, 0xde, 0x3e, 0x43, 0xdb, 0xd5, 0x7f, 0x47, 0x65, 0xb6, 0x5d,
	0x95, 0xd9, 0x76, 0xc9, 0x36, 0x54, 0x2d, 0x2f, 0xd4, 0xff, 0xa0, 0x22, 0xdf, 0x23, 0x4f, 0xbc,
	0x30, 0xf7, 0x8c, 0x23, 0x33, 0x79, 0x00, 0x33, 0x3e, 0xb3, 0xc6, 0x03, 0xa6, 0x7f, 0xa3, 0x22,
	0xdf, 0x5c, 0x26, 0x27, 0xcb, 0x90, 0x98, 0x17, 0x03, 0x8b, 0xe3, 0x51, 0x6b, 0xd7, 0x73, 0x83,
	0x90, 0xba, 0xa1, 0xfe, 0x67, 0x15, 0x39, 0xb0, 0x74, 0x85, 0x49, 0x25, 0xb0, 0x88, 0x38, 0xf4,
	0x13, 0xde, 0xf3, 0x74, 0xc4, 0xf4, 0xbf, 0xa9, 0xc8, 0x7e, 0x32, 0x23, 0xba, 0xe2, 0xa7, 0x98,
	0x1b, 0x81, 0xe7, 0x0e, 0x0d, 0x43, 0xe6, 0xea, 0x7f, 0xab, 0x00, 0xf7, 0x22, 0xba, 0x02, 0x8c,
	0xb9, 0xf9, 0x91, 0x61, 0xfe, 0x70, 0x1c, 0x32, 0xfd, 0x1f, 0x14, 0x60, 0x2f, 0xa2, 0xab, 0x47,
	0x26, 0xa2, 0xa2, 0xa1, 0x06, 0x9e, 0x3b, 0xa0, 0xa1, 0xfe, 0x5d, 0xc5, 0x50, 0xbb, 0x9c, 0xac,
	0x18, 0x2a, 0xe2, 0xe5, 0xfb, 0x69, 0xe4, 0xd8, 0xa1, 0xfe, 0x49, 0x45, 0xd9, 0x4f, 0x48, 0x55,
	0xf7, 0x13, 0xd2, 0x48, 0x17, 0x96, 0x02, 0xf6, 0x5b, 0x63, 0xe6, 0x0e, 0x98, 0xc9, 0x46, 0x8c,
	0x86, 0xfa, 0x0f, 0x2a, 0x72, 0xe6, 0xd4, 0x97, 0xa6, 0x65, 0x21, 0x0a, 0x96, 0x1c, 0xc1, 0x72,
	0x60, 0xe3, 0xb9, 0x35, 0xd9, 0x60, 0xec, 0xfb, 0xcc, 0x0d, 0xf5, 0xaf, 0x55, 0xb9, 0xb8, 0xb4,
	0x44, 0xed, 0xcb, 0xf3, 0xb2, 0x3c, 0x15, 0x8d, 0x3b, 0xf2, 0xc2, 0x1f, 0xeb, 0xdf, 0xac, 0xca,
	0x3b, 0x72, 0xdf, 0x3c, 0x51, 0x76, 0xd7, 0x85, 0x3f, 0x26, 0x1f, 0x02, 0x19, 0xbb, 0xf6, 0x13,
	0xdb, 0x67, 0x3c, 0x28, 0x50, 0xa7, 0xdb, 0x3f, 0x3e, 0xd0, 0xbf, 0x15, 0x61, 0x3f, 0x37, 0x09,
	0x1c, 0x2a, 0x8b, 0x2c, 0x2a, 0x47, 0x06, 0x39, 0x81, 0x1b, 0x67, 0x19, 0xc1, 0xdf, 0xae, 0xca,
	0x89, 0x45, 0xab, 0x5c, 0x6e, 0x56, 0x42, 0x6b, 0x16, 0xa6, 0x79, 0x61, 0x6f, 0xfc, 0xb5, 0x06,
	0x8b, 0x2d, 0xcf, 0xb7, 0x98, 0xbf, 0x33, 0xf4, 0xc6, 0x6e, 0x18, 0x90, 0x36, 0x2c, 0x9e, 0x89,
	0x04, 0x1d, 0x78, 0xa5, 0x9f, 0xee, 0x79, 0x89, 0x7b, 0xab, 0x6d, 0x5d, 0xb0, 0xbe, 0xfd, 0x15,
	0x16, 0x98, 0x32, 0x6a, 0xad, 0x0f, 0xf3, 0xe9, 0x1c, 0xf9, 0x2c, 0x2c, 0x06, 0x21, 0xf5, 0xc3,
	0x84, 0xc2, 0x93, 0x94, 0x9a, 0x29, 0x13, 0xb1, 0x22, 0x66, 0xae, 0x95, 0xf2, 0x54, 0x38, 0x8f,
	0x48, 0x32, 0x0e, 0x60, 0xe1, 0x94, 0x3a, 0xb6, 0x15, 0x47, 0x7d, 0xf2, 0x08, 0x96, 0xe2, 0x50,
	0x9f, 0x28, 0xab, 0xc9, 0x09, 0xa2, 0xa4, 0xac, 0xa9, 0x30, 0x1b, 0x7f, 0xac, 0x41, 0xbd, 0x4f,
	0x87, 0x2c, 0x11, 0xf7, 0x14, 0x16, 0x69, 0x70, 0x35, 0xc4, 0x1c, 0xec, 0xea, 0xc0, 0xb3, 0x22,
	0x35, 0x97, 0xb6, 0x7f, 0x21, 0xdd, 0x41, 0x13, 0x5e, 0xf1, 0x37, 0xb2, 0x9a, 0x32, 0x12, 0xcb,
	0x40, 0x85, 0x83, 0xac, 0x02, 0x69, 0x1d, 0x1d, 0x1f, 0x1f, 0x1d, 0x7c, 0x64, 0x3e, 0xdd, 0xef,
	0x1c, 0x7f, 0xd4, 0x69, 0xef, 0x9c, 0x7e, 0xb9, 0x31, 0x45, 0x08, 0x2c, 0x1d, 0x1f, 0xf5, 0x3e,
	0xea, 0xb6, 0xf7, 0x12, 0x9a, 0x66, 0x6c, 0xc1, 0x82, 0x58, 0x20, 0x91, 0x75, 0x80, 0x73, 0xc7,
	0xa3, 0xe1, 0x29, 0x75, 0xc6, 0x49, 0xab, 0x41, 0xa0, 0x18, 0x7f, 0x54, 0x83, 0xd5, 0xfc, 0x04,
	0x8d, 0xbc, 0x0e, 0x4b, 0x51, 0x7e, 0xb7, 0x1b, 0x35, 0x51, 0x82, 0xd8, 0xf8, 0x0a, 0x15, 0xf9,
	0x9e, 0x31, 0xdf, 0x65, 0x4e, 0xca, 0x17, 0x39, 0x40, 0xa1, 0x12, 0x1d, 0x66, 0xdd, 0x7d, 0xdf,
	0x1b, 0x8f, 0x02, 0x5e, 0x5f, 0xd5, 0xcc, 0x64, 0x88, 0x4a, 0x46, 0xbc, 0xdc, 0x7d, 0xcd, 0x8d,
	0xea, 0x66, 0xcd, 0x14, 0x28, 0x98, 0x77, 0x06, 0xa1, 0x6f, 0x5b, 0x4c, 0x5f, 0xe7, 0x73, 0xf1,
	0x08, 0x9f, 0x6c, 0xd9, 0x0e, 0x4f, 0xe5, 0xf6, 0xe8, 0x20, 0xf4, 0x7c, 0x7d, 0x93, 0xcf, 0x2b,
	0x54, 0xf2, 0x06, 0x4c, 0x3f, 0x47, 0xef, 0xc7, 0x55, 0x40, 0x5a, 0x4a, 0x8a, 0x5b, 0x02, 0xe3,
	0x0b, 0x67, 0x22, 0x77, 0xa1, 0x16, 0x60, 0x3e, 0xfc, 0x16, 0x67, 0x5e, 0xc9, 0xf1, 0x21, 0x5e,
	0x55, 0xc8, 0x42, 0x36, 0x61, 0xd9, 0x0e, 0x9e, 0x30, 0x31, 0xf9, 0xc5, 0xc2, 0x61, 0xce, 0x54,
	0xc9, 0xb8, 0xf8, 0x4b, 0x1a, 0xf0, 0x36, 0xd1, 0x1e, 0xe7, 0x48, 0x86, 0x64, 0x0b, 0x66, 0x3f,
	0xe6, 0x1e, 0x0b, 0xf4, 0x5f, 0x2f, 0xa9, 0x74, 0x13, 0x26, 0x5e, 0x16, 0xa3, 0x98, 0xdf, 0x28,
	0x2d, 0x8b, 0x51, 0xf2, 0x06, 0xd4, 0x23, 0x57, 0xf5, 0xf9, 0x05, 0x62, 0x71, 0xdb, 0x88, 0xa4,
	0x96, 0x2e, 0x39, 0x3f, 0x5e, 0x1d, 0xaf, 0x15, 0xfe, 0x4d, 0x83, 0x5b, 0x05, 0xd9, 0x2f, 0x1e,
	0x4a, 0x5e, 0x0f, 0x28, 0xfb, 0x42, 0x26, 0xe6, 0x6c, 0x9f, 0x4a, 0xee, 0xf6, 0x11, 0x2c, 0x03,
	0x85, 0x96, 0x69, 0xbe, 0x8a, 0x65, 0x6e, 0x5e, 0x67, 0x19, 0xe3, 0xfb, 0x1a, 0x34, 0xf3, 0xd2,
	0x72, 0xb2, 0x06, 0x73, 0x7c, 0x15, 0x4f, 0xec, 0x61, 0xbc, 0xaa, 0x74, 0xfc, 0x33, 0xbd, 0xa0,
	0x1f, 0x56, 0xa0, 0x99, 0x57, 0x28, 0xe0, 0x82, 0x06, 0xb2, 0x9b, 0xd2, 0x31, 0x2e, 0x68, 0xe0,
	0x0d, 0x47, 0xe3, 0x90, 0xc5, 0xa5, 0x02, 0xef, 0x94, 0xcc, 0x99, 0x0a, 0x95, 0x3c, 0x80, 0x9b,
	0x36, 0xcf, 0x47, 0x26, 0x75, 0x44, 0x54, 0x6d, 0xcd, 0x70, 0xf6, 0xfc, 0x49, 0x34, 0x03, 0x1b,
	0x05, 0xb6, 0xe3, 0xb9, 0x71, 0x33, 0x36, 0x19, 0x92, 0x7b, 0x30, 0x7d, 0x41, 0x87, 0x43, 0x1a,
	0xf7, 0x4c, 0x0a, 0x9a, 0x40, 0x9c, 0x25, 0x6d, 0x02, 0x35, 0xae, 0x6b, 0x02, 0x21, 0xe7, 0x90,
	0x51, 0x57, 0xbf, 0x51, 0xc6, 0x89, 0x1c, 0xe4, 0x97, 0x60, 0xee, 0x79, 0x5c, 0x17, 0xe9, 0xa4,
	0x84, 0x3b, 0xe5, 0x32, 0xfe, 0xa4, 0x06, 0x24, 0x5b, 0x86, 0x92, 0x77, 0xa1, 0x16, 0x5e, 0x8d,
	0x92, 0x68, 0xff, 0x7a, 0x71, 0xc1, 0x9a, 0x90, 0xf0, 0x68, 0x99, 0x1c, 0xa3, 0xc4, 0x3c, 0x28,
	0x89, 0x79, 0x4d, 0x29, 0xe6, 0xa5, 0xb1, 0x6c, 0xfd, 0x55, 0x62, 0xd9, 0x6b, 0xd7, 0xc7, 0xb2,
	0xdf, 0x84, 0x86, 0xed, 0x0e, 0x9c, 0xb1, 0xc5, 0xba, 0x34, 0x08, 0x7b, 0xf6, 0x0b, 0xe6, 0xe8,
	0x1b, 0x1c, 0xf6, 0x85, 0x92, 0x85, 0xf1, 0xc7, 0xee, 0x7a, 0x98, 0x02, 0x85, 0x82, 0xc8, 0x8c,
	0x28, 0xdc, 0x44, 0xf4, 0xf9, 0x05, 0x4a, 0x68, 0xbf, 0xe0, 0x53, 0x31, 0x33, 0x8f, 0xc9, 0x73,
	0x66, 0xfe, 0x24, 0x86, 0x9a, 0x0b, 0xc7, 0x3b, 0xa3, 0x4e, 0xfc, 0xe8, 0x38, 0xbc, 0xca, 0xc4,
	0xb5, 0xc7, 0xd0, 0xcc, 0xd3, 0x03, 0x37, 0xb8, 0x72, 0xcb, 0x47, 0x76, 0x56, 0xaf, 0xf3, 0xfb,
	0x50, 0x17, 0x1c, 0x44, 0x66, 0xa1, 0x7a, 0xb0, 0xf3, 0x61, 0x63, 0x8a, 0xd4, 0x61, 0x76, 0xe7,
	0xb4, 0x6d, 0xee, 0xec, 0xb7, 0x1b, 0x1a, 0x99, 0x81, 0x4a, 0x77, 0xbb, 0x51, 0x69, 0x35, 0xd3,
	0xad, 0x20, 0xc6, 0xcb, 0x3f, 0xaf, 0x02, 0xc9, 0x96, 0x94, 0xa4, 0x03, 0x73, 0x83, 0xa4, 0x06,
	0x88, 0x32, 0x8c, 0x7b, 0xc5, 0x05, 0x68, 0x42, 0x4a, 0xb2, 0x7f, 0xac, 0xd8, 0x12, 0x34, 0x39,
	0x04, 0xf0, 0xd9, 0xb9, 0x13, 0x25, 0x63, 0x71, 0x4f, 0xf4, 0x8d, 0xeb, 0x65, 0x99, 0x29, 0xa6,
	0x33, 0x65, 0x0a, 0x12, 0xc8, 0xfb, 0x50, 0xf7, 0xd9, 0xc8, 0xb1, 0x07, 0xd1, 0x51, 0x8e, 0x12,
	0xc3, 0x5f, 0x7c, 0x19, 0x81, 0x29, 0xa8, 0x33, 0x65, 0x8a, 0x32, 0x72, 0x92, 0x2a, 0x78, 0x85,
	0xa4, 0x6a, 0xed, 0xf3, 0xb0, 0xac, 0x18, 0x80, 0x34, 0xf9, 0x66, 0x1f, 0xb3, 0xa4, 0x21, 0xcd,
	0x07, 0x6b, 0x2b, 0x70, 0x23, 0xb3, 0xba, 0xb5, 0x66, 0x6a, 0x7f, 0x41, 0xc3, 0xd6, 0x22, 0xd4,
	0x45, 0x2f, 0x3d, 0x84, 0x1b, 0x99, 0x62, 0x04, 0x77, 0x49, 0x52, 0x13, 0x44, 0x93, 0xbc, 0x81,
	0x35, 0x67, 0x2a, 0x54, 0xe3, 0x1c, 0x96, 0xe4, 0xae, 0xc4, 0xcb, 0x37, 0xf7, 0xc9, 0x1d, 0x98,
	0x77, 0xbc, 0x01, 0x8d, 0x0e, 0x7b, 0x95, 0xc7, 0xe1, 0x09, 0x81, 0x2c, 0x80, 0xf6, 0x4c, 0xaf,
	0x71, 0x76, 0xed, 0x99, 0xd1, 0x04, 0x92, 0x6d, 0x99, 0x18, 0x5b, 0xd0, 0x50, 0x4b, 0x22, 0x0c,
	0xee, 0xee, 0x11, 0xbf, 0x7c, 0xd2, 0xe0, 0x9e, 0x8c, 0x8d, 0xd7, 0x61, 0x49, 0x6e, 0x1b, 0x14,
	0x74, 0xf7, 0xef, 0xc3, 0x4a, 0x4e, 0xb3, 0xa0, 0x80, 0xf9, 0x9b, 0x15, 0xd0, 0x8b, 0xba, 0x18,
	0xe4, 0xb1, 0x14, 0x0d, 0xef, 0x5d, 0xd7, 0xf5, 0xd8, 0x3a, 0x1a, 0x31, 0x3f, 0x6a, 0xaa, 0x47,
	0x11, 0x31, 0x7d, 0x64, 0x45, 0xb4, 0xa6, 0x70, 0x8d, 0x54, 0xe5, 0x6b, 0xa4, 0x09, 0xd3, 0xc1,
	0xa5, 0x7d, 0x1e, 0xc6, 0x96, 0x8b, 0x06, 0x9c, 0xca, 0x1b, 0x14, 0xd3, 0x31, 0x15, 0x07, 0xc6,
	0x19, 0xcc, 0xa7, 0x8f, 0x23, 0x73, 0x50, 0xeb, 0xbf, 0x6f, 0x1e, 0x37, 0xa6, 0xc8, 0x3c, 0x4c,
	0x9b, 0xfc, 0xa7, 0x86, 0x67, 0xfd, 0xe9, 0xe1, 0x69, 0xdb, 0xec, 0xb7, 0x1b, 0x15, 0xa4, 0xf7,
	0x8e, 0x3e, 0x68, 0x9b, 0x8d, 0x2a, 0x06, 0x83, 0xf6, 0x87, 0xbd, 0x46, 0x0d, 0x7f, 0x74, 0x8f,
	0xf6, 0x1b, 0xd3, 0xf8, 0x63, 0xa7, 0xd5, 0x6f, 0xcc, 0x90, 0x45, 0x98, 0x3f, 0xee, 0x98, 0xed,
	0x7e, 0xe7, 0xa8, 0xfb, 0xa4, 0x31, 0x6b, 0x3c, 0x84, 0x95, 0x9c, 0xd6, 0x10, 0x2f, 0x61, 0x06,
	0x14, 0xe3, 0x45, 0x9c, 0xa3, 0x6a, 0x3c, 0x06, 0xc9, 0x44, 0xe3, 0x7d, 0x58, 0x56, 0xfa, 0x21,
	0xd1, 0xfa, 0xe8, 0x88, 0xc5, 0x80, 0x68, 0x90, 0xe6, 0x04, 0x95, 0x6b, 0x73, 0x82, 0xef, 0x6a,
	0xd0, 0x50, 0xbb, 0x32, 0x78, 0xed, 0x70, 0x39, 0xd1, 0x5b, 0xd2, 0x48, 0xb2, 0x40, 0xc1, 0xbb,
	0x39, 0x32, 0x5f, 0x99, 0xfc, 0xb8, 0xb1, 0x23, 0x24, 0x3a, 0x55, 0x39, 0xd1, 0xb9, 0x03, 0xf3,
	0x5c, 0x26, 0x9f, 0xab, 0xf1, 0x87, 0x4c, 0x08, 0xe9, 0x12, 0xa6, 0xaf, 0x5d, 0xc2, 0x97, 0xe1,
	0x56, 0x41, 0xa7, 0xa4, 0xd8, 0x3a, 0x16, 0xbd, 0xee, 0x9d, 0x11, 0x72, 0x18, 0xdb, 0xb0, 0x9a,
	0xdf, 0xd9, 0x14, 0x77, 0x9c, 0x26, 0xed, 0x38, 0xe3, 0x77, 0x35, 0x20, 0xd9, 0xee, 0x09, 0x79,
	0x08, 0xb5, 0xe1, 0xa4, 0xe8, 0xfb, 0x7c, 0x71, 0x9f, 0x25, 0x21, 0x1d, 0x61, 0x18, 0x34, 0x39,
	0xc8, 0x78, 0x0b, 0x16, 0x44, 0x2a, 0xb9, 0x01, 0x8b, 0xbb, 0x9d, 0x9d, 0xc3, 0xc3, 0x76, 0xf7,
	0xa3, 0xbd, 0xa7, 0x66, 0x1f, 0x77, 0x69, 0x03, 0x16, 0x12, 0x52, 0x77, 0xa7, 0x7f, 0xdc, 0xd0,
	0x8c, 0xbf, 0xd4, 0x80, 0x64, 0xfb, 0x3f, 0x98, 0xf0, 0x87, 0xd4, 0xbf, 0x60, 0x71, 0xc2, 0x8f,
	0x96, 0xa9, 0x9a, 0x22, 0x29, 0x55, 0xb5, 0x22, 0xab, 0x9a, 0x95, 0x95, 0x90, 0x14, 0x55, 0x45,
	0xea, 0xcb, 0xa9, 0xba, 0x09, 0x24, 0xdb, 0x37, 0xc2, 0x18, 0x49, 0x5f, 0xd8, 0x41, 0xec, 0x3c,
	0xfe, 0xdb, 0xf8, 0x67, 0x0d, 0x6e, 0x64, 0x7a, 0x6a, 0xe4, 0x91, 0x64, 0xdc, 0xbb, 0x85, 0xcd,
	0xb7, 0x98, 0x22, 0x04, 0x15, 0x84, 0x89, 0xce, 0xac, 0xc8, 0xce, 0xfc, 0x10, 0x96, 0x15, 0x08,
	0x9e, 0xec, 0xfe, 0xc9, 0x41, 0x63, 0x8a, 0x1f, 0xf1, 0xd3, 0xfd, 0x86, 0x86, 0xa1, 0xa2, 0x67,
	0x1e, 0x3d, 0x69, 0x54, 0x08, 0xc0, 0x4c, 0xf7, 0x68, 0x1f, 0xa7, 0xab, 0x78, 0xf0, 0xfb, 0x27,
	0x07, 0xfd, 0xf7, 0x4f, 0x76, 0xcc, 0x76, 0xa3, 0xc6, 0x33, 0x83, 0x37, 0x1b, 0xd3, 0x71, 0x86,
	0x30, 0x63, 0x9c, 0xc1, 0xb2, 0xd2, 0x90, 0x26, 0x5f, 0x84, 0xfa, 0xc0, 0xf7, 0x46, 0x2f, 0xd5,
	0x6c, 0x10, 0x39, 0xf9, 0x2b, 0x97, 0xf3, 0xf3, 0x80, 0x85, 0xfa, 0x74, 0x94, 0x06, 0x46, 0x23,
	0xfe, 0xfa, 0x35, 0xd3, 0xa8, 0x35, 0x1a, 0xb0, 0x24, 0xb7, 0x49, 0x39, 0x45, 0xea, 0x85, 0x1a,
	0xbb, 0x70, 0x33, 0xb7, 0xe1, 0x49, 0xee, 0x41, 0x63, 0xe0, 0x05, 0xb6, 0xcb, 0xfa, 0xf6, 0xd0,
	0x76, 0xf8, 0x6b, 0x23, 0xae, 0xe8, 0x9c, 0x99, 0xa1, 0x1b, 0x7f, 0xa8, 0xc1, 0xc6, 0x75, 0xef,
	0x17, 0xf0, 0x62, 0xa5, 0x03, 0xdf, 0x0b, 0x02, 0xa9, 0x50, 0x9c, 0x33, 0x15, 0x2a, 0x79, 0x03,
	0x6e, 0xa4, 0x2f, 0x12, 0x12, 0x81, 0xdc, 0x5b, 0x73, 0x66, 0x76, 0xa2, 0xf8, 0x42, 0x30, 0x7e,
	0x15, 0x6e, 0x17, 0x76, 0xfe, 0x88, 0x01, 0x0b, 0x2e, 0x52, 0x43, 0x1b, 0x5d, 0x9d, 0xdc, 0x97,
	0x12, 0xcd, 0xf8, 0x7e, 0x15, 0xd6, 0x8a, 0x9b, 0x7d, 0xbc, 0xda, 0xc7, 0x62, 0xf0, 0x94, 0x61,
	0xc8, 0x16, 0xda, 0x51, 0x2a, 0x19, 0x4d, 0x19, 0x15, 0x85, 0x02, 0x6b, 0x54, 0x2c, 0x66, 0xe8,
	0xe4, 0x1d, 0xe9, 0x05, 0x16, 0x94, 0xbf, 0xbf, 0x92, 0xde, 0x5e, 0x09, 0x89, 0x4b, 0x74, 0xeb,
	0xf3, 0x82, 0x4a, 0x48, 0x5c, 0x22, 0x2a, 0xde, 0x40, 0x71, 0x60, 0x8e, 0x1e, 0xcb, 0x8b, 0xcf,
	0x39, 0x53, 0x26, 0x92, 0x77, 0x60, 0x21, 0xaa, 0x3b, 0x0f, 0x68, 0xe8, 0xdb, 0x2f, 0xd4, 0xfa,
	0x42, 0x0a, 0xa1, 0x12, 0x27, 0x79, 0x0c, 0xcb, 0x3e, 0xda, 0x2b, 0xb0, 0x3d, 0x37, 0x06, 0xbf,
	0x56, 0x02, 0x56, 0x99, 0xc9, 0x03, 0x80, 0xb3, 0x89, 0x72, 0x1b, 0x25, 0x50, 0x81, 0x0f, 0x1d,
	0xea, 0xb3, 0xe7, 0xcc, 0x0f, 0xd8, 0x53, 0xfe, 0xa6, 0x32, 0x4a, 0xda, 0x24, 0x9a, 0xf1, 0x83,
	0x59, 0x58, 0x92, 0x1b, 0xaf, 0xff, 0x4f, 0x4e, 0x7c, 0x17, 0xea, 0x13, 0xc7, 0x24, 0x9d, 0xcf,
	0x62, 0x2f, 0x8a, 0xcc, 0x2f, 0xed, 0xc6, 0xd7, 0x61, 0x49, 0xf2, 0x58, 0x10, 0xfb, 0x51, 0xa1,
	0x92, 0x2e, 0xac, 0x8e, 0x47, 0x16, 0x0d, 0xd9, 0x3e, 0x0d, 0xd9, 0x07, 0x2f, 0xeb, 0xd2, 0x02,
	0x0c, 0xf9, 0x12, 0xdc, 0xf4, 0x59, 0xc0, 0xc2, 0x8c, 0xb0, 0x32, 0x17, 0xe7, 0x43, 0x50, 0xb3,
	0xc8, 0x72, 0x19, 0x61, 0x65, 0x4e, 0x2f, 0xc0, 0x10, 0x13, 0x6e, 0x4f, 0x74, 0x36, 0x95, 0x0d,
	0xb8, 0x5d, 0x22, 0xb0, 0x18, 0x46, 0x7a, 0xa0, 0xa7, 0xaa, 0xab, 0x22, 0xdf, 0x2a, 0x11, 0x59,
	0x88, 0x42, 0x2d, 0x27, 0xfa, 0xab, 0x22, 0x1f, 0x94, 0x69, 0x59, 0x08, 0x23, 0x1d, 0x68, 0x4e,
	0x96, 0x20, 0x9c, 0xeb, 0xbd, 0x12, 0x71, 0xb9, 0x08, 0xb2, 0x07, 0x2b, 0xa9, 0xe6, 0x82, 0xa0,
	0xfd, 0x12, 0x41, 0x79, 0x00, 0xd4, 0x68, 0xa2, 0xae, 0x20, 0xa8, 0x53, 0xa6, 0x51, 0x1e, 0xe2,
	0xa5, 0x8e, 0xf5, 0x37, 0x2a, 0x00, 0xdd, 0xfe, 0xf1, 0x41, 0xb6, 0x80, 0x8b, 0x0f, 0x10, 0xfc,
	0x58, 0x07, 0x68, 0x1d, 0xe0, 0xdc, 0xc3, 0x9c, 0x29, 0xfd, 0xaa, 0x6f, 0xce, 0x14, 0x28, 0x64,
	0x0b, 0xc8, 0x25, 0x0d, 0x7a, 0x8c, 0x8d, 0x2e, 0x3d, 0x87, 0x25, 0xb2, 0x36, 0x39, 0x5f, 0xce,
	0x0c, 0x79, 0x0f, 0x6e, 0x0f, 0xbc, 0xf1, 0xc8, 0x61, 0x16, 0x57, 0x7f, 0xc7, 0xb5, 0xf6, 0xb8,
	0x30, 0x5c, 0x79, 0xdc, 0xfe, 0x28, 0x66, 0xc0, 0xdb, 0x71, 0xc0, 0x1c, 0x67, 0xd7, 0xb1, 0x47,
	0xe9, 0x77, 0x40, 0xbc, 0x0d, 0x52, 0x31, 0xb3, 0x13, 0xc6, 0xdf, 0xcd, 0x43, 0x03, 0x4d, 0x23,
	0xbd, 0x04, 0xf8, 0x12, 0xdc, 0xe4, 0xc1, 0x2d, 0x73, 0xec, 0xca, 0xbe, 0xc2, 0xca, 0x87, 0xe0,
	0x19, 0x3e, 0x4f, 0x95, 0x93, 0x84, 0x95, 0xe5, 0xdc, 0x05, 0x18, 0x94, 0x76, 0xe6, 0x78, 0x83,
	0x67, 0x7c, 0xdd, 0x92, 0xb4, 0x6a, 0x99, 0xb4, 0x7c, 0x4c, 0x49, 0x7c, 0xa9, 0xfd, 0x08, 0xf1,
	0xa5, 0x07, 0x7a, 0x6a, 0x02, 0xf5, 0xe0, 0x96, 0xb5, 0x6f, 0x0b, 0x51, 0x18, 0x0b, 0x26, 0x76,
	0x50, 0x45, 0x96, 0x35, 0x79, 0x8b, 0x61, 0x28, 0x73, 0x62, 0x0d, 0x55, 0xe6, 0x6a, 0x99, 0xcc,
	0x42, 0x58, 0x79, 0xcc, 0xba, 0xf5, 0xa3, 0xc5, 0xac, 0x3d, 0x58, 0x49, 0xed, 0x22, 0x04, 0x88,
	0xcd, 0xb2, 0x48, 0x93, 0x03, 0xc0, 0x48, 0x33, 0x31, 0x86, 0x20, 0xe8, 0x6e, 0x59, 0xa4, 0xc9,
	0x43, 0xa0, 0xa4, 0x89, 0x09, 0x04, 0x49, 0xf7, 0xca, 0x24, 0xe5, 0x21, 0x0a, 0xa3, 0xdf, 0xfd,
	0x57, 0x8e, 0x7e, 0x87, 0x70, 0x2b, 0x5d, 0xb4, 0x1c, 0x46, 0xe2, 0x2f, 0xd2, 0xf2, 0x85, 0x15,
	0x81, 0x70, 0x0f, 0x4f, 0xd6, 0xae, 0x08, 0x7c, 0x54, 0xb6, 0x87, 0x8b, 0x50, 0x28, 0x71, 0xa2,
	0xb9, 0x22, 0xf1, 0x71, 0x99, 0xc4, 0x22, 0x94, 0xf1, 0x4f, 0x15, 0xf8, 0x4c, 0xe9, 0x1b, 0xee,
	0x9f, 0xc1, 0x9c, 0xed, 0x1e, 0xcc, 0xf0, 0x8f, 0xee, 0x82, 0xf8, 0x1d, 0x06, 0x49, 0x3f, 0xec,
	0x48, 0xaf, 0x25, 0x33, 0xe6, 0x20, 0xef, 0x25, 0x89, 0x75, 0x44, 0x8f, 0x63, 0x87, 0x2e, 0x22,
	0xf2, 0x92, 0xeb, 0x49, 0xdd, 0x72, 0xed, 0x7d, 0xf8, 0xd5, 0x2a, 0xdc, 0x69, 0xfd, 0xe4, 0x0d,
	0xd8, 0x83, 0x55, 0xc1, 0x26, 0x7b, 0x9e, 0xff, 0x31, 0xf5, 0x2d, 0xfe, 0x9d, 0xc1, 0x75, 0xb6,
	0x2c, 0xc0, 0x11, 0x13, 0x6e, 0x09, 0x33, 0x2d, 0x3a, 0x78, 0x96, 0x8a, 0xac, 0x5f, 0x23, 0xb2,
	0x08, 0xf8, 0x63, 0xba, 0xaa, 0xfa, 0xf2, 0xae, 0x32, 0xbe, 0x53, 0x81, 0x5b, 0xd2, 0xf7, 0x95,
	0xbb, 0x0e, 0x0d, 0x02, 0xfb, 0xdc, 0x66, 0xfe, 0x4f, 0xf7, 0xaf, 0x13, 0xe4, 0x09, 0xdc, 0x08,
	0x42, 0xdf, 0x76, 0x2f, 0xb8, 0x46, 0x5d, 0x7a, 0x86, 0xc5, 0xb8, 0x25, 0x9f, 0xd6, 0x3e, 0x67,
	0x88, 0xdc, 0xdb, 0x99, 0x32, 0xb3, 0x00, 0xb2, 0x03, 0x0d, 0xdb, 0x0d, 0xdf, 0x7e, 0x20, 0x0a,
	0x61, 0xf2, 0x8b, 0xa5, 0xa7, 0x38, 0x9f, 0xca, 0xc8, 0xb0, 0xb7, 0x16, 0xa1, 0x2e, 0x0c, 0x8d,
	0xaf, 0x6b, 0xca, 0x5f, 0x24, 0x4c, 0x76, 0xe1, 0xf3, 0xff, 0x0d, 0xfc, 0x74, 0x0d, 0xd6, 0x22,
	0xdf, 0xfb, 0x74, 0x5d, 0xfb, 0x97, 0x4f, 0xd7, 0xb5, 0x7f, 0xff, 0x74, 0x5d, 0xfb, 0xda, 0x7f,
	0xac, 0x4f, 0x75, 0xaa, 0xbd, 0xa9, 0xb3, 0x19, 0xfe, 0xc7, 0x98, 0xb7, 0xfe, 0x2f, 0x00, 0x00,
	0xff, 0xff, 0x11, 0xc0, 0x2b, 0x7d, 0x4d, 0x33, 0x00, 0x00,
}
