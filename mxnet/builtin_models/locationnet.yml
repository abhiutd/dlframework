name: LocationNet
framework: mxnet
version: 1.0
type: cnn
input:
  type: image
  dimensions: [1, 3, 224, 224]
dataset_name: MultimediaCommons
features_url: https://github.com/multimedia-berkeley/tutorials/blob/master/grids.txt
graph_url: https://s3.amazonaws.com/mmcommons-tutorial/models/RN101-5k500-symbol.json
weights_url: https://s3.amazonaws.com/mmcommons-tutorial/models/RN101-5k500-0012.params
mean_image: [123.68, 116.779, 103.939]
references:
  - https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45488.pdf
description: >
  A convolutional neural network (based on the Inception architecture) trained to localize photos.
  The network was trained on 19M EXIF geotagged photos.
  The network consists of 97,321,048 parameters.
  LoationNet is able to localize 3.6% of images at street level, and 48% at continent level.